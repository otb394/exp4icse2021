id,created_at,closed_at,state,comments,title
309,2020-08-29 20:47:57.000000000,2020-08-29 20:56:17.000000000,closed,0,"Update docs w/ markdown, summary tables"
308,2020-08-27 22:54:54.000000000,2020-08-30 00:15:52.000000000,closed,1,"""IndexError: list assignment index out of range"" performing `delete_words` in a text"
307,2020-08-25 07:50:24.000000000,2020-08-26 04:43:21.000000000,closed,0,Improve and expand text statistics
306,2020-08-17 03:49:54.000000000,2020-08-17 05:01:52.000000000,closed,0,Continue tidying pkg and code
305,2020-08-16 03:52:56.000000000,2020-08-16 06:54:49.000000000,closed,0,Update package configuration and automate maintenance actions
304,2020-08-03 05:14:50.000000000,1970-01-01 00:00:00.000000001,open,1,spacy morphology size changed
303,2020-08-01 05:51:56.000000000,2020-08-14 06:30:21.000000000,closed,1,Spherical k-means for sparse vector clustering
302,2020-07-14 04:04:29.000000000,2020-07-15 05:33:50.000000000,closed,1,Fix vsm.Vectorizer reference in quickstart docs
301,2020-05-09 13:08:41.000000000,2020-06-10 06:52:24.000000000,closed,2,Paragraph Count in Textacy
300,2020-05-01 13:44:15.000000000,2020-07-15 05:37:36.000000000,closed,5,"Module 'textacy' has no attribute 'Vectorizer'`, following Quickstart docs"
299,2020-04-09 19:23:21.000000000,2020-04-10 22:53:24.000000000,closed,3,Extracting SVO triplets -> get token indexes?
298,2020-04-09 18:32:12.000000000,2020-04-10 03:59:40.000000000,closed,0,Adopt pyproject.toml configuration standard
297,2020-04-05 22:00:44.000000000,2020-04-06 05:46:25.000000000,closed,1,attribute error: textacy has no attribute 'preprocess'
296,2020-04-04 02:16:34.000000000,2020-04-04 02:49:43.000000000,closed,0,can't seem to download textacy any longer from conda or pypi
295,2020-03-25 00:02:23.000000000,2020-07-15 05:35:47.000000000,closed,6,Termite spectral sort
294,2020-03-22 13:26:08.000000000,2020-05-11 06:12:41.000000000,closed,7,outdated version of textacy on Anaconda
293,2020-03-09 18:22:20.000000000,1970-01-01 00:00:00.000000001,open,1,Thank You for maintaining this library. Indirect Speech extracation
292,2020-02-25 18:41:27.000000000,2020-02-28 19:36:53.000000000,closed,4,Language Identification does not work anymore
291,2020-02-25 08:03:05.000000000,2020-02-28 08:33:52.000000000,closed,1,textacy.lang_utils.identify_lang throws IndexError: pop from empty list
290,2020-02-12 15:50:29.000000000,1970-01-01 00:00:00.000000001,open,4,pos_regex_matches vs matches different behavior
289,2020-02-07 08:35:15.000000000,2020-02-15 03:00:20.000000000,closed,0,Add type hints and update docstrings
288,2020-01-31 17:20:38.000000000,1970-01-01 00:00:00.000000001,open,0,"In vectorizer.fit_transform() function, when tf_type=""log"" we get UFuncTypeError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'"
287,2020-01-27 12:15:08.000000000,2020-02-15 01:15:30.000000000,closed,1,Identifying the tense of sentence as Future
286,2020-01-16 10:50:20.000000000,2020-01-16 16:54:56.000000000,closed,1,No module named 'textacy'
285,2019-12-31 00:34:20.000000000,2019-12-31 00:39:43.000000000,closed,0,Update corpus methods with new spaCy functionality
284,2019-11-20 10:16:04.000000000,2019-12-17 23:04:18.000000000,closed,1,AttributeError: module 'textacy' has no attribute 'resources'
283,2019-11-11 14:16:26.000000000,2019-12-17 23:12:21.000000000,closed,1,Unable to install library on Azure Databricks cluster
282,2019-11-08 19:02:10.000000000,2019-11-30 14:26:16.000000000,closed,3,always UNICODE errors
281,2019-11-06 15:53:44.000000000,2020-03-02 04:19:18.000000000,closed,3,Old preprocess.py still deployed
280,2019-10-04 22:20:31.000000000,2020-03-02 01:34:12.000000000,closed,0,Mistype in resources documentation
279,2019-10-01 07:07:58.000000000,2019-12-17 23:12:39.000000000,closed,1,ModuleNotFoundError: No module named '_lzma'
278,2019-10-01 00:29:28.000000000,2020-03-02 01:34:12.000000000,closed,4,Convert all space symbols to one form
277,2019-09-29 13:58:58.000000000,2020-03-02 04:19:45.000000000,closed,5,multithreading for Corpus creation
276,2019-09-29 13:45:29.000000000,1970-01-01 00:00:00.000000001,open,3,QUOTE_TRANSLATION_TABLE need « / »
275,2019-09-28 20:01:11.000000000,2020-03-02 01:34:12.000000000,closed,6,Preprocessing: replace repeating punctuation characters 
274,2019-09-28 19:35:10.000000000,2019-12-22 03:34:24.000000000,closed,3,Preprocessing: replace em/en/doubled dash to single dash
273,2019-09-26 19:08:43.000000000,2019-09-27 13:37:22.000000000,closed,0,error with preprocessing.normalize_whitespace and textacy.make_spacy_doc
272,2019-09-10 06:46:02.000000000,2019-09-10 17:11:53.000000000,closed,2,n-gram range in textacy.extract.ngrams
271,2019-08-31 01:01:07.000000000,2019-08-31 01:20:04.000000000,closed,0,Add UDHR dataset
270,2019-08-30 18:01:14.000000000,2019-09-03 20:01:11.000000000,closed,1,ZeroDivisionError and ValueError in keyterms extraction with sCAKE
269,2019-08-30 05:43:30.000000000,2019-08-30 19:03:59.000000000,closed,0,Improve data augmentation functionality
268,2019-08-26 07:07:07.000000000,2019-08-27 00:05:19.000000000,closed,0,Add basic text data augmentation functionality
267,2019-08-24 04:06:38.000000000,2019-09-03 20:01:11.000000000,closed,1,Small bug in url detection regex
266,2019-08-22 01:54:38.000000000,1970-01-01 00:00:00.000000001,open,0,Apostrophes 2
265,2019-08-20 07:24:44.000000000,2019-08-21 18:04:46.000000000,closed,0,"Add, update, and standardize access to resources"
264,2019-07-31 02:20:54.000000000,1970-01-01 00:00:00.000000001,open,9,Wrong span for compounds?
263,2019-07-29 17:26:37.000000000,2019-07-30 21:23:08.000000000,closed,2,Add Portuguese readability score
262,2019-07-28 11:43:29.000000000,2019-07-31 21:00:40.000000000,closed,2,pandas dataframe to corpus
261,2019-07-23 21:23:29.000000000,2019-07-24 03:01:35.000000000,closed,0,"Drop PY2 support, and update PY3-only code"
260,2019-07-19 00:29:51.000000000,2019-07-19 02:25:09.000000000,closed,4,TopicModel broken with scikit-learn 0.21
259,2019-07-18 21:13:51.000000000,2019-08-19 18:39:29.000000000,closed,2,Apostrophes
258,2019-07-18 05:28:07.000000000,1970-01-01 00:00:00.000000001,open,1,"KeyError: ""[E018] Can't retrieve string for hash '10542206011124529393'."""
257,2019-07-07 23:44:14.000000000,2019-07-14 23:58:27.000000000,closed,0,Update keyterms module
256,2019-07-01 04:27:06.000000000,2019-07-01 06:02:14.000000000,closed,0,Update similarity module
255,2019-06-30 21:36:42.000000000,2019-07-01 04:23:29.000000000,closed,1,preprocess_text() got an unexpected keyword argument 'normalized_unicode'
254,2019-06-28 19:04:55.000000000,2020-03-02 04:20:09.000000000,closed,3,Unable to save corpus with custom extension attributes
253,2019-06-27 20:04:04.000000000,2019-06-28 00:59:00.000000000,closed,0,Enhance text preprocessing functionality
252,2019-06-27 18:19:05.000000000,2020-03-02 04:20:21.000000000,closed,1,"Saving corpus with custom user tags ""unhashable"" list"
251,2019-06-27 17:05:22.000000000,1970-01-01 00:00:00.000000001,open,1,Invalid subject verb object tuple in case of a composite subject
250,2019-06-26 19:57:27.000000000,2019-06-26 20:32:12.000000000,closed,2,preprocess text broken
249,2019-06-26 15:56:57.000000000,2019-07-04 19:13:33.000000000,closed,1,Add additional flags to doc_extensions.to_bag_of_words
248,2019-06-16 21:06:55.000000000,2019-07-15 00:53:51.000000000,closed,5,Issue241 rcm param and ducktyping for models
247,2019-06-02 22:15:30.000000000,2019-06-04 07:07:11.000000000,closed,0,Include built-in language identification functionality
246,2019-06-02 18:01:25.000000000,2019-06-26 01:10:57.000000000,closed,3,Installing `textacy[lang]` fails due to `cld2-cffi` bug
245,2019-05-30 14:51:50.000000000,2019-06-03 17:25:53.000000000,closed,5,Could able to import textacy package.
244,2019-05-27 10:34:38.000000000,2019-05-29 10:20:41.000000000,closed,0,subject_verb_object_triples error
243,2019-05-26 11:36:54.000000000,2019-06-26 20:10:54.000000000,closed,4,call to preprocess.preprocess_text returns TypeError (0.7.0)
242,2019-05-24 16:06:43.000000000,2019-05-24 17:58:23.000000000,closed,2,Model not found
241,2019-05-19 19:25:55.000000000,2019-07-15 00:55:15.000000000,closed,2,Flexible setting for RC_PARAMS and the ability to incorporate other topic models
240,2019-05-12 19:23:40.000000000,2019-05-13 00:20:05.000000000,closed,0,"Tidy up names, tests, docs, API"
239,2019-05-10 19:12:12.000000000,2019-05-11 09:33:29.000000000,closed,0,re-conceptualize and refactor core doc + docs API and functionality
238,2019-05-04 13:41:15.000000000,2019-07-15 01:00:00.000000000,closed,1,Clean emoji in preprocess_text method
237,2019-05-01 17:07:52.000000000,2019-06-04 06:39:57.000000000,closed,1,error during pip install textacy 
236,2019-04-30 15:19:44.000000000,2019-05-07 19:19:26.000000000,closed,2,In POS not getting Nouns (pattern=r’<NOUN>+’)
235,2019-04-29 21:54:55.000000000,2019-05-07 18:11:27.000000000,closed,0,Add to and improve `datasets`
234,2019-04-24 01:49:10.000000000,2019-04-25 19:26:36.000000000,closed,0,Refactor datasets
233,2019-03-06 16:59:31.000000000,2019-03-08 01:45:37.000000000,closed,2,Document how to make textacy.Doc(text) use default model if no language detected
232,2019-02-26 22:27:35.000000000,2019-03-08 02:21:57.000000000,closed,1,read multiple text files from a folder 
231,2019-02-19 22:44:39.000000000,2019-03-08 02:24:22.000000000,closed,1,Added Czech category mapping
230,2019-02-01 17:15:29.000000000,1970-01-01 00:00:00.000000001,open,1,Issues with stopwords when working with make_doc_from_text_chunks
229,2019-02-01 16:43:19.000000000,2019-03-22 22:38:19.000000000,closed,1,fix textacy.io.spacy.read_spacy_docs
228,2019-02-01 16:33:49.000000000,2019-03-22 22:37:52.000000000,closed,0,textacy.io.spacy.read_spacy_docs() gives key error when iterated over
227,2019-01-31 11:12:14.000000000,2019-05-07 18:11:46.000000000,closed,4,lots of missing words in text extracted from wikimedia dumps
226,2019-01-31 09:51:34.000000000,2019-05-07 18:11:57.000000000,closed,3,categories extracted from wikidumps are still present in extracted text
225,2019-01-30 14:02:35.000000000,2019-01-31 01:43:22.000000000,closed,2,Undefined variable in textacy.spacier.utils.merge_spans
224,2019-01-20 01:53:28.000000000,2019-02-02 22:27:58.000000000,closed,2,added a named param to records() to allow stripping of section headings 
223,2019-01-19 23:37:08.000000000,2019-01-30 23:42:16.000000000,closed,3,small change to catch bad wiki category markup
222,2019-01-11 15:36:05.000000000,2019-01-30 23:56:14.000000000,closed,2,some wikipedia categories aren't matched by regexp
221,2019-01-11 11:54:48.000000000,2019-03-24 03:37:05.000000000,closed,3,needs a version bump and submission to PyPi to make latest PRs accessable
220,2019-01-03 08:05:22.000000000,2019-01-06 03:42:09.000000000,closed,6,new feature allowing accessing records/text from Wikipedia other than namespace 0
219,2019-01-03 07:23:02.000000000,2019-01-08 19:35:59.000000000,closed,3,New feature allowing working with Wikinews media dumps
218,2018-12-21 22:26:58.000000000,2018-12-21 22:27:28.000000000,closed,2,"numpy.ufunc has the wrong size, try recompiling"
217,2018-12-15 19:41:09.000000000,2019-01-05 03:33:35.000000000,closed,1,fix small typo
216,2018-12-02 18:49:36.000000000,2018-12-03 00:40:40.000000000,closed,2,Issue with Numpy on Ubuntu 18.04
215,2018-11-29 23:09:17.000000000,2018-12-03 00:35:21.000000000,closed,1,GroupVectorizer- NameError: name 'doc_term_matrix' is not defined
214,2018-11-27 15:46:35.000000000,2018-11-27 15:47:33.000000000,closed,0,split
213,2018-11-08 01:03:32.000000000,2019-07-15 04:06:22.000000000,closed,2,Termite Plot cropping words
212,2018-08-24 15:49:10.000000000,2019-03-11 20:28:42.000000000,closed,1,Guide to getting started to contribute
211,2018-08-21 07:19:32.000000000,2019-03-08 03:33:42.000000000,closed,3,ValueError: `terms` = [] is invalid; it must contain at least 1 term in the form of a string or spacy token
210,2018-08-21 02:59:42.000000000,2019-06-28 20:50:09.000000000,closed,1,UnicodeDecodeError: 'ascii' codec can't decode byte...
209,2018-08-19 00:29:02.000000000,2018-08-20 21:43:35.000000000,closed,3,"Newbie question: Try to follow example,  but fails after run."
208,2018-08-14 19:24:31.000000000,1970-01-01 00:00:00.000000001,open,0,doc.to_bag_of_terms return empty items in docker
207,2018-08-08 19:21:00.000000000,2020-03-02 04:20:37.000000000,closed,1,"Corpus.load() gives ""buffer source array is read-only"" error"
206,2018-07-24 18:40:09.000000000,2019-07-02 11:49:21.000000000,closed,4,Segmentation fault importing textacy
205,2018-07-15 07:33:44.000000000,2018-07-17 03:13:08.000000000,closed,1,Local variable 'spacy_lang' referenced before assignment
204,2018-06-28 01:41:25.000000000,2018-07-10 22:28:22.000000000,closed,4,corpus.add_texts multithreading/processing broken with spaCy 2.0.x
203,2018-06-20 21:07:40.000000000,2019-07-15 01:00:01.000000000,closed,3,GPL dependencies with requirements.txt
202,2018-06-18 11:19:30.000000000,2018-06-25 20:14:01.000000000,closed,1,"In named_entities i am specifying include_types=""DATE"",am getting error like (invalid `include_types` type: \""<class 'str'>\"") how to reslove this issue"
201,2018-06-18 05:40:37.000000000,2018-06-19 18:07:21.000000000,closed,1,Error importing Textacy 
200,2018-06-12 13:15:39.000000000,1970-01-01 00:00:00.000000001,open,1,An example of direct_quotations 
199,2018-06-11 18:31:03.000000000,2018-06-25 22:34:30.000000000,closed,2,'divrank' and 'bestcoverage'  not working
198,2018-06-01 16:59:07.000000000,1970-01-01 00:00:00.000000001,open,0,subject_verb_object_triples Enhancement
197,2018-05-03 10:46:57.000000000,2019-06-26 00:30:36.000000000,closed,1,strip_markup in textacy.datasets.wikipedia doesn't work as expected
196,2018-05-02 17:17:20.000000000,2018-05-07 00:07:12.000000000,closed,0,ZeroDivisionError on empty network
195,2018-04-26 12:52:58.000000000,1970-01-01 00:00:00.000000001,open,2,"Feature suggestion, advice wanted: Word Embedding Association Tests to report implicit bias in spaCy models"
194,2018-04-25 16:39:16.000000000,2018-04-25 17:31:27.000000000,closed,1,textacy.Vectorizer: TypeError: __init__() got an unexpected keyword argument 'weighting'
193,2018-04-25 16:03:29.000000000,2018-04-25 21:42:34.000000000,closed,2,module 'textacy.spacier' has no attribute 'utils'
192,2018-04-20 18:37:49.000000000,2018-04-20 21:06:52.000000000,closed,3,tf-idf score across corpus of original tweets but vetctorizer does not import
191,2018-04-13 12:17:17.000000000,2018-04-13 17:29:20.000000000,closed,1,Missing return statement
190,2018-04-12 03:08:09.000000000,2018-04-12 06:01:29.000000000,closed,1,Typo in apply_idf_weighting causing error
189,2018-04-09 17:30:52.000000000,2018-04-09 18:02:31.000000000,closed,1,Fix most_discriminating_terms in keyterms
188,2018-04-08 16:32:40.000000000,1970-01-01 00:00:00.000000001,open,0,How to limit subject-verb-object extraction to one output per row?
187,2018-04-08 03:12:50.000000000,2018-04-08 03:37:29.000000000,closed,0,"add custom pipeline components to new ""spacier"" sub-package"
186,2018-04-01 21:35:17.000000000,2018-04-01 22:12:27.000000000,closed,0,Improve installation and quickstart documentation
185,2018-03-28 01:12:06.000000000,2018-03-28 02:35:07.000000000,closed,6,create corpus from spacy docs?
184,2018-03-26 14:59:13.000000000,2018-04-08 16:33:03.000000000,closed,0,Extracting information while keeping an ID attached
183,2018-03-26 12:50:02.000000000,2019-05-18 21:57:29.000000000,closed,5,Better handling of corpus of 200k+ docs
182,2018-03-26 02:37:47.000000000,2018-03-26 04:09:11.000000000,closed,2,Cannot disable a spacy module
181,2018-03-25 22:51:00.000000000,2018-03-26 04:05:01.000000000,closed,2, 'spacy.tokens.doc.Doc' object has no attribute 'string' when extracting direct quotations
180,2018-03-23 17:45:55.000000000,2018-03-25 01:15:16.000000000,closed,1,Can't create corpus with non-parsed text
179,2018-03-23 07:18:00.000000000,1970-01-01 00:00:00.000000001,open,0,The named_entities option does not appear to work in to_terms_list
178,2018-03-21 20:34:55.000000000,2018-03-22 18:34:16.000000000,closed,1,deciding on the number of topics
177,2018-03-21 16:35:08.000000000,2018-03-22 17:56:49.000000000,closed,1,fixed typos in direct_quotations
176,2018-03-17 20:21:05.000000000,2018-03-22 18:42:13.000000000,closed,2,Help Needed in  key_terms_from_semantic_network
175,2018-03-14 21:31:13.000000000,2018-03-24 23:44:11.000000000,closed,4,[ISSUE #174] Getting categories for German and French
174,2018-03-13 14:48:42.000000000,2018-03-25 00:04:16.000000000,closed,6,Wikipedia category extraction for non-English languages
173,2018-03-10 20:27:08.000000000,2018-03-26 14:59:30.000000000,closed,2,Subject-verb-object extraction example.
172,2018-03-03 15:56:00.000000000,2018-03-22 18:58:28.000000000,closed,3,[Question] Corpus handling
171,2018-03-01 03:39:18.000000000,1970-01-01 00:00:00.000000001,open,3,Context for ngrams?
170,2018-02-28 14:24:35.000000000,2018-03-01 08:25:24.000000000,closed,3,After I install textacy. the Spacy is broken.
169,2018-02-26 23:52:31.000000000,2019-06-26 00:51:44.000000000,closed,2,to_bag_of_terms(named_entities=False) doesn't exclude named entities 
168,2018-02-26 18:06:31.000000000,2018-04-09 02:09:01.000000000,closed,6,Idea: spaCy pipeline components for textacy features
167,2018-02-23 09:37:25.000000000,2018-02-25 05:37:49.000000000,closed,0,Improve `vsm` module
166,2018-02-21 15:53:44.000000000,2019-06-28 20:54:41.000000000,closed,3,Wikipedia.texts() does not strip some HTML and CSS
165,2018-02-17 17:13:08.000000000,2018-02-17 21:51:21.000000000,closed,2,QUESTION: Get POS tags quickly out of doc.pos_tagged_text
164,2018-02-15 19:22:19.000000000,2018-02-15 20:03:52.000000000,closed,2,"Regarding a closed issue  #162, having question after testing"
163,2018-02-13 20:35:18.000000000,2018-02-13 20:46:25.000000000,closed,0,Improve `network` module
162,2018-02-12 19:32:06.000000000,2018-02-13 08:35:03.000000000,closed,2,Index of each n-gram in the original text when extracted by textacy.extract.ngrams with filter_stops or  filter_punct are TRUE
161,2018-02-12 11:21:45.000000000,2018-02-13 19:06:38.000000000,closed,4,how to get entity types for the list(doc)  after using named_entities( ) method in textacy
160,2018-01-31 00:46:52.000000000,2018-02-13 21:10:30.000000000,closed,2,Serious lack of examples and how-tos
159,2018-01-23 22:03:57.000000000,1970-01-01 00:00:00.000000001,open,3,Question: blacklining
158,2018-01-18 21:41:53.000000000,2018-01-18 21:54:19.000000000,closed,0,Add lang-dependent Flesch Reading Ease text stat
157,2018-01-18 17:30:59.000000000,2018-01-19 04:36:20.000000000,closed,2,extract.ngrams returns wrong bigrams
156,2018-01-16 04:10:50.000000000,2018-01-16 09:52:29.000000000,closed,0,Add flexible group-term-matrix vectorization class
155,2018-01-15 22:50:07.000000000,2018-01-18 21:48:05.000000000,closed,8,Use appropriate readability function depending on the used language.
154,2018-01-09 21:31:47.000000000,2018-04-22 20:55:25.000000000,closed,5,"Usage example fails on Supreme Court texts, even with tons of RAM"
153,2018-01-06 02:49:49.000000000,2018-01-06 02:54:17.000000000,closed,1,fixed the basic example
152,2018-01-06 02:42:04.000000000,2018-01-06 02:52:01.000000000,closed,3,AttributeError: module 'textacy' has no attribute 'io'
151,2018-01-02 08:43:53.000000000,2018-01-02 09:17:19.000000000,closed,0,Refactor and improve fileio (now io) subpackage
150,2018-01-01 02:58:30.000000000,2019-06-28 20:52:09.000000000,closed,4,Memory leak when repeatedly calling doc.count() over a large corpus
149,2017-12-26 16:05:07.000000000,2017-12-27 22:39:05.000000000,closed,2,keyterms not available in version 0.5.0
148,2017-12-12 20:15:19.000000000,2017-12-13 19:59:52.000000000,closed,4,STOPWORDS in Topic Modelling
147,2017-12-11 21:19:57.000000000,2017-12-11 22:39:26.000000000,closed,1,Textacy unable to create corpus from a textacy.doc.Doc class
146,2017-12-09 03:11:22.000000000,2017-12-09 05:57:50.000000000,closed,3,NameError: name 'Vectorizer' is not defined
145,2017-12-04 15:51:07.000000000,1970-01-01 00:00:00.000000001,open,1,Help: sort keywords into pre-defined topics / categories
144,2017-11-29 01:08:52.000000000,2017-11-29 08:08:45.000000000,closed,0,Add spacy-inspired CLI for downloading datasets
143,2017-11-25 03:39:10.000000000,2017-11-26 02:42:46.000000000,closed,2,textacy.datasets.RedditComments failed to download.
142,2017-11-22 10:19:47.000000000,2017-12-01 19:48:24.000000000,closed,2,Make textacy compatible with spacy v2.0
141,2017-11-15 17:25:36.000000000,2017-12-03 02:05:00.000000000,closed,4,Upgrade to spacy 2.x
140,2017-11-10 17:29:15.000000000,2018-04-03 06:26:43.000000000,closed,1,sgrank extremely slow or unresponsive on large text
139,2017-11-05 15:57:44.000000000,2017-11-15 19:28:45.000000000,closed,2,textacy and utf8
138,2017-10-27 19:33:26.000000000,2017-11-19 03:14:02.000000000,closed,2,emotional_valence() directory error
137,2017-10-25 00:21:15.000000000,2017-10-25 06:11:16.000000000,closed,2,Bug in replace_currency_symbols
136,2017-10-24 01:07:41.000000000,2018-04-24 04:34:08.000000000,closed,5,loading saved supreme court corpus causes an error
135,2017-10-24 00:59:05.000000000,2017-10-24 01:23:25.000000000,closed,2,keyword.textrank finds 0 keywords on short text
134,2017-10-23 23:32:49.000000000,2017-10-23 23:41:51.000000000,closed,3,Import parserfromhell
133,2017-10-19 20:04:30.000000000,2018-06-05 11:44:34.000000000,closed,13,Textacy with Jupiter
132,2017-09-26 20:45:41.000000000,1970-01-01 00:00:00.000000001,open,5,Extracted topics make no sense; might have something to do with unicodes
131,2017-09-25 13:29:59.000000000,2017-10-25 06:44:32.000000000,closed,5,Unexpected KeyError
130,2017-09-22 20:04:07.000000000,2017-09-27 15:56:03.000000000,closed,2,You can't perform that action at this time and can't fork
129,2017-09-01 18:52:03.000000000,2017-09-01 19:02:27.000000000,closed,1,Update api_reference.rst
128,2017-08-28 07:45:10.000000000,2017-08-29 19:48:43.000000000,closed,1,Add group to PHONE_REGEX for easier interpretation
127,2017-08-24 14:26:17.000000000,2017-08-29 19:01:54.000000000,closed,3,Conda installation not working correctly
126,2017-08-24 00:25:08.000000000,2017-08-24 01:24:36.000000000,closed,7,"can't install on mac os x, python 2.7"
125,2017-08-14 22:49:30.000000000,2018-01-19 09:28:08.000000000,closed,1,keyterms.sgrank() - python2 v. python3 discrepancies
124,2017-08-04 01:00:27.000000000,2017-08-29 19:25:20.000000000,closed,1,fixing corpus example
123,2017-08-04 00:30:56.000000000,2017-08-05 00:15:07.000000000,closed,3,"Error while running text_stream, metadata_stream = textacy.fileio.split_record_fields(records, 'text')"
122,2017-08-01 19:53:23.000000000,2017-08-29 19:23:16.000000000,closed,6,Error while importing textacy on virtualenv. I am using macosx and python installed in virtualenv.
121,2017-07-27 13:47:52.000000000,1970-01-01 00:00:00.000000001,open,2,Compute character index mapping for before `preprocess.normalize_whitespace`
120,2017-07-24 18:03:33.000000000,2017-07-25 19:45:19.000000000,closed,3,Change keyterms.most_discriminating_terms to use new vsm.Vectorizer class
119,2017-07-10 17:52:39.000000000,2017-07-10 18:19:21.000000000,closed,3,corpus loading error
118,2017-07-06 17:59:48.000000000,2017-07-25 21:28:20.000000000,closed,1,Update wikipedia.py
117,2017-07-02 19:27:52.000000000,1970-01-01 00:00:00.000000001,open,4,Add more code examples / tutorials
116,2017-07-02 02:47:51.000000000,1970-01-01 00:00:00.000000001,open,3,Anaphora resolution?
115,2017-06-24 04:20:53.000000000,1970-01-01 00:00:00.000000001,open,2,Question: Is it possible to save a Corporus to disk and then append or delete docs from it?
114,2017-06-24 04:12:12.000000000,2017-12-04 05:04:45.000000000,closed,1,Warning:  textacy is not able to load files written in python 3.5 from 3.6
113,2017-06-19 06:49:13.000000000,2017-06-22 01:34:58.000000000,closed,2,Add `Vectorizer` class to replace `vsm.doc_term_matrix` function
112,2017-06-15 01:40:28.000000000,2017-06-15 01:50:15.000000000,closed,0,"Refactor `corpora` subpkg into `datasets` subpkg, and add a new dataset to it"
111,2017-06-14 16:34:33.000000000,2017-06-16 00:30:30.000000000,closed,3,Fix terms overlap test in doc.to_terms_list
110,2017-06-13 22:25:27.000000000,2017-06-19 16:14:35.000000000,closed,8,Added the ability for vsm.doc_term_matrix to take an existing vocabulary
109,2017-06-09 13:09:21.000000000,2017-07-06 17:47:58.000000000,closed,2,Encoding UTF-8 on open_sesame
108,2017-06-03 00:50:35.000000000,2017-06-16 00:54:32.000000000,closed,2,enhancement for LDA models
107,2017-06-02 23:47:55.000000000,2017-06-02 23:57:31.000000000,closed,1,Warning: no model found for 'en'
106,2017-06-02 10:00:07.000000000,2017-06-06 10:23:16.000000000,closed,2,pip install fails in Fresh Virtualenv
105,2017-05-29 03:52:46.000000000,2017-05-29 19:46:08.000000000,closed,1,"IndexError in terms_to_semantic_network, need to check for empty term list"
104,2017-05-25 20:04:22.000000000,2017-05-27 01:20:28.000000000,closed,4,cannot import textacy in pycharm python console from remote host
103,2017-05-18 12:04:44.000000000,2017-05-26 17:11:21.000000000,closed,2,Python 2 : explicit about unicode for language
102,2017-05-14 07:26:23.000000000,2017-05-18 01:22:31.000000000,closed,6,termite plot squished
101,2017-05-14 02:46:10.000000000,2017-05-14 02:52:21.000000000,closed,0,Add Travis CI to repo
100,2017-05-13 08:47:49.000000000,2017-05-13 22:26:47.000000000,closed,2,DOC Add conda installation instructions.
99,2017-05-13 08:34:22.000000000,2017-05-13 21:01:47.000000000,closed,1,PY2 Add coding declaration to test file.
98,2017-05-11 23:13:16.000000000,2017-05-12 00:19:12.000000000,closed,5,Textacy Extract Example returns empty list
97,2017-05-10 03:04:57.000000000,2017-05-10 03:34:33.000000000,closed,6,Add custom stop_word list?
96,2017-05-10 01:21:07.000000000,2017-05-10 01:27:53.000000000,closed,1,"List of Docs to Corpus? More straight forward than ""streams""?"
95,2017-05-08 04:21:27.000000000,1970-01-01 00:00:00.000000001,open,0,cythonize certain modules for improved performance
94,2017-05-06 07:50:48.000000000,2017-05-14 00:00:25.000000000,closed,2, error: narrowing conversion 
93,2017-05-02 08:36:43.000000000,2017-05-04 06:33:08.000000000,closed,3,Listing all docs for topic
92,2017-04-28 22:24:46.000000000,2017-04-28 22:53:52.000000000,closed,1,Warning for readability when num sentences < 30
91,2017-04-28 05:16:23.000000000,2017-05-08 01:11:18.000000000,closed,4,no_punct disables doc.sents
90,2017-04-25 12:46:40.000000000,1970-01-01 00:00:00.000000001,open,0,True-casing words and sentences
89,2017-04-25 06:46:04.000000000,2017-04-25 06:51:00.000000000,closed,2,Textacy assuming 4 cpu cores are available
88,2017-04-24 11:48:36.000000000,2017-05-08 03:38:45.000000000,closed,2,Float division by zero (ZeroDivisionError) for flesch_kincaid_grade_level having n_words = 0
87,2017-04-19 15:39:45.000000000,2017-04-19 18:12:10.000000000,closed,4,the generated Documentation on readthedocs site is empty
86,2017-04-19 00:02:26.000000000,2017-04-19 00:10:28.000000000,closed,0,make cld2-cffi optional
85,2017-04-18 22:15:07.000000000,2017-04-19 00:10:28.000000000,closed,3,make cld2-cffi dependency optional
84,2017-04-14 22:40:15.000000000,2017-04-14 22:42:51.000000000,closed,3,AttributeError: module 'textacy.text_stats' has no attribute 'TextStats'
83,2017-04-14 12:52:58.000000000,2017-04-15 01:48:19.000000000,closed,2,No  input text in textacy.doc.Doc when written to file and read from file
82,2017-04-09 01:32:15.000000000,2017-04-16 00:35:22.000000000,closed,4,to_bag_of_terms method fails to find some expressions in document
81,2017-04-04 16:14:23.000000000,2017-12-04 05:13:18.000000000,closed,7,"textacy.Doc.load(content, lang=""en"") does not handle less common utf-8 characters well"
80,2017-04-03 19:01:03.000000000,2017-04-03 23:49:20.000000000,closed,2,readability_stats cannot process original SpaCy Doc since doc.lang is not set in spacy.Doc (it's actually doc.vocab.lang)
79,2017-04-03 08:41:46.000000000,2017-04-03 18:40:04.000000000,closed,2,Optional POS regular expression for sgrank method
78,2017-03-30 14:20:34.000000000,2017-03-31 06:04:15.000000000,closed,1,Question about the use of pagerank algorithm
77,2017-03-28 19:16:58.000000000,2017-04-01 23:40:05.000000000,closed,2,implemented readability index for german texts
76,2017-03-28 11:49:51.000000000,2017-03-28 19:55:50.000000000,closed,5,Returning empty list using Textacy sgrank automated keyterm retrieval
75,2017-03-26 08:18:26.000000000,2017-03-27 18:59:50.000000000,closed,3,Expose ngrams in sgrank method
74,2017-03-24 08:14:30.000000000,2017-03-29 21:36:23.000000000,closed,4,SGRank method tests observed and expected values make no sense
73,2017-03-23 18:29:40.000000000,2017-03-23 19:15:24.000000000,closed,3,preprocess_text Error: object of type 'float' has no len()
72,2017-03-18 10:02:10.000000000,2017-03-18 20:40:10.000000000,closed,2,"SGRank method crashes at ""low"" values of term co-occurence window size"
71,2017-03-17 23:16:06.000000000,2017-03-17 23:34:00.000000000,closed,2,Corpus.load throws exception when using an absolute path?
70,2017-03-17 21:03:57.000000000,1970-01-01 00:00:00.000000001,open,3,Phrase models vs n-grams in pre-processing
69,2017-03-17 02:23:36.000000000,2019-06-28 20:50:56.000000000,closed,5,TopicModel: infer topics for a new doc?
68,2017-03-16 06:38:47.000000000,2017-04-16 00:38:16.000000000,closed,6,Installation section of documentation needs dependency on spacy data added
67,2017-03-09 10:41:01.000000000,2017-04-25 16:55:36.000000000,closed,1,Issue while creating and loading large corpus
66,2017-03-08 10:13:12.000000000,2017-03-09 07:18:34.000000000,closed,3,Problem on to_terms_list method on readme
65,2017-03-04 23:57:07.000000000,2017-03-05 00:32:23.000000000,closed,5,"Add MANIFEST.in file to include docs, tests and dist files"
64,2017-03-02 16:54:44.000000000,2017-03-02 20:31:17.000000000,closed,1,Bugfix for the wiki_reader
63,2017-03-02 08:28:17.000000000,2017-03-02 09:28:11.000000000,closed,1,"Textacy is Apache-licensed, but has a dependency on fuzzywuzzy, a GPL lib"
62,2017-03-02 08:28:01.000000000,2017-03-09 02:01:48.000000000,closed,2,fuzzywuzzy is GPL
61,2017-02-17 18:37:05.000000000,2017-02-20 22:37:49.000000000,closed,1,Acronyms_and_definitions returns only 1st character of definition when passing in known defs
60,2017-02-03 21:46:09.000000000,2017-02-03 21:59:33.000000000,closed,1,How to add stopwords?
59,2017-01-28 22:34:42.000000000,2017-02-11 04:01:15.000000000,closed,3,New version to PyPI
58,2017-01-05 00:15:50.000000000,2017-01-05 21:42:06.000000000,closed,2,Empty string key term can be returned by textrank
57,2016-12-30 06:21:07.000000000,2017-01-03 21:31:38.000000000,closed,5,Unexpected behavior of to_bag_of_terms method
56,2016-12-21 18:37:14.000000000,2017-03-09 02:21:46.000000000,closed,5,can not load wikipedia files one the disk
55,2016-12-18 12:08:51.000000000,2016-12-20 04:53:06.000000000,closed,3,Unable to reproduce example in README
54,2016-12-12 03:04:52.000000000,2016-12-14 06:41:17.000000000,closed,3,added flexible token/span normalization; tweaks to keyterm functions
53,2016-12-07 02:12:54.000000000,2016-12-08 03:25:28.000000000,closed,10,inconsistency in handling lemmas/raw-text between corpus.word_doc_freqs and sgrank
52,2016-11-22 03:19:50.000000000,2016-11-22 03:33:27.000000000,closed,1,"Doc.save() writes to ""metadatas.json"" and ""spacy_docs.bin"""
51,2016-11-02 23:22:34.000000000,2016-11-16 00:12:23.000000000,closed,3,can not load wikipedia files one the disk
50,2016-11-02 21:15:16.000000000,2016-11-06 20:27:51.000000000,closed,2,Made matplotlib and backports.csv optional dependencies
49,2016-11-01 13:12:40.000000000,2016-11-06 20:28:06.000000000,closed,3,Import matplotlib locally
48,2016-10-28 19:54:50.000000000,2016-11-02 19:58:20.000000000,closed,12,ValueError: token is not POS-tagged
47,2016-10-14 14:30:32.000000000,2016-10-14 18:47:28.000000000,closed,1,SGRank issue
46,2016-10-13 21:19:32.000000000,2016-11-04 18:48:53.000000000,closed,3,Issues while loading corpus from disk.
45,2016-10-06 03:46:49.000000000,2016-10-06 18:41:39.000000000,closed,2,cachetools 2.0.0 breaks textacy
44,2016-09-23 20:18:42.000000000,2016-09-23 20:31:29.000000000,closed,1,keyterms function extract function parameters
43,2016-08-22 17:21:36.000000000,2016-08-22 17:29:42.000000000,closed,1,TextDoc.as_terms_list has not implemented the dedupe flag
42,2016-08-14 09:15:54.000000000,2016-08-16 19:24:56.000000000,closed,1,Please make it possible to comment on your bugs!
41,2016-08-14 09:13:00.000000000,2016-08-14 18:01:19.000000000,closed,0,Please make it possible to comment on your bugs!
40,2016-08-14 08:18:36.000000000,2016-08-23 01:25:26.000000000,closed,18,backports.lzma dependency in textacy
39,2016-08-12 22:00:16.000000000,2016-08-23 00:56:43.000000000,closed,1,"Refactor Doc and Corpus, Update corpora and extract functions, Improve Documentation"
38,2016-08-12 13:41:08.000000000,2016-08-12 18:06:54.000000000,closed,1,Accessing to the set of TextDoc based on the metadata in doc_term_matrix?
37,2016-08-10 18:18:08.000000000,2016-08-12 14:02:43.000000000,closed,1,Is the objects are available to be pickled  
36,2016-08-09 08:46:48.000000000,2016-08-09 21:01:07.000000000,closed,2,Bump CLD2 to 0.1.4
35,2016-08-07 00:52:50.000000000,2016-08-07 00:53:11.000000000,closed,0,Added delimited format fileio
34,2016-08-04 06:59:17.000000000,2016-08-09 21:01:19.000000000,closed,1,CLD2 outreach
33,2016-08-04 01:40:14.000000000,2016-08-04 17:35:17.000000000,closed,6,"lang_or_pipeline argument of textacy.TextCorpus.from_texts() does not accept 'en' or {'en', 'de'} per docstring"
32,2016-08-03 20:32:10.000000000,2016-08-03 20:32:38.000000000,closed,0,Added SupremeCourt corpus
31,2016-08-02 14:53:18.000000000,2016-08-11 01:27:01.000000000,closed,6,textacy.lexicon_methods.emotional_valence doesn't always work
30,2016-07-31 22:12:44.000000000,2016-07-31 22:13:51.000000000,closed,0,Added CapitolWords corpus
29,2016-07-27 00:13:20.000000000,2016-07-27 22:15:00.000000000,closed,2,Deleting TextDocs from a TextCorpus throws a TypeError
28,2016-07-20 19:39:15.000000000,1970-01-01 00:00:00.000000001,open,2,"more, better, and interactive(?) data viz"
27,2016-07-20 19:16:46.000000000,1970-01-01 00:00:00.000000001,open,8,"more, better example corpora"
26,2016-07-19 07:14:23.000000000,2016-07-25 20:49:26.000000000,closed,1,"compressed fileio, plus better py2/3 unicode/bytes compatibility"
25,2016-07-15 03:07:10.000000000,2016-07-15 03:56:47.000000000,closed,1,Failure to load depechemood on Python 2.7 due to unicode vs str bug
24,2016-07-14 21:44:16.000000000,2016-07-14 21:44:34.000000000,closed,0,most discriminating terms function
23,2016-06-30 02:25:34.000000000,2016-06-30 21:03:57.000000000,closed,1,Update index.rst
22,2016-06-25 21:09:37.000000000,2016-07-13 23:01:48.000000000,closed,0,"document, set, and string distance metrics"
21,2016-06-24 01:47:01.000000000,2016-06-24 18:22:03.000000000,closed,1,added save/load methods to TextDoc and TextCorpus
20,2016-06-23 18:54:49.000000000,2016-06-23 20:23:09.000000000,closed,12,Question: NER example
19,2016-06-17 22:44:25.000000000,2016-06-20 21:49:14.000000000,closed,12,fatal error C1083: Cannot open include file: 'stdint.h': No such file or directory 
18,2016-06-01 20:11:49.000000000,2016-06-20 20:32:28.000000000,closed,0,consistent corpora readers for reddit and wikipedia
17,2016-05-30 22:01:55.000000000,2016-06-02 04:30:55.000000000,closed,6,Textacy import error on Python Jupyter notebooks
16,2016-05-23 04:53:39.000000000,2017-04-19 00:30:48.000000000,closed,2,Lemma matching in extract.pos_regex_matches
15,2016-05-13 11:52:58.000000000,2016-06-01 18:27:52.000000000,closed,2,Truecasing words
14,2016-05-11 05:45:45.000000000,2016-05-11 18:45:53.000000000,closed,2,Update README.rst
13,2016-05-06 01:31:08.000000000,2016-06-20 20:32:42.000000000,closed,3,Reddit corpus reader?
12,2016-05-03 02:21:03.000000000,2016-05-05 01:22:56.000000000,closed,3,addition of the viz subpackage
11,2016-05-02 21:21:10.000000000,2016-05-04 23:51:38.000000000,closed,1,added (str) term cleaning function and tests
10,2016-04-28 22:04:55.000000000,2016-05-02 21:57:12.000000000,closed,0,"added Bernie & Hillary corpus, automatic downloading of resources"
9,2016-04-26 22:10:20.000000000,2016-05-06 00:18:37.000000000,closed,4,Flexibility to load spaCy from different data directory
8,2016-04-26 07:33:09.000000000,2016-04-26 18:26:50.000000000,closed,1,probably user error maybe readability_stats() error
7,2016-04-05 18:17:13.000000000,2016-04-11 18:39:34.000000000,closed,1,Readability stats use wrong word count due to stop list usage
6,2016-03-29 21:30:52.000000000,2016-04-11 18:33:29.000000000,closed,0,"topic modeling, document representations, lots of bugfixes, cleanup, and upgrades"
5,2016-03-20 08:23:23.000000000,2016-03-24 19:30:36.000000000,closed,37,cld2-cffi dependency
4,2016-02-24 08:23:18.000000000,2016-02-26 21:26:24.000000000,closed,3,added fileio subpackage for reading/writing content from/to disk
3,2016-02-21 23:41:34.000000000,2016-02-22 21:21:56.000000000,closed,1,"extract generators, merge spans, language matching, docstring miscellany"
2,2016-02-19 22:07:04.000000000,2016-02-20 20:49:56.000000000,closed,3,"Keyterms Error: Input terms must be strings or spacy Tokens, not <type 'unicode'>."
1,2016-02-18 03:02:38.000000000,2016-02-18 21:37:47.000000000,closed,2,"exporting textacy/spacy objects into ""third-party"" formats"
