id,created_at,closed_at,state,comments,title
2679,2020-08-25 18:39:03.000000000,2020-08-25 19:26:00.000000000,closed,0,implement tidyr::pivot_longer functionality for Spark data frame 
2678,2020-08-22 18:14:21.000000000,1970-01-01 00:00:00.000000001,open,0,Qubole + Arrow
2677,2020-08-22 10:34:22.000000000,2020-08-22 12:55:19.000000000,closed,2,skip 1 test case on databricks connect
2676,2020-08-22 03:13:26.000000000,2020-08-22 04:02:32.000000000,closed,0,made str_separate logic self-contained and other necessary refactors
2675,2020-08-21 22:28:43.000000000,2020-08-21 23:30:19.000000000,closed,0,set app name in shell args
2674,2020-08-21 22:23:45.000000000,2020-08-21 23:10:46.000000000,closed,0,code readability improvements
2673,2020-08-21 20:23:33.000000000,2020-08-21 23:30:19.000000000,closed,2,yarn-cluster not respecting application name
2672,2020-08-21 16:52:55.000000000,2020-08-21 17:28:28.000000000,closed,0,improve test reporting
2671,2020-08-20 23:22:31.000000000,1970-01-01 00:00:00.000000001,open,0,look into avro + db connect
2670,2020-08-20 23:16:40.000000000,1970-01-01 00:00:00.000000001,open,0,refactor some tidyr-related methods in sparklyr
2669,2020-08-20 22:59:58.000000000,1970-01-01 00:00:00.000000001,open,1,warn about duplicate values per key for pivot_wider.tbl_spark
2668,2020-08-20 21:58:49.000000000,2020-08-20 22:58:52.000000000,closed,0,implement tidyr::pivot_wider functionality for Spark data frame
2667,2020-08-20 18:58:49.000000000,1970-01-01 00:00:00.000000001,open,2,Failure when using dplyr's across
2666,2020-08-20 01:18:19.000000000,2020-08-22 10:17:26.000000000,closed,8,Disable avro read/write test on DB Connect
2665,2020-08-18 23:06:02.000000000,1970-01-01 00:00:00.000000001,open,0,explore possible modifications of JIT params for efficiency gain
2664,2020-08-18 16:47:29.000000000,2020-08-25 19:26:36.000000000,closed,1,re-export tidyr and dplyr functionalities following existing convention in reexports.R
2663,2020-08-17 16:18:53.000000000,1970-01-01 00:00:00.000000001,open,0,make `sdf_weighted_sample` functionality available through the dplyr interface
2662,2020-08-15 00:22:25.000000000,2020-08-15 00:22:53.000000000,closed,0,make .Rbuildignore and .gitignore technically correct
2661,2020-08-14 23:23:00.000000000,2020-08-14 23:53:32.000000000,closed,0,make `separate.tbl_spark` usable in Spark 2.4
2660,2020-08-14 23:11:14.000000000,2020-08-14 23:53:32.000000000,closed,0,make separate.tbl_spark compatible with Spark 2.4
2659,2020-08-13 22:40:52.000000000,2020-08-14 19:56:04.000000000,closed,1,avoid spark_read_compat_param name collision
2658,2020-08-13 20:30:53.000000000,2020-08-13 22:20:49.000000000,closed,0,revise unnest.tbl_spark error message
2657,2020-08-13 20:09:08.000000000,2020-08-14 19:57:31.000000000,closed,5,unnest.tbl_spark is buggy
2656,2020-08-13 19:46:17.000000000,2020-08-13 22:27:06.000000000,closed,1,ignore code cov upload failure in CI
2655,2020-08-13 17:31:53.000000000,1970-01-01 00:00:00.000000001,open,0,update therinspark.com
2654,2020-08-13 17:21:02.000000000,2020-08-13 17:33:57.000000000,closed,0,retry gateway ports query
2653,2020-08-13 12:18:35.000000000,2020-08-14 19:56:04.000000000,closed,4,Data frames being overwritten if the files being read from databricks mount have same filename
2652,2020-08-13 00:39:38.000000000,2020-08-13 16:17:15.000000000,closed,2,implement tidyr::unnest functionality for Spark data frame
2651,2020-08-12 18:49:57.000000000,2020-08-12 21:17:10.000000000,closed,2,join methods for tbl_spark
2650,2020-08-12 15:47:11.000000000,2020-08-25 19:27:27.000000000,closed,1,must replace '.' with '_' in column/table names for tidyr verbs working with Spark data frames
2649,2020-08-11 20:18:07.000000000,2020-08-11 21:43:42.000000000,closed,0,replace empty nested data with NAs
2648,2020-08-11 19:48:07.000000000,2020-08-12 21:18:51.000000000,closed,11,Leading periods in the `suffix` argument of `dplyr::inner_join` causes Spark error on column conflict
2647,2020-08-10 23:17:09.000000000,2020-08-11 19:17:09.000000000,closed,2,implement tidyr::nest functionality for Spark data frame
2646,2020-08-10 19:01:08.000000000,2020-08-14 23:25:30.000000000,closed,1,support sepate.tbl_spark in Spark 2.x
2645,2020-08-10 18:17:36.000000000,1970-01-01 00:00:00.000000001,open,0,more unit tests for `unite.tbl_spark` and `separate.tbl_spark`
2644,2020-08-10 18:03:38.000000000,1970-01-01 00:00:00.000000001,open,0,make sparklyr 1.4 functionalities accessible via UDF
2643,2020-08-10 18:00:52.000000000,1970-01-01 00:00:00.000000001,open,0,enable perl regex support for `separate.tbl_spark`
2642,2020-08-10 17:21:46.000000000,2020-08-10 17:36:20.000000000,closed,0,fix an issue with locating Livy jar file
2641,2020-08-08 19:22:15.000000000,2020-08-10 17:36:19.000000000,closed,3,Sparkly throws URISyntaxException when connecting to spark via Livy using spark 2.4
2640,2020-08-08 00:02:31.000000000,2020-08-10 16:14:25.000000000,closed,2,code format be gooder
2639,2020-08-07 18:36:01.000000000,2020-08-07 22:51:49.000000000,closed,1,implement tidyr::separate functionality for Spark data frame
2638,2020-08-05 23:42:20.000000000,1970-01-01 00:00:00.000000001,open,0,run sparklyr tests with RAPIDS enabled
2637,2020-08-05 22:32:45.000000000,2020-08-05 23:45:02.000000000,closed,0,implement tidyr::unite functionality for Spark data frame
2636,2020-08-05 21:39:28.000000000,2020-08-06 19:59:09.000000000,closed,1,unexpected behavior with dplyr arrange
2635,2020-08-04 23:52:53.000000000,2020-08-05 16:24:54.000000000,closed,0,implement dplyr verbs for accumulations in Spark SQL
2634,2020-08-04 20:12:39.000000000,1970-01-01 00:00:00.000000001,open,0,make 'remove embedded null' behavior configurable
2633,2020-08-04 20:06:53.000000000,1970-01-01 00:00:00.000000001,open,0,ignore embedded null when reading string from arrow
2632,2020-08-03 17:32:32.000000000,2020-08-05 23:43:56.000000000,closed,17,create spark_connect options for RAPIDS accelerator plugin
2631,2020-08-03 15:37:54.000000000,2020-08-05 23:43:56.000000000,closed,1,support nvidia hardware acceleration in sparklyr
2630,2020-07-31 21:52:56.000000000,2020-07-31 21:53:44.000000000,closed,0,Update package meta data
2629,2020-07-30 17:22:23.000000000,2020-07-30 17:30:49.000000000,closed,0,delete all pre-existing R binaries in CI workflow
2628,2020-07-29 20:12:44.000000000,2020-07-29 21:45:41.000000000,closed,3,delete any pre-existing R binary before running setup-r
2627,2020-07-29 19:18:00.000000000,2020-07-30 17:34:27.000000000,closed,6,fix CI workflow for R 3.2.5
2626,2020-07-29 19:06:04.000000000,2020-07-30 23:29:03.000000000,closed,3,support grepl usage in dplyr::filter for Spark connections
2625,2020-07-28 22:05:28.000000000,1970-01-01 00:00:00.000000001,open,4,call rstudioapi::translateLocalUrl() when applicable
2624,2020-07-28 19:58:57.000000000,2020-07-28 21:24:17.000000000,closed,1,update sampling iters for test-sdf-weighted-sampling-ext
2623,2020-07-28 17:16:16.000000000,2020-07-28 19:57:01.000000000,closed,2,additional test cases for sdf-weighted-sampling
2622,2020-07-25 01:07:13.000000000,2020-07-25 01:17:48.000000000,closed,1,Rebuild reference section
2621,2020-07-24 16:15:40.000000000,2020-07-24 16:59:15.000000000,closed,1,"Revert ""Rebuild html reference pages"""
2620,2020-07-24 16:07:10.000000000,2020-07-24 16:07:27.000000000,closed,0,Rebuild html reference pages
2619,2020-07-24 15:58:41.000000000,2020-07-24 15:58:56.000000000,closed,0,rebuild index.html for hugo
2618,2020-07-24 15:19:25.000000000,2020-07-24 15:40:17.000000000,closed,0,temporarily disable template specification in _pkgdown.yml and re-build html references
2617,2020-07-23 21:06:39.000000000,1970-01-01 00:00:00.000000001,open,1,get Spark web ui to work for rstudio.cloud
2616,2020-07-23 20:01:28.000000000,2020-07-24 15:12:10.000000000,closed,4,Error: not found: value LivyUtils
2615,2020-07-23 14:59:52.000000000,2020-07-23 16:48:15.000000000,closed,2,make test-sdf-weighted-sampling deterministic
2614,2020-07-23 14:47:40.000000000,2020-07-23 16:48:42.000000000,closed,1,simplify system deps for CI workflow
2613,2020-07-22 23:13:12.000000000,2020-07-23 11:41:12.000000000,closed,1,"print additional trouble-shooting tip for the ""sparklyr gateway not responding"" problem"
2612,2020-07-22 19:41:56.000000000,2020-07-23 11:41:12.000000000,closed,0,"if `spark_connect(...)` fails, then error message should suggest `options(sparklyr.log.console = TRUE)` as the next step for troubleshooting"
2611,2020-07-22 16:53:53.000000000,2020-07-23 16:49:08.000000000,closed,0,simplify system dependencies for .github/workflows/ci.yaml
2610,2020-07-22 16:31:51.000000000,2020-07-22 22:40:06.000000000,closed,4,"support http{,s} proxy and additional CURL options for Livy connections"
2609,2020-07-22 10:12:35.000000000,2020-08-03 18:32:18.000000000,closed,9,error to start spark_connect_gateway
2608,2020-07-21 17:27:02.000000000,2020-07-21 18:03:06.000000000,closed,0,fix a subtle bug in do_spark
2607,2020-07-21 14:02:40.000000000,2020-07-30 17:23:09.000000000,closed,5,Working with datasets within the Foreach-loop with sparklyr
2606,2020-07-17 17:51:01.000000000,2020-07-20 20:33:55.000000000,closed,6,implement efficient weighted random sampling with and without replacement for Spark DataFrame
2605,2020-07-15 11:28:32.000000000,2020-07-28 20:30:12.000000000,closed,1,Reference document on web is not exist
2604,2020-07-15 00:37:57.000000000,1970-01-01 00:00:00.000000001,open,2,Can't load table or copy data when arrow is enabled
2603,2020-07-14 09:00:04.000000000,2020-07-14 18:56:28.000000000,closed,2,Copy the dataframe to Spark not working!
2602,2020-07-13 08:03:00.000000000,1970-01-01 00:00:00.000000001,open,0,sparklyr Delta table read using Arrow (0.17.1) and spark_read_delta fails
2601,2020-07-10 22:54:44.000000000,1970-01-01 00:00:00.000000001,open,1,more sparklyr/pyspark benchmarks for common ml algorithms and other real-world big data workloads
2600,2020-07-10 22:30:27.000000000,2020-07-10 22:30:56.000000000,closed,0,increment patch version as suggested by CRAN
2599,2020-07-10 22:22:18.000000000,2020-07-22 22:40:06.000000000,closed,0,more granular http/https proxy settings and curl opts for livy connections
2598,2020-07-09 05:56:41.000000000,2020-08-13 17:33:57.000000000,closed,0,"random test failure with ""error: ignoring SIGPIPE signal"" on first spark_connect call"
2597,2020-07-09 05:53:41.000000000,2020-07-29 18:21:45.000000000,closed,2,support deserialization of MAP_ZIP_WITH return type
2596,2020-07-09 04:53:42.000000000,2020-07-10 16:58:22.000000000,closed,12,Support new higher order functions in spark 3.0
2595,2020-07-09 04:14:18.000000000,2020-07-09 04:14:33.000000000,closed,0,bump release version number
2594,2020-07-09 04:00:02.000000000,2020-07-09 04:11:01.000000000,closed,0,fix a bug with ordering of `.x` and `.y` parameters for lambda expression specified with a R formula in hof_* methods
2593,2020-07-08 22:31:01.000000000,2020-07-20 20:33:54.000000000,closed,0,"support the equivalent of `dplyr::sample_frac(..., weight = ...)` in sparklyr"
2592,2020-07-08 02:28:02.000000000,2020-07-20 20:33:54.000000000,closed,8,Error for the weight argument in dplyr::sample_frac
2591,2020-07-07 07:58:57.000000000,1970-01-01 00:00:00.000000001,open,2,Error using sparklyr spark_write_csv when writing into s3 bucket
2590,2020-07-06 20:47:17.000000000,2020-07-08 15:55:30.000000000,closed,7,Update test-serialization.R for arrow dev changes
2589,2020-07-05 10:20:40.000000000,2020-07-09 16:53:06.000000000,closed,1,dplyr mutate: Error: org.apache.spark.sql.AnalysisException: cannot resolve 'Name' given input columns:
2588,2020-07-04 08:39:27.000000000,1970-01-01 00:00:00.000000001,open,0,`call` must be a quoted call
2587,2020-07-01 05:53:00.000000000,2020-07-23 10:20:40.000000000,closed,8,Can not use sparklyr in RServe session
2586,2020-07-01 01:06:42.000000000,2020-07-29 18:23:46.000000000,closed,0,cross-post sparklyr 1.3 blog post to blogs.rstudio.com/ai
2585,2020-06-27 19:30:36.000000000,2020-06-27 21:15:07.000000000,closed,1,fix CRAN warning on collect.Rd
2584,2020-06-27 05:29:01.000000000,2020-06-27 05:29:32.000000000,closed,0,update feature/sparklyr-1.3.0
2583,2020-06-27 03:16:11.000000000,2020-06-27 05:27:53.000000000,closed,10,sparklyr-3.0.0-preview-2.12.jar => sparklyr-3.0-2.12.jar and other minor changes before CRAN submission
2582,2020-06-27 01:12:46.000000000,2020-06-27 05:27:53.000000000,closed,0,must also replace 3.0.0-preview2 with 3.0.0 in default spark_compilation_spec before CRAN submission
2581,2020-06-26 22:30:54.000000000,2020-06-26 22:33:36.000000000,closed,0,update spark-connections.Rd
2580,2020-06-26 21:42:50.000000000,2020-06-26 21:43:27.000000000,closed,0,feature/sparklyr 1.3.0
2579,2020-06-26 21:41:01.000000000,2020-06-26 21:41:51.000000000,closed,0,update release branch with latest changes
2578,2020-06-24 21:55:27.000000000,2020-06-26 21:46:09.000000000,closed,5,compare absolute errors instead of relative errors
2577,2020-06-24 19:44:46.000000000,2020-06-24 20:43:25.000000000,closed,1,handle custom scala_version correctly in all places
2576,2020-06-23 16:35:40.000000000,2020-06-23 16:36:07.000000000,closed,0,delete irrelevant log file
2575,2020-06-22 21:41:47.000000000,2020-06-23 12:09:11.000000000,closed,2,replace spark master with 3.0.0 in CI workflow
2574,2020-06-22 20:58:48.000000000,2020-08-05 15:04:57.000000000,closed,0,spark-3-specific features in sparklyr
2573,2020-06-22 20:54:45.000000000,2020-06-22 20:55:09.000000000,closed,0,update Spark versions URL
2572,2020-06-22 20:47:36.000000000,2020-06-22 20:48:57.000000000,closed,0,add spark 3.0 version entry
2571,2020-06-22 20:35:36.000000000,2020-06-27 01:10:30.000000000,closed,0,replace Spark 3.0.0-preview2 with Spark 3.0.0 in CI workflow
2570,2020-06-22 20:06:14.000000000,2020-06-23 18:59:26.000000000,closed,4,support spark 2.4 built with scala 2.12
2569,2020-06-22 17:34:50.000000000,2020-06-22 19:38:39.000000000,closed,3,build sparklyr 2.4 jar file with scala 2.12
2568,2020-06-22 16:33:41.000000000,2020-06-22 17:30:18.000000000,closed,1,avoid distributing jar files that are available in maven central
2567,2020-06-22 15:27:17.000000000,2020-06-23 18:59:26.000000000,closed,0,correctly handle spark 2.4.4 built with scala 2.12
2566,2020-06-22 11:36:26.000000000,2020-06-22 12:00:11.000000000,closed,1,update livy branch to 'feature/sparklyr-1.3.0'
2565,2020-06-16 23:11:23.000000000,2020-06-16 23:59:27.000000000,closed,1,ensure additional sparklyr extension repositories are handled correctly
2564,2020-06-16 18:01:01.000000000,2020-06-16 22:26:14.000000000,closed,6,minor changes to test cases
2563,2020-06-16 00:48:46.000000000,2020-06-16 02:58:13.000000000,closed,4,avoid floating point error in Date type serialization
2562,2020-06-12 19:42:48.000000000,2020-06-12 20:18:06.000000000,closed,1,use spark_version_from_home() for avro if version is NULL
2561,2020-06-11 01:04:13.000000000,2020-06-12 20:18:06.000000000,closed,1,"spark-avro version issue with `spark_connect(..., package = ""avro"")`"
2560,2020-06-10 03:36:27.000000000,1970-01-01 00:00:00.000000001,open,0,"maybe still enable Arrow in `spark_apply(..., fetch_result_as_sdf = FALSE)` use case (?)"
2559,2020-06-05 20:41:21.000000000,2020-06-05 20:42:27.000000000,closed,0,explain speculative execution may need to duplicate writes in spark_write
2558,2020-06-05 19:42:06.000000000,2020-06-05 20:26:50.000000000,closed,3,spark_write example
2557,2020-06-05 13:32:49.000000000,2020-06-05 14:10:51.000000000,closed,2,delete tab characters & fix indentation in do_spark.R
2556,2020-06-04 15:09:37.000000000,1970-01-01 00:00:00.000000001,open,2,how to interpret the output of ml_lda() ?
2555,2020-06-04 01:27:16.000000000,2020-06-04 21:26:34.000000000,closed,4,Upgrade databricks-connect pip package to 6.5.1 in CI
2554,2020-06-03 21:26:06.000000000,2020-06-04 15:05:32.000000000,closed,4,update_embedded_sources.R should also sync java/embedded_sources.R
2553,2020-06-03 21:07:04.000000000,2020-06-03 22:56:30.000000000,closed,5,Fix date type portability issues
2552,2020-06-03 20:51:18.000000000,2020-07-10 16:58:22.000000000,closed,3,support new built-in higher-order functions in Spark 3
2551,2020-06-03 19:06:13.000000000,2020-06-04 23:30:39.000000000,closed,9,support formula syntax in higher-order functions
2550,2020-06-02 21:46:46.000000000,2020-06-26 22:34:39.000000000,closed,18,NEWS.md update for sparklyr 1.3 release
2549,2020-06-02 19:28:27.000000000,1970-01-01 00:00:00.000000001,open,1,use protobuf to transport data from R to Spark faster
2548,2020-06-02 15:59:55.000000000,2020-06-04 23:30:39.000000000,closed,0,support formula as lambda expressions in hof_* methods
2547,2020-06-02 15:00:19.000000000,2020-06-02 19:56:22.000000000,closed,7,fix dplyr-related test failures
2546,2020-06-01 20:34:45.000000000,2020-06-03 20:54:34.000000000,closed,14,Fix date type portability issues
2545,2020-05-31 10:57:42.000000000,2020-07-14 18:09:06.000000000,closed,6,spark_connect() failed on C stack usage limit in RStudio but runs on Rterm
2544,2020-05-30 03:18:17.000000000,2020-06-10 10:50:29.000000000,closed,11,Add {arrow} to Suggests
2543,2020-05-29 23:13:22.000000000,2020-06-04 22:43:29.000000000,closed,5,test-serialization failure/warnings due to timezone
2542,2020-05-29 18:50:24.000000000,2020-06-26 22:34:39.000000000,closed,2,prepare for sparklyr 1.3 release
2541,2020-05-28 16:47:39.000000000,1970-01-01 00:00:00.000000001,open,8,Convert columns from binary to string kafka stream data
2540,2020-05-28 15:26:40.000000000,2020-05-28 16:06:16.000000000,closed,1,prefix calls to dplyr methods with dplyr:: for namespace disambiguation
2539,2020-05-27 17:15:51.000000000,2020-05-27 18:34:52.000000000,closed,3,[experimental] avoid csv overhead in dataframe serialization
2538,2020-05-27 02:25:33.000000000,2020-07-20 20:29:13.000000000,closed,1,Only apply arrow format env var for spark < 3
2537,2020-05-27 00:27:14.000000000,2020-06-01 14:38:20.000000000,closed,5,No tags for releases v1.1.0 or v1.2.0
2536,2020-05-26 23:35:35.000000000,2020-05-27 16:45:30.000000000,closed,1,Remove devel version entries in news file
2535,2020-05-26 16:06:47.000000000,2020-05-26 17:23:42.000000000,closed,1,improve embedded source out-of-sync error message
2534,2020-05-25 01:08:26.000000000,1970-01-01 00:00:00.000000001,open,1,Reading from kafka topic stops aggregation query from publishing into topic
2533,2020-05-23 03:31:02.000000000,2020-06-03 09:00:25.000000000,closed,29,Create jobj envs earlier for databricks connections
2532,2020-05-22 22:38:54.000000000,2020-05-24 16:28:27.000000000,closed,1,Skip unreliable tests on windows
2531,2020-05-22 20:50:29.000000000,1970-01-01 00:00:00.000000001,open,0,"Spark, Kafka Streaming Error"
2530,2020-05-22 16:34:21.000000000,2020-05-22 19:23:32.000000000,closed,5,revise appveyor.yml
2529,2020-05-22 16:33:22.000000000,2020-05-22 16:33:59.000000000,closed,0,revise appveyor.yml
2528,2020-05-22 15:28:21.000000000,2020-05-22 15:30:19.000000000,closed,0,revise appeyor.yml
2527,2020-05-21 18:54:59.000000000,2020-05-21 18:57:39.000000000,closed,0,update appveyor CI build URI
2526,2020-05-21 17:35:07.000000000,2020-05-21 18:19:05.000000000,closed,1,test case for accessing struct field within Spark SQL lambda
2525,2020-05-21 15:50:45.000000000,2020-05-21 19:25:16.000000000,closed,6,revise ci/install_r_dependencies.sh
2524,2020-05-20 21:33:49.000000000,2020-05-21 19:25:16.000000000,closed,0,"some tests skipped due to nycflights13, janeaustenr, etc being missing"
2523,2020-05-20 18:44:42.000000000,2020-05-20 19:29:52.000000000,closed,2,avoid unnecessary re-installation of R packages in CI workflow
2522,2020-05-20 14:21:55.000000000,2020-05-20 15:41:01.000000000,closed,1,update sparklyr development wiki page
2521,2020-05-20 11:02:29.000000000,1970-01-01 00:00:00.000000001,open,3,How to connect to remote Cassandra in sparklyr?
2520,2020-05-20 05:59:37.000000000,2020-05-20 11:03:23.000000000,closed,1,How to connect to remote Cassandra using sparkly?
2519,2020-05-20 03:26:58.000000000,2020-05-21 03:07:55.000000000,closed,8,Use arrow::write_to_raw and set local timezone as needed (fixes #2439)
2518,2020-05-20 02:29:22.000000000,2020-05-20 14:14:18.000000000,closed,2,Fix Javier's email
2517,2020-05-20 00:22:02.000000000,2020-05-20 00:22:17.000000000,closed,0,make validJobjs and toRemoveJobjs connection-specific
2516,2020-05-19 23:46:20.000000000,2020-05-20 19:29:52.000000000,closed,0,"cache devtools, covr, etc instead of re-installing them in each CI workflow"
2515,2020-05-19 22:20:47.000000000,2020-05-20 18:16:01.000000000,closed,8,make validJobjs and toRemoveJobjs connection-specific
2514,2020-05-19 19:27:58.000000000,2020-05-21 18:19:05.000000000,closed,2,work around some dbplyr::translate_sql limitations in hof_*
2513,2020-05-19 18:55:45.000000000,2020-05-21 18:19:46.000000000,closed,4,hof throwing parse exception inside of transform()
2512,2020-05-19 16:39:27.000000000,2020-05-20 15:42:13.000000000,closed,5,revise apply_config
2511,2020-05-19 16:39:24.000000000,2020-05-19 16:58:56.000000000,closed,2,lock spark_jobj bindings
2510,2020-05-19 15:54:55.000000000,2020-05-20 15:42:40.000000000,closed,6,[do not merge] debug object life cycle issues
2509,2020-05-18 21:16:04.000000000,2020-05-20 15:42:23.000000000,closed,2,retries on spark_connect
2508,2020-05-18 20:17:57.000000000,2020-05-18 20:51:39.000000000,closed,1,fix man/transform_sdf.Rd
2507,2020-05-18 20:11:54.000000000,2020-05-18 21:15:51.000000000,closed,1,use R version aliases in .ci.yaml
2506,2020-05-18 18:41:50.000000000,2020-05-18 19:52:27.000000000,closed,1,update R versions
2505,2020-05-18 17:11:42.000000000,2020-05-18 18:32:10.000000000,closed,2,enable WARNINGS_ARE_ERRORS
2504,2020-05-18 17:07:49.000000000,2020-05-18 18:29:11.000000000,closed,1,fix typo in spark_write_avro documentation
2503,2020-05-18 00:35:56.000000000,2020-05-20 04:29:40.000000000,closed,6,Setting maxRecordsPerBatch when using Arrow and spark_apply does not work as expected
2502,2020-05-17 09:16:09.000000000,2020-05-17 10:06:39.000000000,closed,1,FindFileOwnerAndPermission error (1789)
2501,2020-05-15 22:57:14.000000000,2020-05-18 16:59:35.000000000,closed,7,avro transform methods for Spark Dataframe columns
2500,2020-05-15 20:35:43.000000000,2020-05-18 18:44:35.000000000,closed,0,fix spark_write_avro documentation
2499,2020-05-15 18:56:01.000000000,2020-05-15 19:38:52.000000000,closed,2,retry gateway info query with exponential backoff
2498,2020-05-15 15:37:28.000000000,2020-05-15 17:54:36.000000000,closed,3,implement spark_write_avro
2497,2020-05-14 22:46:31.000000000,2020-05-15 01:56:17.000000000,closed,1,[DONOTMERGE]Testing DB CI 
2496,2020-05-14 21:50:01.000000000,2020-05-14 21:50:45.000000000,closed,0,update test/livy branch with recent changes
2495,2020-05-14 21:24:05.000000000,2020-05-15 12:53:30.000000000,closed,5,implement spark_read_avro
2494,2020-05-14 16:03:58.000000000,2020-05-14 17:55:27.000000000,closed,0,make stack trace available before abort_shell
2493,2020-05-13 21:58:46.000000000,2020-05-14 12:41:55.000000000,closed,0,make ml-evaluate work on all supported spark versions
2492,2020-05-13 21:19:21.000000000,2020-05-13 21:51:25.000000000,closed,0,close gateway socket in terminate()
2491,2020-05-13 17:30:11.000000000,2020-05-13 20:47:33.000000000,closed,1,wait for backend to fully shutdown in spark_disconnect
2490,2020-05-13 16:52:35.000000000,2020-05-14 12:42:33.000000000,closed,0,workaround for spark disconnect race condition
2489,2020-05-13 14:32:50.000000000,2020-05-13 16:52:22.000000000,closed,0,fix spark disconnect race condition
2488,2020-05-12 23:02:36.000000000,2020-05-12 23:03:11.000000000,closed,0,update days-until-stale threshold
2487,2020-05-12 22:53:45.000000000,2020-05-13 02:30:12.000000000,closed,1,ml_evaluate() for classification models
2486,2020-05-12 22:47:35.000000000,2020-05-12 22:49:37.000000000,closed,0,create stale.yml
2485,2020-05-12 21:09:39.000000000,2020-05-12 22:25:35.000000000,closed,5,add embedded R sources verification step to CI workflow
2484,2020-05-12 20:14:29.000000000,2020-05-12 20:56:59.000000000,closed,1,Boolean -> AtomicBoolean
2483,2020-05-12 20:10:57.000000000,2020-05-12 20:58:01.000000000,closed,4,add embedded R sources verification step to CI workflow
2482,2020-05-12 18:07:42.000000000,2020-05-12 18:53:48.000000000,closed,1,create scripts to efficiently update and verify embedded sources
2481,2020-05-12 17:59:11.000000000,2020-05-12 18:48:58.000000000,closed,1,rename ci script to .ci.R
2480,2020-05-12 17:43:22.000000000,2020-05-12 17:51:28.000000000,closed,0,skip spark-apply nested list test on databricks connect
2479,2020-05-11 21:07:04.000000000,2020-05-12 17:49:08.000000000,closed,3,include embedded R source as resource within sparklyr jar file
2478,2020-05-11 17:36:17.000000000,2020-05-11 17:36:36.000000000,closed,0,fix minor typo
2477,2020-05-11 17:07:42.000000000,2020-05-11 17:12:06.000000000,closed,0,fix dplyr higher-order-function documentation
2476,2020-05-11 15:11:53.000000000,2020-05-11 15:48:14.000000000,closed,0,fix spark_read documentation
2475,2020-05-11 14:47:41.000000000,2020-05-11 14:59:38.000000000,closed,0,support transformation returning nested lists for spark_apply
2474,2020-05-11 14:34:43.000000000,2020-05-11 15:48:14.000000000,closed,0,fix spark_read documentation
2473,2020-05-08 14:59:32.000000000,2020-05-13 21:51:25.000000000,closed,0,race condition with spark_connect followed by spark_disconnect
2472,2020-05-08 13:36:38.000000000,1970-01-01 00:00:00.000000001,open,5,"spark_apply returns Error in file(con, ""r"").... Permission denied"
2471,2020-05-08 13:04:16.000000000,1970-01-01 00:00:00.000000001,open,0,Error with ft_chisq_selector and ml_cross_validator
2470,2020-05-07 20:19:05.000000000,2020-05-07 21:16:26.000000000,closed,2,custom Spark Dataframe writer
2469,2020-05-07 00:18:06.000000000,2020-05-07 21:00:46.000000000,closed,1,look into sparkxgb upgrade path
2468,2020-05-06 23:05:26.000000000,1970-01-01 00:00:00.000000001,open,0,avoid code duplication among scala files
2467,2020-05-06 23:03:35.000000000,2020-05-12 17:49:08.000000000,closed,0,store embedded sources as resource within jar files
2466,2020-05-06 22:56:52.000000000,2020-05-06 22:57:17.000000000,closed,0,merge master with test/livy
2465,2020-05-06 21:25:59.000000000,2020-05-06 23:29:43.000000000,closed,3,Allow hive support to be disabled
2464,2020-05-06 19:51:54.000000000,2020-05-06 19:52:17.000000000,closed,0,support partition index as a named parameter of spark_apply transform function
2463,2020-05-06 18:40:00.000000000,2020-05-06 18:40:23.000000000,closed,0,merge recent changes to the test/livy branch
2462,2020-05-06 16:40:12.000000000,2020-05-06 19:55:56.000000000,closed,2,[WIP][do-not-merge] try to see if we can allow user to opt out of hive integration and still use most functionalities in sparklyr
2461,2020-05-06 02:35:04.000000000,2020-05-06 22:22:47.000000000,closed,13,support partition index as a named parameter of spark_apply transform function
2460,2020-05-05 22:26:34.000000000,2020-05-06 23:30:21.000000000,closed,4,Hive is being forced in 1.2.0
2459,2020-05-05 06:14:26.000000000,2020-05-07 14:07:08.000000000,closed,1,support Spark SQL higher order functions through dplyr
2458,2020-05-05 03:09:58.000000000,2020-05-05 03:50:18.000000000,closed,2,Kryo serialiser failed to work on sparklyr 1.2.
2457,2020-05-04 23:55:23.000000000,2020-05-04 23:56:30.000000000,closed,0,remove travis CI badge
2456,2020-05-04 22:56:16.000000000,2020-05-05 02:07:25.000000000,closed,7,ml_evaluate() for clustering models
2455,2020-05-04 13:18:49.000000000,2020-05-12 19:00:09.000000000,closed,4,filter is not working inside for loop in sparklyr
2454,2020-05-03 21:06:19.000000000,2020-05-05 03:26:04.000000000,closed,1,Support for partitionId under barrier execution
2453,2020-05-01 16:54:38.000000000,2020-05-05 02:08:18.000000000,closed,7,enable custom file reader to run on workers
2452,2020-04-30 22:00:17.000000000,2020-05-04 19:22:01.000000000,closed,17,revise arrow-related github CI workflows
2451,2020-04-30 17:38:28.000000000,1970-01-01 00:00:00.000000001,open,0,stream_write_orc file sinks not readable with spark_read_orc
2450,2020-04-29 23:11:31.000000000,2020-04-30 21:40:17.000000000,closed,6,support returning arbitrary objects from spark apply function
2449,2020-04-29 22:42:05.000000000,2020-04-30 10:52:12.000000000,closed,2,spark_apply avoid infer schema
2448,2020-04-29 16:39:59.000000000,2020-04-29 19:01:01.000000000,closed,1,"spark_write_jdbc - error ""Unsupported type for serialization"""
2447,2020-04-28 17:46:49.000000000,2020-05-04 13:59:55.000000000,closed,9,Sparklyr + Error in spark_install_find
2446,2020-04-27 23:03:31.000000000,2020-04-27 23:27:05.000000000,closed,0,change livy test branch
2445,2020-04-27 21:08:07.000000000,2020-04-27 21:08:38.000000000,closed,0,revise news.md
2444,2020-04-27 15:34:23.000000000,2020-05-12 22:31:27.000000000,closed,5,Connect R with Kafka Stream
2443,2020-04-24 06:29:04.000000000,2020-08-04 23:33:58.000000000,closed,8,Failed while connecting to sparklyr to port (8880) on GCP ubuntu instance
2442,2020-04-24 06:16:42.000000000,2020-04-24 08:46:49.000000000,closed,1,Add support to collect SeqWrapper
2441,2020-04-24 04:20:32.000000000,2020-04-24 08:46:51.000000000,closed,0,Spark function returning SeqWrapper object is not converted to an array or list
2440,2020-04-24 01:16:08.000000000,2020-04-24 02:34:39.000000000,closed,1,[DB Connect] Some minor cleanup of Jenkinsfile
2439,2020-04-24 00:23:13.000000000,2020-05-21 03:07:56.000000000,closed,3,Set timezone when sending POSIXt data to Spark
2438,2020-04-23 05:17:19.000000000,2020-04-23 09:49:09.000000000,closed,5,Avoiding race-conditions on deleting test data on DBFS
2437,2020-04-23 02:13:24.000000000,2020-04-23 04:15:04.000000000,closed,11,Update DB Connect to 6.4.1 in CI
2436,2020-04-22 23:26:17.000000000,2020-04-28 15:23:45.000000000,closed,0,add a description of support for nested data to news.md
2435,2020-04-22 21:36:58.000000000,2020-04-22 22:31:06.000000000,closed,1,enable more basic tests on databricks connect
2434,2020-04-22 18:52:22.000000000,2020-04-27 22:55:01.000000000,closed,14,revise sparklyr.Utils.collect to read data row-by-row rather than column-by-column
2433,2020-04-22 16:49:14.000000000,2020-04-22 17:14:56.000000000,closed,2,re-generate and rebuild scala sources
2432,2020-04-20 15:32:23.000000000,2020-04-20 16:06:04.000000000,closed,1,prepare sparklyr for CRAN re-submission
2431,2020-04-19 03:13:35.000000000,2020-04-20 15:44:32.000000000,closed,1,Fix warnings for deprecated function
2430,2020-04-17 23:38:29.000000000,2020-04-22 18:03:24.000000000,closed,10,[WIP] optimize sdf collect
2429,2020-04-17 02:13:54.000000000,2020-04-17 11:25:53.000000000,closed,7,[DO NOT MERGE] Build Spark 2.4 jars with Scala 2.12
2428,2020-04-17 01:18:11.000000000,2020-05-22 16:13:46.000000000,closed,1,Build Spark 2.4 jars with Scala 2.12 
2427,2020-04-17 01:04:56.000000000,2020-04-17 06:18:46.000000000,closed,11,Dealing with S3 eventual consistency in Databricks CI
2426,2020-04-16 20:28:27.000000000,2020-04-16 20:54:45.000000000,closed,1,Fix skip_on_arrow()
2425,2020-04-16 19:21:17.000000000,2020-04-22 21:16:07.000000000,closed,6,enable some basic tests to run on Databricks connect
2424,2020-04-16 17:05:55.000000000,2020-04-16 18:07:19.000000000,closed,1,fix typo: get_simple_data_path -> get_sample_data_path
2423,2020-04-16 16:31:38.000000000,2020-04-22 21:16:07.000000000,closed,0,make test infra work better with Databricks
2422,2020-04-16 14:11:37.000000000,2020-04-17 01:28:40.000000000,closed,3,"Problem with Spark_apply not working with packages over Yarn cluster , only base r functions working "
2421,2020-04-16 02:58:56.000000000,2020-04-16 03:53:45.000000000,closed,3,Making Databricks CI logs accessible to community contributors
2420,2020-04-15 20:12:20.000000000,2020-04-16 16:52:29.000000000,closed,6,support deserializing struct types within arrays or nested arrays
2419,2020-04-15 16:37:05.000000000,2020-04-17 15:34:51.000000000,closed,3,deserialize array of Spark SQL structs correctly in sdf_collect
2418,2020-04-14 21:26:12.000000000,2020-04-14 21:26:40.000000000,closed,0,support installing Spark 2.4.5
2417,2020-04-14 20:30:04.000000000,2020-04-17 21:31:06.000000000,closed,8,attach expected output of the Databricks example in README.Rmd
2416,2020-04-14 20:01:24.000000000,2020-04-14 21:40:09.000000000,closed,0,add spark 2.4.5 to the list of available versions
2415,2020-04-14 19:38:29.000000000,2020-04-14 20:18:25.000000000,closed,0,switch spark_master to spark 3.0.0 preview2
2414,2020-04-14 18:58:26.000000000,2020-04-14 20:58:18.000000000,closed,0,creating release branch for sparklyr 1.2.0
2413,2020-04-14 17:14:45.000000000,2020-04-14 17:33:52.000000000,closed,3,creating release branch for sparklyr 1.2.0
2412,2020-04-14 16:43:59.000000000,2020-04-14 16:55:22.000000000,closed,1,update feature/sparklyr 1.2.0 to pick up some recent minor changes
2411,2020-04-14 13:10:46.000000000,2020-04-14 13:11:28.000000000,closed,0,Revise gitignore
2410,2020-04-13 15:24:15.000000000,2020-04-13 15:24:52.000000000,closed,0, re-generate docs/references/*.html and revise .gitignore
2409,2020-04-13 09:50:03.000000000,2020-04-15 22:06:03.000000000,closed,3,Unable to install spark on Slow Network 
2408,2020-04-11 21:40:16.000000000,1970-01-01 00:00:00.000000001,open,0,Consider creating spark_read_csv_options()
2407,2020-04-11 00:57:53.000000000,2020-04-13 16:18:23.000000000,closed,4,Fixing Databricks CI
2406,2020-04-10 22:17:48.000000000,2020-04-10 22:18:31.000000000,closed,0,fix possible typo in _pkgdown.yml
2405,2020-04-10 22:09:39.000000000,2020-04-10 22:10:17.000000000,closed,0,"add spark_{read,write}_delta to _pkgdown.yml"
2404,2020-04-10 19:34:37.000000000,2020-04-14 11:53:11.000000000,closed,1,deserialize Spark SQL StructTypes back to sensible R data structures
2403,2020-04-10 14:52:07.000000000,2020-04-10 14:53:53.000000000,closed,0,support for installing spark 3.0 preview 2 (#2402)
2402,2020-04-10 03:45:08.000000000,2020-04-10 14:48:03.000000000,closed,0,Support installing spark 3.0 preview 2
2401,2020-04-09 21:28:32.000000000,2020-04-10 06:38:26.000000000,closed,0,re-build html references
2400,2020-04-09 21:08:27.000000000,2020-04-14 21:33:54.000000000,closed,2,call enableHiveSupport in SparkSession builder
2399,2020-04-09 20:56:59.000000000,2020-04-10 06:36:32.000000000,closed,0,support printing spark context
2398,2020-04-09 17:18:59.000000000,2020-04-09 18:08:55.000000000,closed,0,change github workflow cache key
2397,2020-04-09 16:17:21.000000000,2020-04-09 16:55:41.000000000,closed,0,revise install_r_dependencies.sh
2396,2020-04-09 16:06:22.000000000,2020-04-09 17:26:42.000000000,closed,0,Avoid tar-ing all packages in spark-apply-bundle test
2395,2020-04-09 14:52:18.000000000,2020-04-09 16:13:28.000000000,closed,0,use actions/cache@master instead of @v1
2394,2020-04-09 14:43:09.000000000,2020-04-10 06:39:18.000000000,closed,0,include Spark 3.0.0 preview in spark_version_latest
2393,2020-04-09 04:44:22.000000000,2020-04-09 23:10:16.000000000,closed,0,Fake PR to test CI
2392,2020-04-08 17:28:57.000000000,2020-04-09 21:42:54.000000000,closed,1,make sdf_copy_to map list columns to Spark SQL structs
2391,2020-04-07 21:41:13.000000000,1970-01-01 00:00:00.000000001,open,3,Job freezes for no apparent reason
2390,2020-04-07 16:42:35.000000000,2020-04-07 16:44:36.000000000,closed,0,re-render readme md
2389,2020-04-07 16:10:06.000000000,2020-04-07 17:35:53.000000000,closed,3,spark_apply and data.table
2388,2020-04-07 03:11:59.000000000,2020-04-07 21:09:55.000000000,closed,0,fix minor issues with README.md
2387,2020-04-07 02:58:11.000000000,2020-04-07 02:59:05.000000000,closed,0,fix README.md
2386,2020-04-07 02:42:37.000000000,2020-04-07 02:46:22.000000000,closed,0,Fix readme md
2385,2020-04-07 02:34:41.000000000,2020-04-07 02:35:44.000000000,closed,0,update github workflow status badge
2384,2020-04-07 01:41:19.000000000,2020-04-07 01:41:46.000000000,closed,0,adding back docs that were missing
2383,2020-04-06 22:28:36.000000000,2020-04-06 22:28:51.000000000,closed,0,update README.md
2382,2020-04-04 21:01:59.000000000,2020-04-15 21:16:58.000000000,closed,0,sparklyr nested data -- see gitter.im
2381,2020-04-03 14:31:29.000000000,2020-05-15 19:38:52.000000000,closed,1,barrier spark-apply test sometimes fails
2380,2020-04-03 14:22:53.000000000,2020-04-03 15:57:09.000000000,closed,0,Do not cache arrow devel build artifacts
2379,2020-04-03 01:01:57.000000000,2020-04-03 14:05:07.000000000,closed,1,Fix summary() in ml_linear_regression when intercept = FALSE
2378,2020-04-02 23:17:06.000000000,2020-05-28 18:35:33.000000000,closed,2,"Failed during initialize_connection: Result 2 must be a single string, not a character vector of length 0"
2377,2020-04-02 18:17:20.000000000,2020-04-06 21:45:13.000000000,closed,0,Prepare for sparklr 1.2.0 release
2376,2020-04-02 16:06:03.000000000,2020-04-02 18:58:44.000000000,closed,0,create feature/sparklyr-1.2.0 release branch
2375,2020-04-02 15:56:56.000000000,2020-04-02 20:37:36.000000000,closed,0,Update feature branch for livy connection
2374,2020-04-02 15:40:15.000000000,2020-04-23 12:26:39.000000000,closed,6,support adls credential passthrough for databricks connections
2373,2020-04-01 23:40:51.000000000,1970-01-01 00:00:00.000000001,open,0,replace writing to tmp file with writing to fifo pipe in sdf_copy_to
2372,2020-04-01 19:08:09.000000000,2020-04-02 15:36:14.000000000,closed,0,tentative fix to address https://github.com/sparklyr/sparklyr/issues/2342 #2368
2371,2020-04-01 18:15:18.000000000,2020-04-22 15:56:10.000000000,closed,1,Release sparklyr 1.2.0
2370,2020-04-01 18:14:10.000000000,2020-05-04 19:22:01.000000000,closed,1,migrate arrow CI jobs to github action workflow
2369,2020-03-31 21:53:21.000000000,2020-04-11 04:02:55.000000000,closed,0,Add the dockerfile for jenkins server
2368,2020-03-31 20:56:07.000000000,2020-04-01 19:07:12.000000000,closed,0,tentative fix to address https://github.com/sparklyr/sparklyr/issues/2342
2367,2020-03-31 17:08:13.000000000,2020-03-31 20:48:52.000000000,closed,0,ensure test performance reporter does not cause test failure
2366,2020-03-30 23:07:54.000000000,2020-03-31 16:14:42.000000000,closed,1,fix serialization test failure
2365,2020-03-30 22:38:29.000000000,2020-03-31 16:14:42.000000000,closed,0,random serialization test failure
2364,2020-03-30 21:05:08.000000000,2020-03-31 16:18:01.000000000,closed,0,report the list of failed tests
2363,2020-03-30 20:47:34.000000000,2020-03-31 22:07:53.000000000,closed,0,fail with a more informative error message if the required network interface is not up
2362,2020-03-30 19:40:05.000000000,2020-03-31 16:20:20.000000000,closed,0,use jars from a test branch for testthat livy connections
2361,2020-03-30 16:48:35.000000000,2020-03-31 23:52:04.000000000,closed,1,comment out CI builds that are migrated to github action workflow
2360,2020-03-30 13:22:42.000000000,2020-03-30 13:26:16.000000000,closed,0,test
2359,2020-03-29 22:33:10.000000000,2020-05-01 17:20:36.000000000,closed,0,[do-not-merge] try to resolve compilation error for arrow 0.11 etc
2358,2020-03-28 19:08:49.000000000,2020-05-01 20:34:22.000000000,closed,1,spark_read_jdbc cannot convert column to integer error
2357,2020-03-27 21:42:01.000000000,2020-03-31 16:13:28.000000000,closed,2,sdf_copy_to error
2356,2020-03-27 16:41:30.000000000,2020-03-29 17:25:49.000000000,closed,0,github CI workflow
2355,2020-03-27 16:34:11.000000000,2020-03-27 16:34:28.000000000,closed,0,delete previous incomplete CI config
2354,2020-03-27 16:19:56.000000000,2020-03-27 16:22:44.000000000,closed,1,setup github CI workflow
2353,2020-03-27 15:53:27.000000000,2020-03-29 17:25:49.000000000,closed,0,migrate CI to github action
2352,2020-03-26 18:47:12.000000000,2020-05-15 12:53:29.000000000,closed,9,Read Avro Data in Kafka Stream
2351,2020-03-26 13:10:21.000000000,2020-03-26 13:13:40.000000000,closed,0,"Revert ""[experimental[ try to migrate CI to github action"""
2350,2020-03-26 05:48:58.000000000,2020-04-24 04:34:40.000000000,closed,0,Enable some broom tests and other tests that pass on DB Connect
2349,2020-03-25 21:33:45.000000000,2020-03-25 21:38:11.000000000,closed,0,[experimental[ try to migrate CI to github action
2348,2020-03-25 16:35:59.000000000,2020-03-26 13:45:11.000000000,closed,2,"merge a chain of invoke(...) calls into a single invoke(..., ""%>%"", ...) call"
2347,2020-03-25 15:57:36.000000000,1970-01-01 00:00:00.000000001,open,0,avoid calling invoke() in a loop if possible
2346,2020-03-25 05:35:49.000000000,2020-03-27 23:16:05.000000000,closed,4,Allow sdf_query_plan to also get analyzed plan
2345,2020-03-24 20:08:13.000000000,2020-03-27 15:05:35.000000000,closed,3,using hclust inside spark_apply
2344,2020-03-24 17:54:36.000000000,2020-03-25 01:51:34.000000000,closed,0,skip return status on jvm object deletions
2343,2020-03-24 17:21:38.000000000,2020-03-24 17:48:30.000000000,closed,0,revert debug-only change
2342,2020-03-24 15:20:12.000000000,1970-01-01 00:00:00.000000001,open,3,Cannot use credential passthrough on databricks
2341,2020-03-24 00:08:17.000000000,2020-03-24 16:34:29.000000000,closed,1,optimize jvm object deletions
2340,2020-03-23 22:04:44.000000000,2020-03-23 23:15:30.000000000,closed,0,delete duplicate scala source file
2339,2020-03-23 19:50:12.000000000,2020-05-12 22:37:58.000000000,closed,1,commit hook to block a commit if embedded source might be out of sync with actual R source file
2338,2020-03-23 19:41:22.000000000,2020-03-23 20:34:28.000000000,closed,0,delete unnecessary locking in JvmObjectTracker
2337,2020-03-20 23:12:06.000000000,2020-03-21 05:26:19.000000000,closed,0,implement suggested fix in #2328
2336,2020-03-20 22:39:16.000000000,1970-01-01 00:00:00.000000001,open,0,replace the hack in https://github.com/sparklyr/sparklyr/pull/2332 with something less hacky
2335,2020-03-20 22:22:07.000000000,2020-03-21 05:24:34.000000000,closed,0,ensure JVM object is alive during method invocation
2334,2020-03-20 21:17:50.000000000,2020-03-21 05:24:33.000000000,closed,1,JVM object might disappear before method invocation happens
2333,2020-03-19 23:28:33.000000000,2020-03-24 17:49:11.000000000,closed,3,Error initializing SparkContext
2332,2020-03-19 22:25:01.000000000,2020-03-20 22:36:34.000000000,closed,1,workaround for Rcpp 1.0.4 compilation failure with R 3.2
2331,2020-03-19 06:31:21.000000000,2020-03-19 06:39:36.000000000,closed,1,[do-not-merge-yet] avoid upgrading rcpp
2330,2020-03-19 05:34:11.000000000,2020-03-19 23:52:37.000000000,closed,0,replace deprecated SynchronizedMap with ConcurrentHashMap
2329,2020-03-19 04:52:36.000000000,2020-03-19 05:43:17.000000000,closed,1,[do-not-merge-yet] try running tests without stringi package
2328,2020-03-19 04:31:19.000000000,2020-03-21 05:26:19.000000000,closed,1,"""Unexpected end of input"" error when using spark_apply"
2327,2020-03-19 03:01:05.000000000,2020-03-19 19:06:57.000000000,closed,0,use tmpfs to reduce disk IOs in CI jobs
2326,2020-03-19 01:47:23.000000000,2020-03-20 22:36:34.000000000,closed,0,some tests failing with g++/gfortran compile-time errors
2325,2020-03-19 01:39:56.000000000,2020-03-23 16:56:49.000000000,closed,1,[experimental][do-not-merge] try to run some tests in parallel
2324,2020-03-18 23:47:30.000000000,2020-03-23 16:52:39.000000000,closed,1,fix a spark-3.0 compatibility issue when connecting to an existing spark session
2323,2020-03-18 04:53:21.000000000,2020-03-30 20:18:18.000000000,closed,1,Question: Arrow with Livy
2322,2020-03-18 04:43:19.000000000,2020-03-19 22:25:00.000000000,closed,1,Add local property for Databricks Connect
2321,2020-03-18 04:17:21.000000000,2020-03-23 16:52:39.000000000,closed,1,gateway connection is not working for spark 3.0.0-preview
2320,2020-03-17 19:23:47.000000000,1970-01-01 00:00:00.000000001,open,1,copy_to fails with databricks-connect 6.4.0
2319,2020-03-17 19:23:39.000000000,2020-03-18 19:52:21.000000000,closed,0,Add March 2020 committers
2318,2020-03-17 12:40:04.000000000,2020-05-12 18:32:31.000000000,closed,6,Best config of Sparklyr + Arrow
2317,2020-03-16 17:30:59.000000000,2020-03-16 20:02:33.000000000,closed,0,implement serialization for date types
2316,2020-03-12 23:59:05.000000000,2020-03-14 05:07:37.000000000,closed,0,fix a minor bug in spark dataframe's print method
2315,2020-03-12 21:55:34.000000000,2020-03-14 05:06:08.000000000,closed,1,Improve serialization and deserialization of date and timestamp types
2314,2020-03-12 18:24:37.000000000,2020-03-16 17:26:38.000000000,closed,0,sdf_collect turns timestamp / datetime values equal to 1970-01-01 into NAs
2313,2020-03-12 05:05:06.000000000,2020-03-16 20:34:00.000000000,closed,5,Type date becomes double after sdf_copy_to()
2312,2020-03-11 23:59:55.000000000,2020-03-13 00:39:59.000000000,closed,0,Copying local test files to Databricks cluster for tests
2311,2020-03-11 21:26:08.000000000,2020-03-12 07:40:01.000000000,closed,0,make test-ml-evaluation work for Spark master
2310,2020-03-11 19:34:03.000000000,2020-03-12 07:39:34.000000000,closed,0,make spark_submit work for spark 3.0.0-preview / master
2309,2020-03-11 12:08:10.000000000,2020-03-17 06:06:35.000000000,closed,5,Fix tests for DB connect with local data file
2308,2020-03-11 07:24:39.000000000,2020-03-13 01:48:06.000000000,closed,1,Fix unit tests that attempt to create tables that already exist
2307,2020-03-11 03:25:46.000000000,2020-03-13 01:48:06.000000000,closed,0,Fix unit tests that attempt to create tables that already exist
2306,2020-03-11 02:01:43.000000000,2020-03-11 20:07:08.000000000,closed,0,[WIP](do not merge) looking into test_submit failure on CI
2305,2020-03-10 22:58:54.000000000,2020-03-12 07:33:22.000000000,closed,0,delete skip_on_spark_master() calls in most tests
2304,2020-03-10 22:31:33.000000000,2020-03-10 22:51:39.000000000,closed,1,replace hive context with spark session for spark 3.0.0-preview
2303,2020-03-10 21:57:16.000000000,2020-03-12 07:32:46.000000000,closed,1,probable workaround for windows temp dir issues
2302,2020-03-10 21:44:26.000000000,2020-03-10 21:44:44.000000000,closed,0,Probable workaround for windows temp dir issues
2301,2020-03-10 21:38:21.000000000,2020-03-10 21:42:38.000000000,closed,0,Probable workaround for windows temp dir issues
2300,2020-03-10 21:23:19.000000000,2020-03-10 22:29:53.000000000,closed,0,replace hive context with spark session for spark 3.0.0-preview
2299,2020-03-10 08:57:21.000000000,2020-03-11 03:11:24.000000000,closed,0,"No need to set master when using `method = ""databricks""`"
2298,2020-03-09 20:42:26.000000000,2020-03-10 15:40:53.000000000,closed,0,improve broom-multilayer_perceptron test
2297,2020-03-09 20:36:34.000000000,1970-01-01 00:00:00.000000001,open,0,ml unit tests should include sanity checks on key metrics
2296,2020-03-09 18:40:48.000000000,2020-03-10 15:40:38.000000000,closed,1,adjust one test-invoke test case after scalac 2.12 behavior change
2295,2020-03-09 01:26:54.000000000,2020-03-16 23:41:28.000000000,closed,5,Error in force(code): Failed while connecting to sparklyr to port (8880) for sessionid (33366): Gateway in localhost:8880 did not respond.
2294,2020-03-08 14:11:42.000000000,2020-03-09 18:50:17.000000000,closed,0,fixing the issue I found in https://github.com/sparklyr/sparklyr/issu…
2293,2020-03-08 11:11:34.000000000,2020-03-09 02:03:38.000000000,closed,0,Enabling tests that pass with datbaricks-connect=6.3.1
2292,2020-03-07 10:31:32.000000000,2020-03-12 16:00:48.000000000,closed,3,AppVeyor failure in doSpark in Spark 2.4
2291,2020-03-07 05:00:23.000000000,2020-04-24 04:34:28.000000000,closed,0,"(Testing, do no merge)"
2290,2020-03-06 19:19:04.000000000,2020-03-07 01:56:07.000000000,closed,0,account for changes to the LDA method in Spark 3.0
2289,2020-03-06 16:24:18.000000000,2020-03-07 01:55:30.000000000,closed,0,adjust test-ml-feature-idf after hashing algorithm change in Spark 3.0.0
2288,2020-03-06 05:48:33.000000000,2020-04-16 02:57:42.000000000,closed,12,Posting Databricks Jenkins CI logs to github
2287,2020-03-06 03:02:27.000000000,2020-03-10 21:20:43.000000000,closed,3,replace hive context with spark session for spark 3.0.0-preview
2286,2020-03-06 01:13:36.000000000,2020-03-07 01:51:30.000000000,closed,0,fix broom gradient boosted trees test
2285,2020-03-05 23:34:09.000000000,2020-03-07 01:50:59.000000000,closed,0,fix serialization issues for missing values
2284,2020-03-05 05:24:07.000000000,2020-03-07 13:05:30.000000000,closed,1,Jenkins CI for Databricks Connection mode
2283,2020-03-05 02:13:50.000000000,2020-03-05 05:27:41.000000000,closed,0,Testing jenkins
2282,2020-03-05 00:18:42.000000000,2020-03-10 03:07:15.000000000,closed,12,WIP: Support for copy_to() in databricks connection
2281,2020-03-04 17:58:11.000000000,2020-03-04 20:28:04.000000000,closed,0,revise word2vec find synonyms test case
2280,2020-03-04 01:19:13.000000000,2020-03-04 02:17:36.000000000,closed,3,spark_apply and spark_write_avro are extremely slow
2279,2020-03-03 23:55:00.000000000,2020-03-04 02:27:37.000000000,closed,0,make ml-classification-naive-bayes work in both spark 2.4.4 and 3.0.0…
2278,2020-03-03 22:41:04.000000000,2020-03-04 02:27:14.000000000,closed,0,make test-broom-naive_bayes.R work for both spark 2.4.4 and 3.0.0-preview
2277,2020-03-03 17:14:50.000000000,2020-03-04 20:25:21.000000000,closed,0,append uuid to spark bundle filename
2276,2020-03-03 12:48:01.000000000,2020-07-14 18:09:41.000000000,closed,2,Spark 3.0
2275,2020-03-03 12:46:56.000000000,2020-08-05 15:03:53.000000000,closed,2,ggvis
2274,2020-03-03 12:42:52.000000000,2020-06-09 15:12:54.000000000,closed,6,Benchmarking
2273,2020-03-03 12:40:08.000000000,2020-08-03 10:15:52.000000000,closed,1,Engineering Improvements
2272,2020-03-03 12:35:41.000000000,1970-01-01 00:00:00.000000001,open,0,Hyperopt
2271,2020-03-02 16:43:01.000000000,2020-03-02 21:53:04.000000000,closed,0,make doSpark preserve error condition object from worker
2270,2020-03-02 15:49:54.000000000,2020-03-02 16:40:36.000000000,closed,0,make doSpark preserve error condition object
2269,2020-03-02 15:35:08.000000000,2020-03-02 21:52:03.000000000,closed,0,make do_spark workers load required packages
2268,2020-03-02 15:14:28.000000000,2020-03-02 21:50:47.000000000,closed,0,report doSpark number of workers
2267,2020-02-29 00:50:14.000000000,1970-01-01 00:00:00.000000001,open,0,How do transformers work in the context of k-fold cross validation?
2266,2020-02-28 23:01:47.000000000,2020-03-02 21:50:17.000000000,closed,4,wait for livy server socket to be in listening state before running test cases
2265,2020-02-28 01:17:34.000000000,2020-02-28 19:44:28.000000000,closed,1,"allow doSpark to support loop referencing external functions and variables"""
2264,2020-02-27 18:14:20.000000000,2020-03-09 20:28:33.000000000,closed,0,"`spark_apply(sdf, fn, columns = c(<schema>))` did not work as expected"
2263,2020-02-27 05:05:10.000000000,2020-04-07 04:59:03.000000000,closed,5,Can't connect to Kubernetes in cluster mode
2262,2020-02-26 20:53:36.000000000,2020-02-26 23:17:42.000000000,closed,1,[experimental][do_not_review] parallelize test runs
2261,2020-02-24 23:19:28.000000000,2020-02-25 23:16:25.000000000,closed,0,fix row.names
2260,2020-02-24 18:08:30.000000000,2020-02-27 00:08:13.000000000,closed,7,parallel backend for `foreach` using `spark_apply`
2259,2020-02-24 00:54:46.000000000,2020-03-17 17:06:44.000000000,closed,1,Failed while connecting to sparklyr to port (8880)
2258,2020-02-21 01:05:57.000000000,2020-03-16 19:19:13.000000000,closed,2,print more than 10 lines 
2257,2020-02-19 04:48:43.000000000,1970-01-01 00:00:00.000000001,open,1,BucketedRandomProjectionLSH
2256,2020-02-15 01:44:22.000000000,2020-02-19 05:47:18.000000000,closed,1,spark_apply unexpected behavior
2255,2020-02-07 04:16:51.000000000,2020-02-25 03:21:32.000000000,closed,1,[MINOR] Update NAMESPACE and add man file
2254,2020-02-07 04:10:23.000000000,1970-01-01 00:00:00.000000001,open,1,Add ft_robust_scaler
2253,2020-02-06 05:09:30.000000000,2020-02-06 10:59:57.000000000,closed,1,Support JDK11 for Spark 3
2252,2020-02-05 09:21:53.000000000,2020-02-06 06:13:06.000000000,closed,0,Improve collect() performance for columns with lists
2251,2020-02-04 21:12:35.000000000,2020-03-03 16:48:08.000000000,closed,1,"""ft_one_hot_encoder_estimator()"" doesn't work properly in ""ml_pipeline()"" "
2250,2020-02-02 23:39:14.000000000,2020-04-16 22:09:07.000000000,closed,8,remove embedded nul bytes if present in raw data to be read
2249,2020-01-31 21:06:19.000000000,2020-02-27 17:44:22.000000000,closed,3,spark_apply error when using if() and logical evaluation
2248,2020-01-31 09:38:51.000000000,2020-03-23 16:06:24.000000000,closed,1,Investigate performance from loading parquet
2247,2020-01-31 09:24:16.000000000,2020-02-05 09:04:10.000000000,closed,4,Basic support in 'copy_to()' for data frames with list columns
2246,2020-01-30 00:16:43.000000000,2020-02-22 01:53:08.000000000,closed,2,Basic Jenkinsfile for integration testing
2245,2020-01-27 17:56:52.000000000,2020-04-02 18:51:03.000000000,closed,3,Group_by and mutate
2244,2020-01-21 23:35:42.000000000,2020-03-05 22:05:56.000000000,closed,0,Use a unique filename for bundle files
2243,2020-01-21 22:52:58.000000000,2020-03-20 23:08:54.000000000,closed,6,Sparklyr and Arrow Max Records
2242,2020-01-16 21:13:53.000000000,2020-02-05 23:11:23.000000000,closed,3,Add sdf_drop_duplicates
2241,2020-01-16 20:35:58.000000000,1970-01-01 00:00:00.000000001,open,0,og
2240,2020-01-15 08:09:18.000000000,2020-04-13 16:59:23.000000000,closed,1,Packages delta not working with Spark 3.0.0 preview
2239,2020-01-14 01:09:48.000000000,1970-01-01 00:00:00.000000001,open,2,Remove JARs and license header file
2238,2020-01-10 17:41:17.000000000,2020-02-28 20:47:19.000000000,closed,1,Kerberos ticket inside spark_apply function.
2237,2020-01-10 04:30:58.000000000,2020-01-11 10:16:26.000000000,closed,2,Release sparklyr 1.1.0
2236,2020-01-09 11:55:51.000000000,2020-01-10 03:55:17.000000000,closed,0,Add support for `stream_read_delta()` and `stream_write_delta()`
2235,2020-01-09 11:07:48.000000000,2020-01-09 23:17:46.000000000,closed,1,Add support for partition_by in spark_write_delta()
2234,2020-01-07 03:55:48.000000000,2020-01-08 05:32:56.000000000,closed,1,Deprecate Livy source-uploads to favor using JARs
2233,2020-01-03 23:48:43.000000000,2020-08-04 23:35:23.000000000,closed,1,Include lift as part of ml_fpgrowth
2232,2020-01-03 04:34:59.000000000,2020-01-03 07:03:51.000000000,closed,0,Support for DBI 1.1 by implementing dbQuoteLiteral
2231,2019-12-28 21:51:51.000000000,2020-06-24 18:06:52.000000000,closed,2,FR: Sliding Window on Stream
2230,2019-12-27 02:46:35.000000000,2020-04-03 14:05:07.000000000,closed,0,`summary()` does not return coefficients for `ml_linear_regression` when `fit_intercept = FALSE`
2229,2019-12-24 23:26:13.000000000,2020-04-16 21:42:48.000000000,closed,2,R RF translation to Sparklyr RF
2228,2019-12-23 16:47:20.000000000,2020-01-09 23:17:48.000000000,closed,0,Support for delta lake write with partition 
2227,2019-12-22 11:17:40.000000000,2020-05-28 16:02:55.000000000,closed,2,copy_to spark failed with arabic text column.
2226,2019-12-20 00:52:09.000000000,2020-01-07 00:43:20.000000000,closed,0,Allow passing verbatim spark.sql.types as column definitions in spark_read_
2225,2019-12-19 20:09:38.000000000,2019-12-20 21:26:53.000000000,closed,0,Create a knox->livy->spark connection
2224,2019-12-18 03:22:15.000000000,1970-01-01 00:00:00.000000001,open,1,ft_vector_indexer() cannot handle invalid labels
2223,2019-12-15 20:53:58.000000000,2020-03-03 19:51:12.000000000,closed,1,[Question]: How do I filter a stream such that only the last 5 entries are kept
2222,2019-12-12 22:47:17.000000000,1970-01-01 00:00:00.000000001,open,0,how to specify ratings in ml_als for implicit ratings
2221,2019-12-12 07:51:41.000000000,2019-12-13 02:02:35.000000000,closed,1,Error: invalid version specification 'master'
2220,2019-12-11 13:42:23.000000000,1970-01-01 00:00:00.000000001,open,0,how to save the result of spark_apply in a column in the data frame on which it was run
2219,2019-12-11 01:35:35.000000000,2019-12-13 00:03:29.000000000,closed,1,Improve documentation for the `columns` argument
2218,2019-12-11 01:18:37.000000000,2020-01-04 04:07:57.000000000,closed,0,Fix build of Spark 1.5 and allow installing Spark 3.0.0-preview
2217,2019-12-10 02:09:47.000000000,2019-12-13 00:02:56.000000000,closed,1,Switch Livy tests to use jars
2216,2019-12-08 22:03:32.000000000,2020-01-05 03:08:13.000000000,closed,3,Include barrier in spark_apply
2215,2019-12-07 04:22:45.000000000,2019-12-10 03:16:46.000000000,closed,1,Turn arrow cmake flags on
2214,2019-12-06 10:31:50.000000000,2019-12-13 00:03:06.000000000,closed,1,Fix references to new repo
2213,2019-12-06 06:21:38.000000000,2020-02-26 10:30:11.000000000,closed,1,Implement connection method for Databricks Connect
2212,2019-12-04 01:54:53.000000000,2019-12-04 01:55:24.000000000,closed,1,travis
2211,2019-12-03 01:36:41.000000000,2019-12-03 07:17:08.000000000,closed,0,Fix typo in stream_read_socket() to fix #2210
2210,2019-12-02 01:09:37.000000000,2019-12-03 07:17:10.000000000,closed,0,"Typo in function name ""stream_read_scoket"""
2209,2019-11-29 17:49:39.000000000,1970-01-01 00:00:00.000000001,open,0,How to create a unmanaged global table?
2208,2019-11-29 17:46:58.000000000,2019-12-01 14:50:40.000000000,closed,2,How to create an managed Delta table?
2207,2019-11-26 14:37:46.000000000,2019-11-27 15:08:21.000000000,closed,2,Problem loading R twitter text data to spark copy_to 
2206,2019-11-26 13:19:32.000000000,2020-04-13 09:00:02.000000000,closed,1,Unable to connect to local cluster
2205,2019-11-25 22:36:54.000000000,2020-04-15 21:29:42.000000000,closed,2,spark_write_table - spaces in column names replaced with underscores
2204,2019-11-23 22:20:22.000000000,2019-11-23 22:56:06.000000000,closed,1,spark_write_table inconsistent behaviour with spark_write_<format>
2203,2019-11-23 00:02:37.000000000,2019-11-26 01:44:59.000000000,closed,0,Remove compute_cost in spark 3.0
2202,2019-11-22 17:54:28.000000000,2020-05-28 16:04:13.000000000,closed,8,Sparklyr 1.0.5 don't see hive tables and databases
2201,2019-11-21 14:22:10.000000000,2019-11-22 13:35:41.000000000,closed,2,extract resulting latent factors from ALS implementation ml_als
2200,2019-11-21 10:26:41.000000000,2019-11-22 06:10:31.000000000,closed,0,Add config to enable utc_timestamp in spark 3.0
2199,2019-11-21 00:31:34.000000000,2019-11-22 06:10:13.000000000,closed,2,Change the way to compute wssse when creating glance_tbl for kmeans and bisecting_kmeans 
2198,2019-11-20 01:00:06.000000000,2020-03-05 22:06:07.000000000,closed,3,Behavior changes in test-ml-feature-word2vec with spark 3.0
2197,2019-11-20 00:59:22.000000000,2019-11-20 23:05:47.000000000,closed,0,Do not use temporary directory in testthat_shell_connection
2196,2019-11-20 00:58:30.000000000,2020-03-09 17:59:40.000000000,closed,2,Behavior changes in ml-feature-imputer with spark 3.0
2195,2019-11-20 00:56:58.000000000,2020-03-04 17:24:53.000000000,closed,0,Behavior changes in ml.classification.NaiveBayes with spark 3.0
2194,2019-11-20 00:53:18.000000000,2020-03-09 18:52:41.000000000,closed,2,Behavior changes in test-dplyr-lead-lag with spark 3.0
2193,2019-11-20 00:52:04.000000000,2020-03-12 20:56:00.000000000,closed,0,Behavior changes in test-submit with spark 3.0
2192,2019-11-20 00:50:24.000000000,2020-03-10 01:01:00.000000000,closed,2,Behavior changes in test-invoke with spark 3.0
2191,2019-11-20 00:24:01.000000000,2019-11-20 06:45:19.000000000,closed,1,Change the way to set NumBuckets in QuantileDiscretizer
2190,2019-11-19 21:01:20.000000000,2019-11-20 02:41:36.000000000,closed,2,Test 1
2189,2019-11-19 11:20:53.000000000,2020-03-10 01:01:36.000000000,closed,1,Behavior changes in broom-multilayer_perceptron in spark 3.0
2188,2019-11-19 10:44:44.000000000,2020-03-09 17:51:42.000000000,closed,0,Behavior changes in test-broom-lda for spark 3.0
2187,2019-11-19 10:37:40.000000000,2020-03-09 17:51:23.000000000,closed,0,Behavior changes for hashingTF in spark 3.0
2186,2019-11-19 06:06:54.000000000,2020-03-09 17:51:32.000000000,closed,1,Behavior changes in broom-gradient_boosted_trees in spark 3.0
2185,2019-11-19 06:04:57.000000000,2020-03-08 13:56:52.000000000,closed,3,Behavior changes to handle NaN in spark 3.0
2184,2019-11-19 06:03:23.000000000,2019-11-23 01:55:41.000000000,closed,0,SQLContext.createExternalTable and SparkSession.createExternalTable are removed in spark 3.0
2183,2019-11-19 06:01:03.000000000,2019-11-22 06:10:13.000000000,closed,0,Error in test-broom-kmeans.R with Spark 3.0
2182,2019-11-19 05:59:13.000000000,2019-12-11 00:18:30.000000000,closed,0,New implementation for to_utc_timestamp and from_utc_timestamp in Sparek 3.0
2181,2019-11-19 05:52:42.000000000,2019-11-21 00:14:24.000000000,closed,0,New error handling logic in ml.feature.QuantileDiscretizer in spark 3.0
2180,2019-11-19 05:47:37.000000000,2019-11-26 01:44:59.000000000,closed,0,computeCost is removed from org.apache.spark.ml.clustering.KMeansModel in Spark 3.0
2179,2019-11-19 03:48:24.000000000,1970-01-01 00:00:00.000000001,open,0,Allow one to pass additional options to `spark_read_libsvm`?
2178,2019-11-19 02:09:07.000000000,2019-11-20 23:05:11.000000000,closed,15,Update ft_one_hot_encoder to be compatible with spark 3.0
2177,2019-11-19 01:18:03.000000000,2019-11-21 09:26:01.000000000,closed,0,Support to install Spark 2.4.4
2176,2019-11-19 01:15:27.000000000,2019-11-20 07:44:11.000000000,closed,1,support sparklyr executor memory setting and warn to fix printed book issue
2175,2019-11-19 00:26:16.000000000,2019-11-20 06:45:42.000000000,closed,0,"Fix reading with ""name"" provided as a named character"
2174,2019-11-19 00:25:33.000000000,1970-01-01 00:00:00.000000001,open,0,spark_read_... fail if a named character is provided as the `name` argument
2173,2019-11-18 02:09:02.000000000,2020-08-25 19:29:37.000000000,closed,1,Inconsistent dates depending on whether arrow package is loaded
2172,2019-11-17 23:36:15.000000000,2019-11-21 00:13:54.000000000,closed,0,API changes for OneHotEncoder and OneHotEncoderEstimator in spark 3.0
2171,2019-11-14 06:39:22.000000000,2019-11-14 21:29:48.000000000,closed,0,Let sdf_sql() accept glue strings
2170,2019-11-14 06:33:56.000000000,2019-11-14 21:29:48.000000000,closed,0,sdf_sql() cannot handle glue strings
2169,2019-11-14 05:28:05.000000000,2019-11-15 00:53:10.000000000,closed,0,Prepare sparklyr 1.0.5 CRAN patch release
2168,2019-11-14 03:15:58.000000000,1970-01-01 00:00:00.000000001,open,2,org.apache.spark.sql.AnalysisException:
2167,2019-11-14 00:17:25.000000000,2019-11-14 05:08:39.000000000,closed,0,Remove gmlnet from R old release tests
2166,2019-11-13 21:42:11.000000000,2019-11-14 01:33:16.000000000,closed,1,Error in if (nchar(versions$pattern) > 0) { :    valor ausente donde TRUE/FALSE es necesario Además: Warning message: In if (nchar(versions$pattern) > 0) { :   la condición tiene longitud > 1 y sólo el primer elemento será usado
2165,2019-11-12 20:26:57.000000000,2020-08-13 17:24:17.000000000,closed,5,sparklyr_1.0.4.9003 fails to start with Spark 2.4.4 / Scala 2.12.8 
2164,2019-11-11 15:13:03.000000000,2020-01-06 20:12:43.000000000,closed,2,Error loading data from SAP HANA into spark via jdbc and sparklyr.
2163,2019-11-09 05:58:25.000000000,2019-11-12 02:18:26.000000000,closed,2,[WIP] Specify dplyr package for `filter(...)`
2162,2019-11-06 02:21:51.000000000,2019-11-16 00:43:32.000000000,closed,4,Build sparklyr with spark master
2161,2019-11-05 21:52:19.000000000,2019-11-06 02:48:46.000000000,closed,5,Retrieve logical plan using sparklyr
2160,2019-10-30 20:47:25.000000000,2019-11-05 01:45:46.000000000,closed,3,How to create a new column with spark_apply
2159,2019-10-29 10:20:13.000000000,2019-10-29 17:49:11.000000000,closed,0,2.4 is not a missing version for sparklyr jar on Databricks any more
2158,2019-10-29 00:56:10.000000000,2019-10-29 05:04:44.000000000,closed,0,Use full url with protocol to avoid yarn-cluster errors and fix #2157
2157,2019-10-28 23:40:41.000000000,2019-10-29 05:04:46.000000000,closed,2,"Cannot create spark connection when master=""yarn-cluster"""
2156,2019-10-23 22:50:23.000000000,1970-01-01 00:00:00.000000001,open,1,Support for convert = FALSE in invoke()
2155,2019-10-23 09:18:51.000000000,2019-10-23 22:57:50.000000000,closed,6,Send R environments to Scala maps
2154,2019-10-22 23:27:46.000000000,2019-10-23 01:35:49.000000000,closed,1,Support spark 2.4 with scala-2.12 
2153,2019-10-22 15:52:34.000000000,2019-10-23 01:37:12.000000000,closed,3,Added SPARKLYR_CONFIG_FILE_PATH environment variable as an option to reading sparklyr config
2152,2019-10-22 15:46:52.000000000,2019-11-02 22:31:04.000000000,closed,0,Allow reading config file path from environment variable
2151,2019-10-21 23:02:48.000000000,1970-01-01 00:00:00.000000001,open,1,support for Float Java type when invoking Scala methods
2150,2019-10-21 18:47:11.000000000,1970-01-01 00:00:00.000000001,open,0,"i failed to install mleap package , and more over when i go back to connect to spark with spark_connect i get this ERROR: spark_dependencies function not found within extension package mleap"
2149,2019-10-19 03:16:08.000000000,1970-01-01 00:00:00.000000001,open,0,Sparklyr does not support Kerberized connection
2148,2019-10-19 02:23:03.000000000,2019-10-19 21:29:25.000000000,closed,1,Convenience functions to read and write from Delta Lake
2147,2019-10-18 18:20:22.000000000,2019-10-18 22:23:13.000000000,closed,0,Moves reference build to package
2146,2019-10-17 01:01:05.000000000,2019-10-18 22:25:16.000000000,closed,6,Some cloudera clusters have been failing with this override
2145,2019-10-16 20:02:51.000000000,1970-01-01 00:00:00.000000001,open,1,Problem running stats::arima() within spark_apply() with R 3.6.0 and in Databricks Runtime 5.5 LTS
2144,2019-10-16 19:57:09.000000000,2019-10-16 20:04:51.000000000,closed,1,Problem running stats::arima() within spark_apply() with R 3.6.0 and in Databricks Runtime 5.5 LTS
2143,2019-10-14 19:45:11.000000000,1970-01-01 00:00:00.000000001,open,6,Can't read a parquet file from AWS S3 bucket
2142,2019-10-13 04:24:31.000000000,2020-07-31 00:12:23.000000000,closed,3,Configuration via `sparklyr.shell.*` or `spark.*`
2141,2019-10-12 05:56:00.000000000,2019-10-12 18:12:25.000000000,closed,0,spark_disconnect() return invisibly
2140,2019-10-08 23:01:08.000000000,2020-05-25 17:25:39.000000000,closed,1,SQL translation for lubridate functions are overwriting Hive functions
2139,2019-10-04 22:17:45.000000000,2019-10-05 01:20:40.000000000,closed,0,Prepare sparklyr 1.0.4 CRAN patch release
2138,2019-10-04 22:00:08.000000000,1970-01-01 00:00:00.000000001,open,0,Support For Long-Format Data
2137,2019-10-04 02:18:41.000000000,1970-01-01 00:00:00.000000001,open,0,Sparklyr functionality issues with Hive and Hadoop 3
2136,2019-10-01 17:45:07.000000000,2020-07-31 00:13:34.000000000,closed,2,Latest Spark releases 2.4.4 and 2.3.4 not in `spark_versions()`
2135,2019-09-27 00:30:00.000000000,2019-09-27 20:22:16.000000000,closed,2,Issue with spark_apply and R 3.6.0
2134,2019-09-26 23:54:18.000000000,2019-09-26 23:54:27.000000000,closed,0,Issue with spark_apply and R 3.6.0
2133,2019-09-21 01:19:22.000000000,2019-09-21 11:08:39.000000000,closed,0,Follow up to Arrow 0.15 PR
2132,2019-09-20 04:35:10.000000000,2019-09-21 03:34:31.000000000,closed,1,Fix Arrow devel tests
2131,2019-09-17 03:31:21.000000000,1970-01-01 00:00:00.000000001,open,0,Add tests for OS X
2130,2019-09-16 23:41:21.000000000,2020-03-03 12:49:11.000000000,closed,1,doSpark
2129,2019-09-13 23:58:58.000000000,2019-09-14 01:42:19.000000000,closed,0,Merge sparklyr 1.0.3 release
2128,2019-09-13 09:50:42.000000000,2019-09-13 17:31:50.000000000,closed,1,Single user can create multiple session using qubole method.
2127,2019-09-12 20:22:59.000000000,1970-01-01 00:00:00.000000001,open,0,Does Sparklyr Support HDP3?
2126,2019-09-10 12:45:35.000000000,1970-01-01 00:00:00.000000001,open,1,`ft_vector_assembler()` crashes when values are missing / `NA`
2125,2019-09-09 22:20:53.000000000,1970-01-01 00:00:00.000000001,open,2,java method not found error when using sparklyr::invoke for xgboost4j-spark
2124,2019-09-06 12:42:37.000000000,1970-01-01 00:00:00.000000001,open,1,`ft_vector_assembler()` converts some numeric types to `DoubleType`
2123,2019-09-03 17:45:11.000000000,1970-01-01 00:00:00.000000001,open,1,Long time to Launch Cluster using Amazon EMR
2122,2019-09-01 18:05:55.000000000,2019-09-06 00:46:08.000000000,closed,2,Calculation between integer and double dplyr
2121,2019-09-01 14:02:21.000000000,1970-01-01 00:00:00.000000001,open,0,"spark_connect failing to connect, submit path error"
2120,2019-08-30 12:10:50.000000000,1970-01-01 00:00:00.000000001,open,1,tidy() puts p-values for linear model equals to zero
2119,2019-08-25 14:23:36.000000000,1970-01-01 00:00:00.000000001,open,0,"How to handle Spark Tables using compute, tbl_cache and sdf_register?"
2118,2019-08-23 22:42:17.000000000,2019-08-31 02:26:42.000000000,closed,4,Allow reading multiple files with `spark_read_`
2117,2019-08-20 08:46:59.000000000,1970-01-01 00:00:00.000000001,open,5,How do we implement K-Medoids in Sparklyr [PAM/CLARA : k-means extension]?
2116,2019-08-17 03:00:38.000000000,1970-01-01 00:00:00.000000001,open,2,Support for future package
2115,2019-08-09 14:53:46.000000000,2019-08-13 08:32:19.000000000,closed,5,It might be convenient for users to be able to cache SparkDataFrame directly
2114,2019-08-07 13:42:25.000000000,1970-01-01 00:00:00.000000001,open,0,Failed while connecting to sparklyr to port (41**) for sessionid (4****): ignoring SIGPIPE signal 
2113,2019-08-06 18:39:39.000000000,1970-01-01 00:00:00.000000001,open,1,Save a crossvalidated model
2112,2019-08-06 16:43:11.000000000,2019-08-28 06:07:00.000000000,closed,5,Area under ROC are all the same in training and testing data
2111,2019-08-06 01:00:04.000000000,1970-01-01 00:00:00.000000001,open,9,"sdf_bind_rows(a,b) %>% group_by(col1,col2) %>% sumarize(n=n()) crashes Spark and R"
2110,2019-08-05 16:14:33.000000000,2019-08-05 19:21:10.000000000,closed,2,spark_apply errors when writing to log
2109,2019-08-03 03:54:25.000000000,2019-08-03 05:40:53.000000000,closed,0,Fix arrow 0.14 type of int64
2108,2019-08-03 02:33:18.000000000,2019-08-03 03:39:37.000000000,closed,0,Fix spark_apply_log() and use rclosure as logging component
2107,2019-08-02 16:09:38.000000000,1970-01-01 00:00:00.000000001,open,1,Unexpected column behavior with spark_read_csv
2106,2019-08-01 15:43:58.000000000,2019-08-02 09:58:32.000000000,closed,1,sdf_with_sequential_id index is not integer?
2105,2019-08-01 12:21:37.000000000,1970-01-01 00:00:00.000000001,open,1,spark_read_jdbc is taking forever to load in R.
2104,2019-07-31 20:03:23.000000000,1970-01-01 00:00:00.000000001,open,4,sparklyr integration with Hive on Hadoop 3
2103,2019-07-31 13:13:54.000000000,2019-08-03 02:15:55.000000000,closed,2,"Using ft_ngram() throws and error- Error in UseMethod(""ft_ngram""): no applicable method for 'ft_ngram' applied to anobject of class ""SpakDataFrame"""
2102,2019-07-30 20:38:10.000000000,2019-08-03 02:15:36.000000000,closed,2,Error in rawToChar(raw)
2101,2019-07-26 17:42:46.000000000,2019-08-09 13:35:54.000000000,closed,3,Logging into spark log from R Script
2100,2019-07-26 11:04:18.000000000,2019-07-26 18:26:10.000000000,closed,0,support for compute() in spark 1.6 to fix #2099
2099,2019-07-25 23:05:44.000000000,2019-07-26 18:26:12.000000000,closed,2,Compute fails on Spark 1.6.3
2098,2019-07-25 10:33:14.000000000,2019-07-25 16:00:41.000000000,closed,0,Support for kubernetes port forwarding in windows
2097,2019-07-25 05:22:11.000000000,1970-01-01 00:00:00.000000001,open,4,Spark does not get connected from rstudio server running on EMR cluster
2096,2019-07-24 15:16:48.000000000,1970-01-01 00:00:00.000000001,open,2,Parallel connections to the gateway fail
2095,2019-07-19 22:18:30.000000000,2019-07-23 16:54:42.000000000,closed,2,Manually create model estimate for scoring
2094,2019-07-19 04:20:03.000000000,1970-01-01 00:00:00.000000001,open,2,Support Map Type Data in Sparklyr
2093,2019-07-17 23:44:15.000000000,1970-01-01 00:00:00.000000001,open,1,connect to spark in cluster mode
2092,2019-07-17 01:01:38.000000000,2019-07-17 01:20:44.000000000,closed,2,Use R functions in Sparklyr
2091,2019-07-16 23:59:16.000000000,1970-01-01 00:00:00.000000001,open,5,How to pass a list of words in a str_detect
2090,2019-07-16 20:02:58.000000000,2019-07-16 21:02:35.000000000,closed,2,convert character to numeric
2089,2019-07-16 16:47:48.000000000,2020-07-03 15:14:02.000000000,closed,6,Databricks Connect
2088,2019-07-16 15:23:41.000000000,2019-07-16 16:49:00.000000000,closed,1,sparklyr support for Databricks-Connect?
2087,2019-07-16 04:32:01.000000000,2020-06-18 17:35:55.000000000,closed,1,Warning message when using filter()
2086,2019-07-16 00:39:17.000000000,1970-01-01 00:00:00.000000001,open,2,Web UI Port issue 4040
2085,2019-07-15 23:22:04.000000000,1970-01-01 00:00:00.000000001,open,6,error in spark_connect on Windows10: system2 returns character(0)
2084,2019-07-15 20:08:53.000000000,1970-01-01 00:00:00.000000001,open,1,top_n doesn't work with spark 2.4.3
2083,2019-07-15 07:17:38.000000000,2020-01-25 05:18:03.000000000,closed,1,Error in spark_connect(): Error in validate_java_version_line
2082,2019-07-11 23:15:12.000000000,1970-01-01 00:00:00.000000001,open,0,sparkhail
2081,2019-07-11 16:03:07.000000000,2019-07-11 16:31:51.000000000,closed,2,spark_apply always try to infer columns type
2080,2019-07-11 13:17:46.000000000,2019-07-17 06:39:48.000000000,closed,0,Update spark_apply.R
2079,2019-07-09 20:44:24.000000000,1970-01-01 00:00:00.000000001,open,0,variantspark
2078,2019-07-09 15:11:43.000000000,1970-01-01 00:00:00.000000001,open,3,ml_als code example doesn't work
2077,2019-07-09 06:47:45.000000000,2019-08-06 16:52:11.000000000,closed,2,Read csv file with column values containing comma by using spark_read_csv
2076,2019-07-08 18:27:22.000000000,1970-01-01 00:00:00.000000001,open,2,SSLHandshakeException when `spark_connect` k8s cluster
2075,2019-07-07 12:30:00.000000000,1970-01-01 00:00:00.000000001,open,3,Support ONNX model inference 
2074,2019-07-06 20:02:56.000000000,2019-07-07 04:52:16.000000000,closed,5,Setting `sparklyr.defaultPackages` not working in `minikube`
2073,2019-07-06 18:19:12.000000000,2019-07-06 18:42:25.000000000,closed,4,no sparklyr client connecting to port 8880 (minikube)
2072,2019-07-06 06:42:10.000000000,2019-07-08 21:59:21.000000000,closed,3,Create R date from string by dplyr::mutate
2071,2019-07-06 00:39:06.000000000,2019-07-06 00:54:47.000000000,closed,1,rlang warning with dplyr::tally
2070,2019-07-04 19:27:15.000000000,2019-07-05 11:08:11.000000000,closed,5,spark_read_source for cassandra
2069,2019-07-03 10:19:08.000000000,2019-07-03 20:36:59.000000000,closed,0,Follow up on #1967
2068,2019-07-03 09:38:01.000000000,2019-07-03 10:42:08.000000000,closed,0,Follow up on PR #1965
2067,2019-07-02 05:30:32.000000000,1970-01-01 00:00:00.000000001,open,1,Matrix Support
2066,2019-07-02 01:59:05.000000000,2019-07-02 10:40:30.000000000,closed,0,Disable test while dbplyr/#330 gets investigated
2065,2019-07-02 00:58:23.000000000,2019-07-03 09:43:59.000000000,closed,0,Fixes for Apache Arrow 0.14
2064,2019-07-01 21:16:21.000000000,1970-01-01 00:00:00.000000001,open,5,"could not find function ""switch_lang"""
2063,2019-07-01 18:36:02.000000000,1970-01-01 00:00:00.000000001,open,2,Error in library(sparklyr) : there is no package called ‘sparklyr’
2062,2019-07-01 08:45:07.000000000,2019-07-03 01:34:43.000000000,closed,0,fix typo in glm description
2061,2019-06-30 08:10:00.000000000,1970-01-01 00:00:00.000000001,open,1,Support for compute sinks
2060,2019-06-30 05:58:30.000000000,2019-07-02 10:48:29.000000000,closed,0,Allow name path parameter under read_spark_()
2059,2019-06-30 00:10:20.000000000,2019-07-03 06:57:16.000000000,closed,0,Set infer_schema from column parameter
2058,2019-06-28 00:11:50.000000000,2019-07-02 01:29:31.000000000,closed,0,Improve printing for `ml_corr()` using tibble
2057,2019-06-27 09:52:35.000000000,2019-07-02 01:29:15.000000000,closed,0,Fix spark_apply() serialize warning
2056,2019-06-27 09:44:23.000000000,2019-07-02 01:29:18.000000000,closed,0,'package:stats' may not be available when loading
2055,2019-06-27 09:32:57.000000000,2019-07-02 01:28:36.000000000,closed,0,Printing a stream should return stream
2054,2019-06-27 08:10:07.000000000,2019-07-02 01:28:05.000000000,closed,0,Fail when uninstall is incomplete
2053,2019-06-27 08:03:51.000000000,2019-07-02 01:27:41.000000000,closed,0,spark_apply() might fail in local windows install with no access to temp path
2052,2019-06-27 06:11:32.000000000,2019-07-02 10:41:12.000000000,closed,0,Avoid printing NULL when disconnecting from Spark
2051,2019-06-26 07:04:54.000000000,2019-06-26 09:15:56.000000000,closed,0,Better error message when installing VC redist
2050,2019-06-25 22:18:47.000000000,1970-01-01 00:00:00.000000001,open,5,"`mutate_at`, `summarise_all`,  not working "
2049,2019-06-25 03:09:23.000000000,2020-02-06 10:59:57.000000000,closed,3,Connect Issue (Spark in R)
2048,2019-06-24 14:20:25.000000000,2019-06-25 00:04:29.000000000,closed,2,Changed the path of get-yarn-url file in Qubole connector
2047,2019-06-20 14:52:15.000000000,1970-01-01 00:00:00.000000001,open,6,"Why is ""tbl_spark"" faster than ""SparkDataFrame"" ?"
2046,2019-06-20 09:48:59.000000000,1970-01-01 00:00:00.000000001,open,2,documentation: why use spark?
2045,2019-06-20 07:31:11.000000000,2019-06-20 08:27:23.000000000,closed,3,java.net.UnknownHostException: $HOST: $HOST: Name or service not known
2044,2019-06-18 21:47:23.000000000,2019-06-18 23:54:37.000000000,closed,0,Avoid hangs in Spark web UI launcher when r/spark are busy
2043,2019-06-18 17:41:29.000000000,1970-01-01 00:00:00.000000001,open,0,Improve query timing of sdf_sql
2042,2019-06-14 22:44:30.000000000,2019-06-15 00:06:43.000000000,closed,0,Log mismatched arguments in `invoke()`
2041,2019-06-13 19:33:45.000000000,2020-08-05 15:01:02.000000000,closed,5,Visualizations in Spark Dataframes
2040,2019-06-12 07:12:08.000000000,1970-01-01 00:00:00.000000001,open,0,Problem translating to SQL expression when expression contain an index
2039,2019-06-10 20:02:45.000000000,2019-06-12 20:19:25.000000000,closed,4,Changes to add new qubole method to support sparklyr with Qubole cluster.
2038,2019-06-08 00:18:03.000000000,1970-01-01 00:00:00.000000001,open,0,H2O Pipelines
2037,2019-06-07 18:48:35.000000000,1970-01-01 00:00:00.000000001,open,1,Save a value from an sdf_sql statement in a variable
2036,2019-06-07 04:04:19.000000000,1970-01-01 00:00:00.000000001,open,0,sparklyr run failed with arrow in batch mode using spark_submit()/spark-submit --batch. Error: java.lang.Exception: No matched method found for class sparklyr.ArrowConverters.toDataFrame
2035,2019-06-06 08:07:27.000000000,1970-01-01 00:00:00.000000001,open,1,sparklyr doesn't work with sparkxgb
2034,2019-06-05 18:39:30.000000000,1970-01-01 00:00:00.000000001,open,3,"spark_apply  returns Error in file(con, ""r"").... Permission denied"
2033,2019-06-05 04:22:14.000000000,1970-01-01 00:00:00.000000001,open,1,Horovod
2032,2019-06-05 04:14:27.000000000,2019-06-18 21:01:33.000000000,closed,3,Use xenial to fix deprecated boost version in arrow devel build
2031,2019-06-04 02:56:31.000000000,1970-01-01 00:00:00.000000001,open,1,"Strings with ""NA"" still handled incorrectly in sdf_copy_to"
2030,2019-06-03 20:41:12.000000000,2019-06-05 04:12:13.000000000,closed,3,Remove arrow changeset pin (fixes #2027)
2029,2019-06-03 19:44:56.000000000,1970-01-01 00:00:00.000000001,open,2,ML_pipelines: managing table reading
2028,2019-06-03 12:19:48.000000000,2019-10-12 18:12:25.000000000,closed,0,Better message on `spark_disconnect()`
2027,2019-06-02 22:17:26.000000000,2019-06-05 04:12:15.000000000,closed,0,Revert temporary arrow-devel workaround
2026,2019-05-31 10:37:27.000000000,1970-01-01 00:00:00.000000001,open,0,Unable to pass a `tbl_spark` to an S4 slot of type `tbl`
2025,2019-05-31 09:06:37.000000000,2019-06-02 22:25:58.000000000,closed,0,"try to fix livy cases when statement state is ""available"" but output is still null."
2024,2019-05-30 22:16:06.000000000,2019-06-03 07:15:58.000000000,closed,0,bump rstudioapi version
2023,2019-05-30 22:14:20.000000000,2019-06-03 08:43:02.000000000,closed,3,Installation of sparklyr 1.0.1 is failing.
2022,2019-05-28 20:09:29.000000000,2019-06-03 18:31:52.000000000,closed,4,Connection to spark 2.4 cluster not working?
2021,2019-05-26 21:29:36.000000000,1970-01-01 00:00:00.000000001,open,0,Livy connection to Azure SQL Big Data Cluster
2020,2019-05-25 06:45:38.000000000,2019-06-02 22:19:45.000000000,closed,1,Fix version parameter for livy in docs
2019,2019-05-24 19:51:15.000000000,2019-06-02 22:18:17.000000000,closed,1,Fix Arrow devel builds on Travis
2018,2019-05-23 21:00:54.000000000,1970-01-01 00:00:00.000000001,open,6,Error while trying to connect to secured sparklyr from r-studio 
2017,2019-05-23 18:38:45.000000000,1970-01-01 00:00:00.000000001,open,2,Spark_apply takes multiple attempts to collect all the results with closures
2016,2019-05-22 01:25:59.000000000,1970-01-01 00:00:00.000000001,open,5,"Connecting to Spark through Livy failed with ""File name too long"""
2015,2019-05-21 19:21:28.000000000,2019-06-07 17:28:18.000000000,closed,2,Problem with ML pipelines
2014,2019-05-20 20:53:16.000000000,1970-01-01 00:00:00.000000001,open,0,Error on loading data frames with escaped characters
2013,2019-05-20 17:34:10.000000000,2019-05-21 18:49:04.000000000,closed,2,Error using a saved ml model
2012,2019-05-18 01:03:58.000000000,2019-05-23 20:42:25.000000000,closed,1,Support for Spark 2.4.3 and 2.3.3
2011,2019-05-17 20:41:41.000000000,2019-05-17 23:57:43.000000000,closed,0,Merge sparklyr 1.0.1 release
2010,2019-05-15 02:28:11.000000000,1970-01-01 00:00:00.000000001,open,0,failed calling getSourceArrayLength
2009,2019-05-13 20:57:33.000000000,1970-01-01 00:00:00.000000001,open,4,Trouble applying collect_list over a window with Partition By and Order By
2008,2019-05-11 09:23:45.000000000,2019-05-11 10:43:53.000000000,closed,0,Fix kubernetes configuration regression
2007,2019-05-11 07:04:34.000000000,2019-05-13 22:06:54.000000000,closed,1,dynamic allocation error even though spark.shuffle.service.enabled = true
2006,2019-05-10 14:34:12.000000000,2020-05-25 16:53:40.000000000,closed,5,How to extract hour from timestamp in sparklyr?
2005,2019-05-08 22:09:52.000000000,2019-05-09 20:30:40.000000000,closed,3,facebook prophet stuck when using with spark_apply
2004,2019-05-05 12:43:53.000000000,2019-05-10 13:31:02.000000000,closed,4,Convert UTC date time to local date time in sparklyr?
2003,2019-05-04 00:22:52.000000000,2020-06-18 16:59:28.000000000,closed,1,Error on install cannot open from URL
2002,2019-05-03 02:08:33.000000000,2019-05-03 06:37:43.000000000,closed,0,Add `ft_one_hot_encoder_estimator()`
2001,2019-05-02 22:06:56.000000000,2019-05-03 07:24:28.000000000,closed,0,Fix sdf_bind_cols with dbplyr 1.4
2000,2019-05-02 21:54:16.000000000,1970-01-01 00:00:00.000000001,open,1,Parse a list of columns in function ft_-
1999,2019-05-02 19:37:44.000000000,2019-06-02 11:40:30.000000000,closed,3,mutate_all() not working with list(~.) instead of funs(.) 
1998,2019-05-02 04:01:15.000000000,2019-05-02 04:55:48.000000000,closed,0,Fix for arrow devel travis build
1997,2019-05-01 22:04:24.000000000,1970-01-01 00:00:00.000000001,open,1, Failed while connecting to sparklyr to port (8880) for sessionid (92068)
1996,2019-05-01 21:48:32.000000000,2019-05-03 00:27:57.000000000,closed,0,Investigate travis failure in 1.6
1995,2019-05-01 00:01:57.000000000,2019-05-02 21:32:45.000000000,closed,4,Problem with ft_one_hot_encoder
1994,2019-04-30 20:19:30.000000000,2019-05-02 04:32:36.000000000,closed,0,Fix travis tests due to tidyverse updates
1993,2019-04-30 04:39:56.000000000,2019-08-30 07:51:31.000000000,closed,3,Scala 2.12 for spark 2.4.2
1992,2019-04-27 00:02:04.000000000,1970-01-01 00:00:00.000000001,open,0,stream_write_memory() does not trigger a refresh in the RStudio Connections pane
1991,2019-04-26 20:43:07.000000000,1970-01-01 00:00:00.000000001,open,1,"[Feature Request] spark_read_csv() with the ""adl://"" or ""abfs://"" file path for Azure Data Lake"
1990,2019-04-25 18:39:59.000000000,1970-01-01 00:00:00.000000001,open,3,Unable to understand spark_apply
1989,2019-04-25 14:34:09.000000000,1970-01-01 00:00:00.000000001,open,1,Ports used by Sparklyr with LIVY
1988,2019-04-25 00:59:21.000000000,2019-05-01 21:49:06.000000000,closed,1,Rename sdf_partition() to sdf_random_split()
1987,2019-04-25 00:30:37.000000000,1970-01-01 00:00:00.000000001,open,0,Quantile predictions for survival regression not returned in ml_predict
1986,2019-04-24 20:28:13.000000000,2019-05-02 04:32:59.000000000,closed,2,add compilation specification for Spark 2.4 and Scala 2.11.
1985,2019-04-24 03:23:53.000000000,2019-05-02 04:32:59.000000000,closed,0,update spark_default_compilation_spec() for Spark 2.4
1984,2019-04-22 23:58:54.000000000,1970-01-01 00:00:00.000000001,open,1,Failed while connecting to sparklyr to port (*) for sessionid (*): ignoring SIGPIPE signal
1983,2019-04-22 17:48:13.000000000,1970-01-01 00:00:00.000000001,open,3,Sparklyr ML Flow integartion
1982,2019-04-16 18:28:37.000000000,1970-01-01 00:00:00.000000001,open,13,Cannot start spark on Kubernetes through Sparklyr 
1981,2019-04-16 17:30:57.000000000,2019-06-07 17:30:54.000000000,closed,5,unable to use str_count
1980,2019-04-16 08:46:51.000000000,2019-04-23 09:41:26.000000000,closed,0,Expose spark_extension()
1979,2019-04-16 07:26:39.000000000,2019-04-23 09:40:46.000000000,closed,0,Support for repositories in extensions
1978,2019-04-11 23:25:56.000000000,2020-07-14 18:42:47.000000000,closed,10,Support for Spark 3.0
1977,2019-04-11 15:08:32.000000000,1970-01-01 00:00:00.000000001,open,10,Improve streaming documentation
1976,2019-04-08 19:38:22.000000000,1970-01-01 00:00:00.000000001,open,1,Rstudio crashes after many jobs successfully done in Sparklyr
1975,2019-04-07 22:24:53.000000000,2019-04-08 19:31:53.000000000,closed,2,tbl_cache() broken
1974,2019-04-06 03:14:16.000000000,2019-04-11 22:19:56.000000000,closed,1,Attempt to enable support for java 9
1973,2019-04-05 20:44:24.000000000,1970-01-01 00:00:00.000000001,open,2,spark_apply() %>% collect() triggers endless loop
1972,2019-04-05 08:40:35.000000000,2019-04-05 18:32:49.000000000,closed,0,Use arrow 0.13 in travis
1971,2019-04-05 02:41:40.000000000,2019-04-05 04:41:59.000000000,closed,0,fix typo in ml_construct_model_lda()
1970,2019-04-05 02:39:15.000000000,2019-04-05 04:41:59.000000000,closed,0,`stop_words` not respected by ml_lda()
1969,2019-04-04 20:09:39.000000000,1970-01-01 00:00:00.000000001,open,0,Support for Kinesis and Flume Streams
1968,2019-04-03 18:40:16.000000000,1970-01-01 00:00:00.000000001,open,2,Get stuck and No response while running sparklyr to collect data
1967,2019-04-02 00:04:51.000000000,2019-07-03 10:19:22.000000000,closed,1,Update test-dplyr.R
1966,2019-04-01 04:07:24.000000000,1970-01-01 00:00:00.000000001,open,0,Support RasterFrames
1965,2019-03-29 20:01:02.000000000,2019-07-03 09:38:27.000000000,closed,2,updates deprecated registerTempTable calls
1964,2019-03-29 04:59:04.000000000,2019-03-29 06:08:59.000000000,closed,0,Fix params has been deprecated and will be removed in a future release
1963,2019-03-28 05:26:45.000000000,2019-04-30 04:56:06.000000000,closed,4,spark_read_parquet from s3 error
1962,2019-03-28 03:31:54.000000000,1970-01-01 00:00:00.000000001,open,1,sparklyr cannot find sparklyr.ArrowHelper when use with arrow
1961,2019-03-27 09:26:29.000000000,1970-01-01 00:00:00.000000001,open,4,"Error in file(con, ""r"") : cannot open the connection"
1960,2019-03-27 01:48:51.000000000,1970-01-01 00:00:00.000000001,open,7,How to count NA Values?
1959,2019-03-27 01:14:41.000000000,2019-03-29 06:10:53.000000000,closed,0,Add ellipsis devel to travis
1958,2019-03-26 17:32:08.000000000,2019-03-29 06:10:23.000000000,closed,3,Bugfix/spark r libpaths
1957,2019-03-25 23:07:36.000000000,1970-01-01 00:00:00.000000001,open,0,Broken URL in README
1956,2019-03-22 01:13:00.000000000,1970-01-01 00:00:00.000000001,open,4,sprark_apply spark.r.libpaths config max 1 path
1955,2019-03-20 18:08:11.000000000,1970-01-01 00:00:00.000000001,open,4,sparklyr slow for parquet tables
1954,2019-03-20 16:24:55.000000000,1970-01-01 00:00:00.000000001,open,4,Date shifting by one day in Sparklyr?
1953,2019-03-20 10:04:40.000000000,1970-01-01 00:00:00.000000001,open,2,Support Cypher in Tidy Way
1952,2019-03-20 01:46:09.000000000,1970-01-01 00:00:00.000000001,open,0,Unable to pass field name to bracketed case_when statement using `.`
1951,2019-03-19 22:56:07.000000000,2019-03-21 04:27:49.000000000,closed,0,Support parameters in spark-submit
1950,2019-03-18 23:00:27.000000000,2019-03-20 21:34:25.000000000,closed,4,"Logical filters and summaries with ""%in%"" fail after group_by()"
1949,2019-03-15 21:06:46.000000000,2020-08-21 02:49:51.000000000,closed,4,sdf_pivot not compatible with enquo
1948,2019-03-12 20:54:40.000000000,1970-01-01 00:00:00.000000001,open,0,Add UI entry for Mesos
1947,2019-03-12 02:40:24.000000000,1970-01-01 00:00:00.000000001,open,0,Exact comparison method between <dttm> and <chr> fields differs depending on whether `=` or `>=`/`<=` logical operator is used
1946,2019-03-11 02:14:14.000000000,2020-08-25 19:45:32.000000000,closed,6,Flint
1945,2019-03-10 01:23:07.000000000,1970-01-01 00:00:00.000000001,open,0,Broadcast variable support in `spark_apply()`
1944,2019-03-09 02:12:17.000000000,2020-07-14 18:42:04.000000000,closed,0,Consider print method for spark_context()
1943,2019-03-08 02:28:33.000000000,1970-01-01 00:00:00.000000001,open,0,Problem with filter interval date
1942,2019-03-07 19:20:29.000000000,1970-01-01 00:00:00.000000001,open,0,drop a model from spark memory
1941,2019-03-07 06:47:39.000000000,2019-03-07 09:11:21.000000000,closed,0,Allow ml_lda() to passing ... arguments to tokenizer and count vectorizer
1940,2019-03-05 07:34:32.000000000,2019-03-05 11:25:23.000000000,closed,0,Add missing internal constructor for clustering evaluator
1939,2019-03-02 03:18:06.000000000,2019-03-02 05:07:26.000000000,closed,0,Clean up iris streaming folders on test exit
1938,2019-03-02 02:50:22.000000000,2019-03-05 15:07:51.000000000,closed,0,Implement `ml_evaluate()` for linear models
1937,2019-03-01 21:34:18.000000000,2019-03-08 18:51:50.000000000,closed,4,"Returning ""object 'type' not found"" in writeType()"
1936,2019-03-01 04:22:21.000000000,2019-03-05 11:25:25.000000000,closed,3,ml_clustering_evaluator() returns error if used with ml_cross_validator()
1935,2019-02-28 08:14:10.000000000,1970-01-01 00:00:00.000000001,open,2,Sparklyr Support Future Frontend.
1934,2019-02-28 06:48:03.000000000,2019-03-01 01:42:15.000000000,closed,0,Add `sdf_crosstab()`
1933,2019-02-27 05:45:18.000000000,2019-02-27 08:56:30.000000000,closed,2,"ml_multilayer_perceptron_classifier gives ""Failed to execute user defined function($anonfun$1: (vector) => vector)"" error"
1932,2019-02-26 10:23:18.000000000,2019-02-26 13:16:57.000000000,closed,0,Fix connections in Windows under Java x86
1931,2019-02-26 10:15:05.000000000,1970-01-01 00:00:00.000000001,open,0,Could not reserve enough space for 2097152KB object heap
1930,2019-02-25 19:28:11.000000000,1970-01-01 00:00:00.000000001,open,4,sparklyr gives different results from Hive on simple query
1929,2019-02-25 11:56:07.000000000,2019-02-25 21:08:41.000000000,closed,0,Port back to main sparklyr 1.0 release
1928,2019-02-23 04:19:51.000000000,1970-01-01 00:00:00.000000001,open,0,Reduce Dependencies
1927,2019-02-23 02:40:50.000000000,2019-02-23 03:07:32.000000000,closed,0,Update README with new features added since 0.6 release
1926,2019-02-23 00:48:37.000000000,2019-02-23 04:23:36.000000000,closed,0,Revert serde change for forge_stamped
1925,2019-02-22 08:01:26.000000000,2019-02-23 03:19:17.000000000,closed,1,Add support for sparklyr extensions in Livy
1924,2019-02-21 23:36:34.000000000,2019-02-22 06:40:31.000000000,closed,0,Fix regression in ui from supporting short spark versions
1923,2019-02-21 04:31:14.000000000,2019-02-21 19:28:12.000000000,closed,0,Default to no caching in `spark_apply()` + memory fix
1922,2019-02-21 03:27:22.000000000,2020-02-06 10:59:57.000000000,closed,1,spark_connect() should handle openjdk 11 gracefully
1921,2019-02-21 02:31:09.000000000,2019-02-21 04:31:34.000000000,closed,1,Databricks connection should be using SparkSession not HiveContext
1920,2019-02-20 23:33:04.000000000,1970-01-01 00:00:00.000000001,open,2,spark_config cannot set spark parameters
1919,2019-02-20 04:41:12.000000000,2019-02-20 07:34:30.000000000,closed,0,Broom methods for ALS
1918,2019-02-20 04:40:08.000000000,2019-02-20 06:13:17.000000000,closed,0,Allocate 2GB by default when using local connections
1917,2019-02-20 04:24:33.000000000,1970-01-01 00:00:00.000000001,open,1,Use SQLContext instead of HiveContext
1916,2019-02-19 11:19:22.000000000,2019-02-19 22:35:28.000000000,closed,0,Use CRAN version for ellipsis package
1915,2019-02-19 06:58:34.000000000,2019-02-20 03:51:37.000000000,closed,1,Fix for Databricks when connecting with Spark 2.4
1914,2019-02-19 06:26:28.000000000,2019-02-19 08:59:10.000000000,closed,0,Deprecations for 1.0
1913,2019-02-19 05:32:55.000000000,2019-02-19 11:10:46.000000000,closed,0,Fix spark_apply() env passing test
1912,2019-02-19 05:32:22.000000000,2019-02-19 21:45:56.000000000,closed,0,Minor batch collection fixes
1911,2019-02-19 03:30:29.000000000,2019-02-19 11:16:17.000000000,closed,0,Add support for opening YARN UI
1910,2019-02-19 02:38:35.000000000,1970-01-01 00:00:00.000000001,open,2,Spark 2.4 Avro file reading
1909,2019-02-19 00:28:30.000000000,2019-02-22 07:07:58.000000000,closed,2,sparklyr dplyr quo 
1908,2019-02-16 01:20:33.000000000,2019-02-16 08:07:18.000000000,closed,0,Support for reading data with path and no name
1907,2019-02-15 23:49:26.000000000,2019-02-16 08:06:38.000000000,closed,0,Hide copy_to() tables and export collect() and copy_to()
1906,2019-02-15 09:30:07.000000000,2019-02-16 08:05:42.000000000,closed,0,Support for installing and connecting using major Spark version
1905,2019-02-15 08:06:58.000000000,2019-02-15 09:21:28.000000000,closed,0,Faster collection of string arrays
1904,2019-02-15 06:29:19.000000000,1970-01-01 00:00:00.000000001,open,0,dataframe na functions
1903,2019-02-15 01:31:15.000000000,1970-01-01 00:00:00.000000001,open,5,"""yarn-cluster"" mode failed with ""Shutdown hook called before final status was reported."""
1902,2019-02-14 16:58:43.000000000,2019-02-14 22:30:40.000000000,closed,2,Scala version used with latest sparklyr (spark version 2.4.0)
1901,2019-02-14 02:59:32.000000000,2019-02-21 03:57:24.000000000,closed,3,streaming not working
1900,2019-02-14 01:32:40.000000000,2019-02-14 06:06:25.000000000,closed,0,Clean up decision tree print method unit test
1899,2019-02-12 21:07:05.000000000,2019-02-13 11:23:16.000000000,closed,0,Port Livy pull/1896 fix to master
1898,2019-02-12 13:55:10.000000000,1970-01-01 00:00:00.000000001,open,3,Cannot Open Local Connection | Permission Denied
1897,2019-02-12 08:17:25.000000000,1970-01-01 00:00:00.000000001,open,0,Type mismatch between additional_params$jars and livy jars
1896,2019-02-12 08:12:16.000000000,2019-02-12 21:05:48.000000000,closed,0,fix: mismatch between additional_params and livy jars
1895,2019-02-12 06:30:24.000000000,2019-02-12 08:52:52.000000000,closed,0,Add installation support for Spark 2.4
1894,2019-02-12 04:12:43.000000000,2019-02-12 06:25:43.000000000,closed,0,Expose probabilistic classifier parameters in MLP
1893,2019-02-12 01:33:30.000000000,2019-02-12 03:06:52.000000000,closed,0,Cast waitSeconds in stream_validate() to difftime
1892,2019-02-12 01:17:17.000000000,2019-02-12 03:06:45.000000000,closed,0,Deprecate dataset argument for feature transformers
1891,2019-02-09 04:00:54.000000000,2019-02-12 03:06:45.000000000,closed,0,Deprecate dataset argument in feature transformers
1890,2019-02-08 23:53:42.000000000,2019-02-09 02:14:42.000000000,closed,0,Export new_* constructors for developer API
1889,2019-02-08 15:30:50.000000000,2019-02-08 21:17:21.000000000,closed,0,??
1888,2019-02-08 07:14:40.000000000,1970-01-01 00:00:00.000000001,open,1,sparklyr not working with orc format external table
1887,2019-02-08 02:55:51.000000000,2019-02-15 20:29:10.000000000,closed,0,Support for Apache Arrow 0.12 in Tavis
1886,2019-02-07 22:50:49.000000000,2019-02-08 00:27:18.000000000,closed,0,Modifications in test-broom-lda.R
1885,2019-02-07 22:22:32.000000000,1970-01-01 00:00:00.000000001,open,0,Ensure broom names are compliant
1884,2019-02-07 13:55:24.000000000,1970-01-01 00:00:00.000000001,open,0,Sparklyr withour admin rights
1883,2019-02-07 04:44:17.000000000,2019-02-08 00:27:01.000000000,closed,2,Improve LDA formula interface behavior
1882,2019-02-06 10:57:57.000000000,2019-02-07 05:16:47.000000000,closed,1,fix #1876: expand variables in conf property value strings.
1881,2019-02-05 23:22:06.000000000,1970-01-01 00:00:00.000000001,open,1,Investigate performance on `spark_apply()` context
1880,2019-02-05 22:30:52.000000000,1970-01-01 00:00:00.000000001,open,3,How to prevent long Spark jobs in sparklyr from being aborted?
1879,2019-02-05 22:19:27.000000000,1970-01-01 00:00:00.000000001,open,0,Improved Examples
1878,2019-02-05 22:05:57.000000000,1970-01-01 00:00:00.000000001,open,0,Improved Errors
1877,2019-02-05 22:01:13.000000000,2019-02-27 08:56:49.000000000,closed,0,Tensorflow Records
1876,2019-02-05 03:39:04.000000000,2019-02-07 05:16:49.000000000,closed,2,spark_yarn_cluster_get_conf_property() doesn't expand variables in conf property value strings.
1875,2019-02-02 04:23:11.000000000,2019-02-02 06:05:36.000000000,closed,0,Add missing arg to find_constructor() call
1874,2019-02-02 04:03:09.000000000,2019-02-02 05:00:52.000000000,closed,0,Add `path` parameter for `spark_read_source()`
1873,2019-02-02 03:07:31.000000000,2019-02-02 07:52:43.000000000,closed,0,Add Spark 2.4 to appveyor script
1872,2019-02-02 01:31:31.000000000,2019-02-06 05:08:59.000000000,closed,0,Attempt to fix Hortonworks Hive Connection
1871,2019-02-01 19:15:46.000000000,2019-02-20 04:35:44.000000000,closed,5,Broom for als
1870,2019-02-01 15:31:04.000000000,2019-03-05 18:44:01.000000000,closed,8,sqlContext error on Databricks
1869,2019-01-31 01:03:34.000000000,2019-01-31 03:36:47.000000000,closed,1,Properly look for constructors defined in extension packages
1868,2019-01-31 01:03:18.000000000,2019-01-31 08:31:12.000000000,closed,4,Livy performance improvement by using sparklyr JARs
1867,2019-01-31 00:05:19.000000000,2019-01-31 03:36:47.000000000,closed,0,ml_get_constructor() doesn't find constructors defined in extension packages
1866,2019-01-30 22:41:40.000000000,2019-01-31 01:20:52.000000000,closed,0,Make cancellable setting a proper config entry
1865,2019-01-30 15:10:08.000000000,1970-01-01 00:00:00.000000001,open,3,Can livy_load_scala_sources function load source files parallely?
1864,2019-01-30 00:53:31.000000000,1970-01-01 00:00:00.000000001,open,0,ml_multiclass_classification_evaluator with ml_multilayer_perceptron_classifier error
1863,2019-01-29 04:50:33.000000000,2019-01-29 09:03:03.000000000,closed,0,Remove dependency on broom
1862,2019-01-29 04:07:09.000000000,2019-01-29 06:18:19.000000000,closed,0,Compatibility with devel dbplyr
1861,2019-01-29 03:36:59.000000000,2019-01-29 08:59:02.000000000,closed,0,Install arrow from arrowlib mirror
1860,2019-01-29 03:15:05.000000000,2019-01-29 04:04:50.000000000,closed,0,Remove dependency on devel forge
1859,2019-01-29 00:29:14.000000000,2019-01-29 09:03:03.000000000,closed,0,Remove broom dependency
1858,2019-01-29 00:17:55.000000000,2019-01-29 01:15:32.000000000,closed,0,Add dbplyr to travis devel check
1857,2019-01-28 21:39:04.000000000,2019-02-08 23:28:28.000000000,closed,0,XGBoost
1856,2019-01-25 20:39:13.000000000,1970-01-01 00:00:00.000000001,open,2,Read one file at a time from HDFS
1855,2019-01-25 03:02:53.000000000,2019-01-30 09:02:55.000000000,closed,2,ml_classification_multilayer_perceptron_classifier error with predict
1854,2019-01-24 17:57:29.000000000,2019-01-25 06:16:06.000000000,closed,1,Appropriately handle NA's in string columns
1853,2019-01-24 17:20:15.000000000,1970-01-01 00:00:00.000000001,open,14,sdf_collect is very slow
1852,2019-01-24 01:30:11.000000000,2019-01-24 04:40:39.000000000,closed,0,Fix progress reentrancy in RStudio 1.2
1851,2019-01-23 22:37:42.000000000,1970-01-01 00:00:00.000000001,open,3,missing components in ml_pca()
1850,2019-01-23 12:58:49.000000000,2019-01-24 00:58:04.000000000,closed,0,Support for Arrow 0.12
1849,2019-01-22 20:47:43.000000000,2019-01-25 17:01:29.000000000,closed,0,Spread in Sparklyr
1848,2019-01-22 15:07:30.000000000,2019-01-23 15:22:54.000000000,closed,2,sparklyr return an error when trying to connect to AWS S3
1847,2019-01-21 22:16:25.000000000,1970-01-01 00:00:00.000000001,open,2,`arrange` carries over and accumulates 
1846,2019-01-21 21:23:11.000000000,1970-01-01 00:00:00.000000001,open,0,SMOTE-BD in sparklyr
1845,2019-01-21 17:26:12.000000000,1970-01-01 00:00:00.000000001,open,0,adls access with kubernetes
1844,2019-01-19 21:16:32.000000000,2019-01-30 09:02:42.000000000,closed,2,"ft_tokenizer Error in rlang::env_get(mapping, nm, default = NULL, inherit = TRUE) "
1843,2019-01-19 03:33:58.000000000,1970-01-01 00:00:00.000000001,open,3,filter() + sample_frac() return an error
1842,2019-01-18 11:31:40.000000000,1970-01-01 00:00:00.000000001,open,0,Not detecting already installed VC++ Redistributable 2015 
1841,2019-01-16 21:37:30.000000000,2019-01-25 02:07:50.000000000,closed,1,broom::tidy(logistic_regression) doesn't return most statistics
1840,2019-01-16 02:30:32.000000000,1970-01-01 00:00:00.000000001,open,1,ml_tree_feature_importance | ml_pipeline | cross validated models
1839,2019-01-15 11:47:17.000000000,1970-01-01 00:00:00.000000001,open,0,Support other namespaces in kubernetes
1838,2019-01-13 11:10:23.000000000,1970-01-01 00:00:00.000000001,open,4,UDF problem with spark_apply
1837,2019-01-10 23:35:24.000000000,2019-01-11 22:00:31.000000000,closed,0,Add devel packages to travis config
1836,2019-01-10 19:22:43.000000000,2019-01-25 06:16:06.000000000,closed,1,"copy_to converts NA values to ""NA"" strings in string columns with local spark context"
1835,2019-01-10 09:38:45.000000000,2019-02-21 01:49:56.000000000,closed,3,Single thread after data manipulation + writing out RDD
1834,2019-01-09 02:25:45.000000000,1970-01-01 00:00:00.000000001,open,2,Feature_Request: Write to Rds
1833,2019-01-08 01:15:49.000000000,2019-01-09 01:50:12.000000000,closed,2,Can't reading parquet in sparklyr.java9 (`spark_read_parquet()`)
1832,2019-01-06 20:32:20.000000000,2019-01-07 21:15:47.000000000,closed,2,Broken link on Rstudio Webpage
1831,2019-01-06 00:50:27.000000000,2019-01-06 01:33:09.000000000,closed,1,"Error in do.call(.f, args, envir = .env): 'what' must be a function or character string"
1830,2019-01-05 05:14:08.000000000,2019-01-05 07:36:07.000000000,closed,0,Fix streaming documents and tibble 2.0.0 printing issue
1829,2019-01-05 02:40:45.000000000,2019-01-09 00:40:07.000000000,closed,3,"Error in if (n > 0) c(NA_integer_, -n) else integer()"
1828,2019-01-05 00:20:31.000000000,2020-07-08 20:00:17.000000000,closed,28, Failed while connecting to sparklyr to port (8880)
1827,2019-01-04 13:47:38.000000000,1970-01-01 00:00:00.000000001,open,1,spark_connect() requires version argument even for non-local connections
1826,2018-12-31 10:33:05.000000000,2018-12-31 12:48:50.000000000,closed,0,Simplify required JARs
1825,2018-12-30 01:57:56.000000000,2019-01-03 00:05:39.000000000,closed,7,FactoMineR MCA fails in spark_apply
1824,2018-12-29 05:22:50.000000000,2018-12-31 10:26:35.000000000,closed,0,Add support to read whole text files
1823,2018-12-29 00:16:53.000000000,2019-03-20 17:45:42.000000000,closed,22,Hive metastore not found after Spark 2.3 upgrade
1822,2018-12-27 23:22:39.000000000,2018-12-28 02:14:43.000000000,closed,0,Support retrieving Spark version from spark-submit
1821,2018-12-25 08:02:25.000000000,1970-01-01 00:00:00.000000001,open,1,Help to create loops with sparklyr
1820,2018-12-25 07:54:52.000000000,1970-01-01 00:00:00.000000001,open,3,Problem with functions
1819,2018-12-21 14:31:47.000000000,2018-12-21 18:43:54.000000000,closed,1,Paste/Paste0 doesn't work 
1818,2018-12-21 01:30:52.000000000,1970-01-01 00:00:00.000000001,open,4,Problem using another CRAN package in UDF and spark_apply
1817,2018-12-21 00:21:06.000000000,1970-01-01 00:00:00.000000001,open,0,Consider moving read/write options to ...
1816,2018-12-19 21:53:32.000000000,1970-01-01 00:00:00.000000001,open,0,Include JDBC read/write examples in package help
1815,2018-12-19 03:34:02.000000000,1970-01-01 00:00:00.000000001,open,8,Error: Unable to use sparklyr to query large data
1814,2018-12-19 02:06:28.000000000,1970-01-01 00:00:00.000000001,open,3,Error: org.apache.spark.SparkException: Job aborted due to stage failure
1813,2018-12-18 09:00:12.000000000,1970-01-01 00:00:00.000000001,open,0,convergence status and null ml_generalized_linear_regression()$summary$.jobj 
1812,2018-12-18 05:44:54.000000000,2018-12-18 10:42:58.000000000,closed,0,`ml_model` constructor revisions
1811,2018-12-18 03:45:27.000000000,2018-12-18 05:40:21.000000000,closed,0,Fix spark_connect() when extension doesn't have spark ml mapping jsons
1810,2018-12-17 21:20:37.000000000,2018-12-18 05:40:21.000000000,closed,5,Error during spark_connect
1809,2018-12-13 02:10:08.000000000,2018-12-13 02:55:59.000000000,closed,0,Dev API missed commits
1808,2018-12-11 23:57:31.000000000,1970-01-01 00:00:00.000000001,open,0,spark_home_set.Rd examples do not run.
1807,2018-12-11 06:39:38.000000000,1970-01-01 00:00:00.000000001,open,0,Developer API followups
1806,2018-12-11 05:26:08.000000000,2019-01-05 07:36:08.000000000,closed,1,stream_write_kafka.Rd examples do not run.
1805,2018-12-11 03:35:01.000000000,2019-01-05 07:36:08.000000000,closed,1,stream_render.Rd examples do not run.
1804,2018-12-11 01:23:28.000000000,2019-02-19 06:41:11.000000000,closed,3,sdf_mutate.Rd examples do not run.
1803,2018-12-11 00:49:57.000000000,1970-01-01 00:00:00.000000001,open,2,ml_multilayer_perceptron_classifier model is missing num_classes attribute
1802,2018-12-10 21:58:47.000000000,2019-02-25 23:44:42.000000000,closed,16,Empty string in table
1801,2018-12-08 05:17:24.000000000,2019-01-05 07:36:08.000000000,closed,0,'stop_stream' should be 'stream_stop' instead?
1800,2018-12-07 18:50:41.000000000,1970-01-01 00:00:00.000000001,open,2,dplyr::copy_to spark reactive Table using Shiny 
1799,2018-12-07 11:21:34.000000000,1970-01-01 00:00:00.000000001,open,0,Support for Generalized Linear Mixed Models?
1798,2018-12-07 01:21:14.000000000,2019-02-12 06:25:43.000000000,closed,0,multilayer perceptron is missing probabilistic classifier params
1797,2018-12-06 07:40:39.000000000,2018-12-20 22:30:32.000000000,closed,5,Unique SqlContext per databricks connection
1796,2018-12-06 02:01:16.000000000,2018-12-07 01:21:40.000000000,closed,2,Error with df.show() pyspark
1795,2018-12-05 10:54:15.000000000,1970-01-01 00:00:00.000000001,open,1,Failed while connecting to sparklyr to port (8880) for sessionid 
1794,2018-11-29 02:47:22.000000000,2019-02-19 06:43:10.000000000,closed,0,Update tests to support spark-2.4
1793,2018-11-29 01:27:08.000000000,2018-11-29 02:48:09.000000000,closed,0,[Test] Support for Spark 2.4.0
1792,2018-11-29 01:25:52.000000000,2018-11-30 03:22:25.000000000,closed,0,Support for Spark 2.4.0
1791,2018-11-28 23:50:55.000000000,1970-01-01 00:00:00.000000001,open,0,Barriers
1790,2018-11-28 23:14:17.000000000,1970-01-01 00:00:00.000000001,open,10,Failed to detect version from SPARK_HOME or SPARK_HOME_VERSION in Jupyter R kernel
1789,2018-11-28 19:51:04.000000000,2019-02-19 06:42:33.000000000,closed,3,No tidy() support for pipeline output
1788,2018-11-28 01:28:06.000000000,2018-11-28 03:29:46.000000000,closed,0,Support for custom cleanup for kubernetes connections
1787,2018-11-27 23:50:13.000000000,2018-11-28 03:27:30.000000000,closed,0,Fix jar parameter under spark_config_kubernetes()
1786,2018-11-27 09:42:05.000000000,2019-01-29 00:28:45.000000000,closed,9,Modifications in ml_lda() and broom
1785,2018-11-27 01:07:15.000000000,2018-11-27 01:50:18.000000000,closed,1,Dereference symlinks when creating package bundle
1784,2018-11-26 13:28:47.000000000,1970-01-01 00:00:00.000000001,open,3,Better interaction with glue 
1783,2018-11-26 13:19:39.000000000,2018-11-26 22:02:16.000000000,closed,1,Improve type error
1782,2018-11-22 16:59:27.000000000,1970-01-01 00:00:00.000000001,open,7,Analogue to createTable and recoverPartitions
1781,2018-11-22 16:44:08.000000000,1970-01-01 00:00:00.000000001,open,2,The spark_apply function uses R extension packages very slowly
1780,2018-11-21 02:42:51.000000000,2018-11-26 21:10:44.000000000,closed,2,Deploy R kernel into Jupyter
1779,2018-11-20 23:35:17.000000000,2020-05-07 21:16:26.000000000,closed,0,Import/Export with R
1778,2018-11-20 14:06:33.000000000,2018-12-11 06:38:21.000000000,closed,0,Developer API for ML pipeline extensions
1777,2018-11-19 22:40:25.000000000,1970-01-01 00:00:00.000000001,open,2,Feature Request: spark_read_excel
1776,2018-11-17 02:35:02.000000000,2018-11-19 04:09:32.000000000,closed,0,Opt-in to enable support for tables with periods
1775,2018-11-15 03:02:38.000000000,2018-11-16 06:27:11.000000000,closed,0,Disable auto preview in SQL action
1774,2018-11-14 20:18:29.000000000,2018-11-15 13:48:46.000000000,closed,2,Value matching under sparklyr
1773,2018-11-10 12:14:12.000000000,2020-05-07 14:08:25.000000000,closed,15,Higher order functions
1772,2018-11-10 12:12:43.000000000,2019-03-05 15:07:53.000000000,closed,0,Deprecate kmeans compute cost
1771,2018-11-10 12:10:46.000000000,1970-01-01 00:00:00.000000001,open,0,Image data source support
1770,2018-11-10 12:05:40.000000000,1970-01-01 00:00:00.000000001,open,0,Add intersect_all and except_all dplyr verbs
1769,2018-11-10 11:41:23.000000000,1970-01-01 00:00:00.000000001,open,0,Single instance prediction
1768,2018-11-10 11:39:14.000000000,1970-01-01 00:00:00.000000001,open,0,Locale support in stop words remover
1767,2018-11-10 11:38:16.000000000,1970-01-01 00:00:00.000000001,open,0,PIC
1766,2018-11-10 11:37:41.000000000,1970-01-01 00:00:00.000000001,open,0,Support fit with validation in GBT
1765,2018-11-10 11:35:41.000000000,1970-01-01 00:00:00.000000001,open,0,Add evaluateEachIteration for GBT
1764,2018-11-10 11:34:01.000000000,1970-01-01 00:00:00.000000001,open,0,Add lift in FPM
1763,2018-11-10 11:33:17.000000000,1970-01-01 00:00:00.000000001,open,0,Support cosine distance in kmeans/bisecting kmeans
1762,2018-11-08 11:20:41.000000000,2019-02-07 05:18:38.000000000,closed,0,Support for Copying and Collecting Batches
1761,2018-11-08 08:17:12.000000000,1970-01-01 00:00:00.000000001,open,3,Consider warning on Livy connections
1760,2018-11-08 07:15:29.000000000,1970-01-01 00:00:00.000000001,open,0,Add a parameter to ft_r_formula to allow changing the ft_string_indexer string_order_type
1759,2018-11-08 03:53:27.000000000,2018-11-08 10:51:41.000000000,closed,0,Fix unknown or uninitialized column: 'tableName'
1758,2018-11-08 03:26:26.000000000,2019-02-19 06:42:43.000000000,closed,0,rlang 0.3 compatibility
1757,2018-11-08 03:04:53.000000000,2018-12-01 04:05:40.000000000,closed,1,Backport fixes under sparklyr 0.9.3
1756,2018-11-07 22:59:22.000000000,2018-11-15 07:55:06.000000000,closed,0,Fixes to Arrow Types
1755,2018-11-07 14:10:52.000000000,2018-11-07 14:54:26.000000000,closed,0,Deprecate `sdf_mutate()`
1754,2018-11-07 14:01:11.000000000,2018-11-07 14:54:26.000000000,closed,0,Deprecate `sdf_mutate()`
1753,2018-11-07 01:52:16.000000000,2018-11-08 10:50:45.000000000,closed,11,Support for tables with periods
1752,2018-11-06 22:38:36.000000000,1970-01-01 00:00:00.000000001,open,0,sparklyr proxy setting with livy
1751,2018-11-06 20:28:39.000000000,2018-11-06 22:41:58.000000000,closed,0,Avoid requiring use of SPARK_HOME_VERSION when version is set
1750,2018-11-06 03:05:23.000000000,1970-01-01 00:00:00.000000001,open,0,Issues with hive post 2.3 breakage fix
1749,2018-11-05 21:35:51.000000000,1970-01-01 00:00:00.000000001,open,9,support spark 2.4
1748,2018-11-05 16:24:56.000000000,2018-11-06 23:41:38.000000000,closed,1,fixed typo (stopping instead of stoping)
1747,2018-11-04 07:04:21.000000000,2018-11-16 20:12:42.000000000,closed,3,Broom for mlp
1746,2018-11-04 01:58:48.000000000,1970-01-01 00:00:00.000000001,open,0,Support for timing out while processing a partition in `spark_apply()`
1745,2018-11-03 01:19:43.000000000,2018-11-06 19:54:30.000000000,closed,0,Fix default session for shiny reactive spark
1744,2018-11-01 00:40:39.000000000,1970-01-01 00:00:00.000000001,open,0,`ml_als()` saves unexposed RDDs in memory
1743,2018-10-31 16:05:02.000000000,1970-01-01 00:00:00.000000001,open,6,Dates out of control
1742,2018-10-31 15:17:19.000000000,1970-01-01 00:00:00.000000001,open,3,Spark Connection - not loading Hive Metastore in AWS Glue
1741,2018-10-29 22:53:42.000000000,2018-10-30 03:51:30.000000000,closed,0,Remove streaming entry points for JDBC
1740,2018-10-29 11:13:49.000000000,1970-01-01 00:00:00.000000001,open,0,Support using carrier::crate() in spark_apply
1739,2018-10-28 04:01:36.000000000,1970-01-01 00:00:00.000000001,open,4,xgboost inference with spark_apply stuck at the last task
1738,2018-10-26 23:55:05.000000000,2019-01-25 02:05:20.000000000,closed,8,SQL translation turns aggregation into window function on SPARK
1737,2018-10-26 19:44:26.000000000,2020-06-10 20:28:45.000000000,closed,1,Investigate timezone test issue in Arrow
1736,2018-10-26 19:42:43.000000000,2018-10-31 01:11:13.000000000,closed,1,Investigate issue when collecting int64 in Arrow
1735,2018-10-26 07:32:10.000000000,1970-01-01 00:00:00.000000001,open,0,NaN support in Arrow
1734,2018-10-26 03:35:12.000000000,2020-04-15 20:47:34.000000000,closed,1,Nested data in Spark with Arrow
1733,2018-10-26 03:33:25.000000000,1970-01-01 00:00:00.000000001,open,0,POSIXct in Spark with Arrow for Date(MILLISECOND)
1732,2018-10-26 01:27:17.000000000,2018-10-30 03:51:32.000000000,closed,1,Sparklyr shouldn't provide stream_read_jdbc and  stream_write_jdbc
1731,2018-10-25 05:27:15.000000000,2018-10-25 08:38:49.000000000,closed,0,Support collecting data frame booleans with NAs
1730,2018-10-25 04:20:56.000000000,2018-11-07 00:41:58.000000000,closed,2,Fix for devtools package not found +  SHA1 not changed error
1729,2018-10-24 21:20:09.000000000,2018-10-26 02:46:08.000000000,closed,1,NA prints FALSE in logical col
1728,2018-10-23 15:49:41.000000000,1970-01-01 00:00:00.000000001,open,1,Lack of log data for spark_apply
1727,2018-10-22 22:36:09.000000000,2018-10-26 05:09:33.000000000,closed,1,[TEST] Run all Travis tests with Arrow enabled
1726,2018-10-19 21:22:30.000000000,1970-01-01 00:00:00.000000001,open,5,segmentation fault upon reconnecting to Spark after a disconnect
1725,2018-10-19 17:18:46.000000000,2018-11-16 23:37:58.000000000,closed,2,Broom for ml_pca()
1724,2018-10-19 16:34:11.000000000,1970-01-01 00:00:00.000000001,open,1,apply UDF with more than one argument in spark_apply() function - need for example
1723,2018-10-18 08:12:05.000000000,2018-10-19 03:25:32.000000000,closed,0,Properly clean JVM objects once deallocated from R
1722,2018-10-17 21:10:00.000000000,2018-10-18 00:06:26.000000000,closed,3,Interaction with categorical includes all levels
1721,2018-10-17 20:21:05.000000000,2018-11-06 09:11:27.000000000,closed,0,Re-enable code coverage due to version changes
1720,2018-10-17 04:34:22.000000000,2018-10-17 20:10:46.000000000,closed,0,Merge back sparklyr 0.9.2 patch release
1719,2018-10-16 22:26:50.000000000,2018-10-17 04:09:21.000000000,closed,0,Support for Spark 2.3.2
1718,2018-10-16 21:09:45.000000000,2018-10-16 22:40:25.000000000,closed,0,Require version 0.6 or newer of rstudioapi to fix #1716
1717,2018-10-16 17:45:20.000000000,2018-10-16 19:47:34.000000000,closed,1,spark_connect fails when h2o package is loaded
1716,2018-10-16 15:28:03.000000000,2018-10-16 22:40:26.000000000,closed,1,Errors trying to install sparklyr.
1715,2018-10-16 15:25:07.000000000,2018-10-21 03:46:08.000000000,closed,3,sparklyr does not work with spark 2.3.1?
1714,2018-10-16 06:19:53.000000000,2018-10-16 08:08:11.000000000,closed,0,Fix spark_apply() error logging
1713,2018-10-15 07:39:40.000000000,2018-10-19 21:37:03.000000000,closed,3,Broom for ml_linear_svc()
1712,2018-10-15 07:37:29.000000000,1970-01-01 00:00:00.000000001,open,0,Hive radians function is not supported
1711,2018-10-12 18:15:49.000000000,1970-01-01 00:00:00.000000001,open,3,Hive date functions throw errors in sdf_sql
1710,2018-10-11 13:46:27.000000000,1970-01-01 00:00:00.000000001,open,3,Long hang time when copying R data frame/table to Spark
1709,2018-10-11 08:43:02.000000000,1970-01-01 00:00:00.000000001,open,1,"Compression Codec Not Found on spark_read_csv, and null pointer on spark_read_jdbc"
1708,2018-10-11 07:40:27.000000000,1970-01-01 00:00:00.000000001,open,0,Hive support required for CTAS
1707,2018-10-11 02:52:35.000000000,2018-10-11 06:34:15.000000000,closed,0,Fix regression in sdf_collect()
1706,2018-10-10 13:48:18.000000000,2018-10-10 14:10:05.000000000,closed,1,Can't locally increase sparklyr.shell.driver-memory
1705,2018-10-10 07:22:11.000000000,2018-10-11 02:19:28.000000000,closed,0,Fix new spark connection selectors in mojave
1704,2018-10-09 23:37:49.000000000,1970-01-01 00:00:00.000000001,open,0,spark_read_jdbc - Unsupported type 101
1703,2018-10-04 17:22:26.000000000,1970-01-01 00:00:00.000000001,open,3,'remote_name' is not an exported object from 'namespace:dbplyr'
1702,2018-10-04 00:18:04.000000000,2018-10-04 22:13:50.000000000,closed,4,Can't copy_to local instance
1701,2018-10-03 01:36:06.000000000,2018-10-03 07:27:29.000000000,closed,0,Remove overwite parameter from spark_read_table() to fix #1698
1700,2018-10-02 23:00:38.000000000,2020-03-03 12:34:02.000000000,closed,4,GIS
1699,2018-10-02 16:58:18.000000000,2018-10-03 19:20:36.000000000,closed,2,Additional parallel processing for rows within spark_apply()
1698,2018-10-02 12:29:50.000000000,2018-10-03 07:27:30.000000000,closed,0,spark_read_table tries to remove Source table
1697,2018-10-01 22:35:03.000000000,2018-10-02 20:14:09.000000000,closed,0,Add older versions of R while testing on travis
1696,2018-10-01 20:58:15.000000000,2018-10-02 20:14:26.000000000,closed,0,Additional paths searching for spark version to fix #1694
1695,2018-09-28 20:32:58.000000000,2018-10-02 20:14:55.000000000,closed,1,Investigate use of R 3.4 with sparklyr 0.9
1694,2018-09-28 15:16:43.000000000,2018-10-02 20:14:26.000000000,closed,4,Can't connect to Spark on Qubole since 0.9.1
1693,2018-09-28 03:44:32.000000000,1970-01-01 00:00:00.000000001,open,4,Collecting dates do not use provided timezone
1692,2018-09-27 02:38:29.000000000,2018-09-27 07:32:19.000000000,closed,0,Fixes for sparklyr 0.9.1
1691,2018-09-24 03:21:46.000000000,1970-01-01 00:00:00.000000001,open,0,unable to read data which was written using any of spark_write method with paritition_by 
1690,2018-09-22 04:11:16.000000000,2018-09-26 12:06:51.000000000,closed,0,Submit Batch
1689,2018-09-21 14:16:24.000000000,2018-09-24 20:18:22.000000000,closed,2,Hyperlink DOI to preferred resolver
1688,2018-09-19 20:42:46.000000000,1970-01-01 00:00:00.000000001,open,4,How do I properly perform Oracle SQL queries through spark_read_jdbc?
1687,2018-09-19 05:02:09.000000000,2018-09-19 20:17:00.000000000,closed,0,spark_connect() should not attempt to download version data
1686,2018-09-19 03:23:56.000000000,2018-09-19 04:58:53.000000000,closed,0,Various fixes under sparklyr 0.9 milestone
1685,2018-09-18 21:08:44.000000000,1970-01-01 00:00:00.000000001,open,1,How do I specify where spark_install gets the file from?
1684,2018-09-17 22:18:50.000000000,2018-09-18 22:14:05.000000000,closed,0,Minor stream related improvements
1683,2018-09-14 15:08:24.000000000,2018-10-12 21:00:40.000000000,closed,5,broom for isotonic regression and aft survival regression
1682,2018-09-14 10:45:56.000000000,2018-09-14 11:34:35.000000000,closed,0,Deprecate and remove usage of ensure_* functions
1681,2018-09-14 05:06:26.000000000,2018-09-19 04:58:55.000000000,closed,0,Stream Jobs not cancelled when disconnecting
1680,2018-09-13 20:23:59.000000000,2018-09-19 03:26:45.000000000,closed,1,Default to Spark 2.3.1 in spark_connect()
1679,2018-09-13 01:54:02.000000000,2018-09-13 03:02:05.000000000,closed,0,Fix `stream_view()` when loading large data
1678,2018-09-12 23:27:22.000000000,2018-09-13 01:54:28.000000000,closed,0,spark_apply() used to cache results by default
1677,2018-09-12 20:49:10.000000000,2018-09-13 01:54:29.000000000,closed,0,`spark_apply()` no longer caches in memory by default
1676,2018-09-12 09:01:52.000000000,2018-09-13 01:54:16.000000000,closed,0,Remove forge remote from DESCRIPTION
1675,2018-09-12 05:48:40.000000000,2018-09-12 08:49:33.000000000,closed,0,Implement `DBI::db_explain()`
1674,2018-09-12 05:48:14.000000000,2018-09-12 08:01:36.000000000,closed,0,Polish couple config settings
1673,2018-09-12 01:35:00.000000000,1970-01-01 00:00:00.000000001,open,1,spark_apply issue in R server
1672,2018-09-11 15:32:07.000000000,1970-01-01 00:00:00.000000001,open,4,add funciton's documentations 
1671,2018-09-11 11:44:52.000000000,2018-09-13 00:12:55.000000000,closed,2,kerberos problem  in sparklyr
1670,2018-09-11 00:03:13.000000000,2018-09-11 02:07:05.000000000,closed,0,Remove no longer in use vignettes
1669,2018-09-07 22:15:21.000000000,2018-09-08 05:50:35.000000000,closed,0,Implement spark_config_settings() to describe all sparklyr settings
1668,2018-09-07 18:36:11.000000000,2018-10-02 20:15:43.000000000,closed,0,Submit Batch
1667,2018-09-07 06:13:47.000000000,2018-09-19 04:58:54.000000000,closed,0,RStudio connections pane not closing connection
1666,2018-09-07 02:54:02.000000000,2018-09-07 07:15:26.000000000,closed,0,spark_apply() does not respect column types for NA columns
1665,2018-09-07 02:50:47.000000000,2018-09-07 07:15:27.000000000,closed,0,spark_apply() does not respect column types for NA columns
1664,2018-09-06 17:49:20.000000000,2018-09-11 19:40:28.000000000,closed,5,ml_fpgrowth() not working
1663,2018-09-06 11:46:28.000000000,2018-09-06 18:52:11.000000000,closed,0,Improve document about livy_config()
1662,2018-09-05 21:10:23.000000000,1970-01-01 00:00:00.000000001,open,3,sdf_* functions not taking pipeline objects as inputs
1661,2018-09-05 21:00:39.000000000,1970-01-01 00:00:00.000000001,open,1,"Creating table in teradata: Error: Data Type ""TEXT"" does not match a Defined Type name."
1660,2018-09-05 06:53:53.000000000,2018-09-05 22:49:55.000000000,closed,1,Broom for random forest and gradient boosted trees
1659,2018-09-01 12:59:06.000000000,1970-01-01 00:00:00.000000001,open,16,Not able to connect to Spark with Sparklyr 0.8.4
1658,2018-09-01 06:52:39.000000000,1970-01-01 00:00:00.000000001,open,4,ML Pipeline Error: org.apache.spark.SparkException: Exception thrown in awaitResult: 
1657,2018-09-01 04:20:20.000000000,2018-09-01 06:05:34.000000000,closed,0,Rebuild jars for pull/1655
1656,2018-08-31 17:23:04.000000000,2018-09-01 03:35:01.000000000,closed,1,Broom for naive bayes and logistic regression
1655,2018-08-31 10:43:55.000000000,2018-09-01 03:30:52.000000000,closed,3,Enable createDataFrameFromText to handle timestamp columns
1654,2018-08-29 19:40:01.000000000,2018-08-29 21:17:13.000000000,closed,1,Investigate flaky livy tests
1653,2018-08-29 17:32:46.000000000,2018-08-29 18:08:18.000000000,closed,0,Fix Databricks connection
1652,2018-08-29 09:30:38.000000000,1970-01-01 00:00:00.000000001,open,0,Kano Model in R
1651,2018-08-28 18:57:30.000000000,2018-09-12 20:17:51.000000000,closed,1, org.apache.spark.sql.AnalysisException: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode0(Ljava/lang/String;I)V;py4j.protocol.Py4JJavaError: An error occurred while calling o28.applySchemaToPythonRDD
1650,2018-08-28 05:05:38.000000000,2018-08-29 18:08:18.000000000,closed,4,Databricks connection is broken in master
1649,2018-08-28 03:23:46.000000000,2018-09-12 20:15:46.000000000,closed,3,"Error installing Spark 2.3.0 - ""cannot open URL"""
1648,2018-08-27 10:32:34.000000000,1970-01-01 00:00:00.000000001,open,3,"Error: `x` and `y` must share the same src, set `copy` = TRUE (may be slow)"
1647,2018-08-24 07:15:22.000000000,2018-08-29 10:16:27.000000000,closed,1,Broom for decision tree
1646,2018-08-23 10:27:28.000000000,2018-08-24 00:08:40.000000000,closed,3,Fix Hive support in Spark 2.3
1645,2018-08-22 19:31:39.000000000,2018-08-22 21:55:22.000000000,closed,3,Spark version upgrade breaks install
1644,2018-08-18 06:14:35.000000000,2018-08-22 07:38:08.000000000,closed,6,Broom for ml_bisecting_kmeans() and ml_gaussian_mixture()
1643,2018-08-16 19:52:05.000000000,1970-01-01 00:00:00.000000001,open,1,zero-length key name in map type fails
1642,2018-08-16 16:08:37.000000000,2018-08-20 20:42:11.000000000,closed,1,[TEST] Use kryo serializer by default
1641,2018-08-16 15:37:02.000000000,2018-09-12 20:14:49.000000000,closed,3,Dynamic variable select issue : Shiny reactive error (Maxdiff analysis ) 
1640,2018-08-16 13:27:21.000000000,1970-01-01 00:00:00.000000001,open,1,Cannot pivot (even a subset of) a large dataset due to stage failure
1639,2018-08-15 15:42:04.000000000,2018-08-22 23:55:47.000000000,closed,0,Improvements when Spark shut downs with OutOfMemory
1638,2018-08-15 07:33:36.000000000,2020-06-24 18:15:07.000000000,closed,10,Support Window Frame in Sparklyr
1637,2018-08-15 07:04:16.000000000,2018-08-16 14:19:19.000000000,closed,0,Spelling correction.
1636,2018-08-13 18:13:21.000000000,2018-09-10 20:52:14.000000000,closed,4,Sparklyr streaming does not work
1635,2018-08-11 06:08:00.000000000,2018-08-11 21:49:09.000000000,closed,2,Issues creating spark context with HDP 3.0 Permission denied
1634,2018-08-09 23:55:23.000000000,2018-08-15 00:09:48.000000000,closed,7,broom for ml_kmeans()
1633,2018-08-09 19:56:26.000000000,1970-01-01 00:00:00.000000001,open,2,sparklyr does not use `order_by` argument in lead/lag
1632,2018-08-06 21:05:17.000000000,2018-08-06 21:05:41.000000000,closed,0,MLeap
1631,2018-08-06 21:04:43.000000000,2018-08-06 21:05:06.000000000,closed,0,GraphFrames
1630,2018-08-04 03:08:54.000000000,2018-08-04 10:36:24.000000000,closed,0,Support configuring gateway address and port for Kubernetes
1629,2018-08-04 02:44:42.000000000,2018-08-04 10:35:59.000000000,closed,2,Stream examples and typos
1628,2018-08-03 05:17:46.000000000,2020-04-17 17:09:43.000000000,closed,5,Nested Data
1627,2018-08-02 23:35:23.000000000,2018-12-12 07:32:40.000000000,closed,2,ml_survival_regression fit generates java lang error
1626,2018-07-27 20:04:54.000000000,1970-01-01 00:00:00.000000001,open,0,Update project website with current ML features
1625,2018-07-27 19:04:57.000000000,1970-01-01 00:00:00.000000001,open,1,copy_to doesn't copy entire data
1624,2018-07-27 07:00:30.000000000,2018-09-06 18:52:11.000000000,closed,2,queue in livy_config
1623,2018-07-26 01:03:59.000000000,2018-09-12 05:57:26.000000000,closed,1,Why is db_explain() a NOOP?
1622,2018-07-25 08:20:07.000000000,2018-08-10 17:22:40.000000000,closed,0,ML internals refactoring
1621,2018-07-22 08:49:58.000000000,1970-01-01 00:00:00.000000001,open,6,spark_apply() of spaklyr does not work with tm library
1620,2018-07-21 20:09:25.000000000,2019-02-12 03:07:42.000000000,closed,0,Investigate broom tests
1619,2018-07-21 09:03:57.000000000,2018-07-21 09:30:40.000000000,closed,0,"Examples for corr(), chisquare_test(), gaussian_mixtures() and clustering_evaluator()"
1618,2018-07-20 22:05:28.000000000,2018-08-10 17:22:40.000000000,closed,0,Vector params are printed on separate lines with duplicate labels
1617,2018-07-20 22:03:58.000000000,1970-01-01 00:00:00.000000001,open,0,Consider not printing individual stage info for pipelines by default
1616,2018-07-20 21:51:57.000000000,1970-01-01 00:00:00.000000001,open,1,Printing error when coefficient bounds are specified for `ml_logistic_regression()`
1615,2018-07-20 13:51:42.000000000,2020-04-10 19:30:18.000000000,closed,16,Support complex DataFrame list columns to be mapped to Spark SQL array and struct respectively
1614,2018-07-20 12:40:31.000000000,1970-01-01 00:00:00.000000001,open,0,Clean up files after tests
1613,2018-07-20 11:12:25.000000000,2018-09-10 20:58:32.000000000,closed,1,Using a new spark dataframe in spark_apply
1612,2018-07-20 11:00:21.000000000,1970-01-01 00:00:00.000000001,open,0,testthat_spark_connection() contains an expectation
1611,2018-07-20 04:18:41.000000000,2018-11-02 10:05:35.000000000,closed,7,Implement Arrow
1610,2018-07-18 22:38:16.000000000,2018-07-18 23:27:44.000000000,closed,2,Example for ml_generalized_linear_regression()
1609,2018-07-18 21:32:53.000000000,2018-09-14 09:44:20.000000000,closed,3,[WIP] test for intercept-only logistic model
1608,2018-07-17 20:01:28.000000000,1970-01-01 00:00:00.000000001,open,3,use dynamic executor classloader to support scala runtime functions
1607,2018-07-17 10:37:12.000000000,1970-01-01 00:00:00.000000001,open,1,sample_n after group_by
1606,2018-07-17 08:04:59.000000000,2018-09-13 23:14:27.000000000,closed,1,[WIP] Don't force index numeric labels for classification
1605,2018-07-17 05:00:10.000000000,2018-07-17 07:17:14.000000000,closed,0,Fix download urls for recent spark versions
1604,2018-07-17 04:44:07.000000000,2018-07-17 11:20:59.000000000,closed,0,Address streaming feedback
1603,2018-07-16 20:51:10.000000000,2018-07-18 03:57:15.000000000,closed,5,test if we can fit a model without an intercept
1602,2018-07-16 20:48:11.000000000,2018-07-17 21:10:10.000000000,closed,3,Installing Spark fails because of version mismatches
1601,2018-07-16 19:47:08.000000000,2018-07-17 11:19:29.000000000,closed,2,Don't poll livy session repetitively when validating
1600,2018-07-16 13:23:45.000000000,2018-08-12 20:29:24.000000000,closed,8,Contradicting error with sparklyr and spark 2.3
1599,2018-07-14 10:42:26.000000000,2018-07-17 10:59:16.000000000,closed,0,Support for Kubernetes
1598,2018-07-14 03:29:19.000000000,2018-07-17 07:22:42.000000000,closed,4,Bugfix/logistic coef sign
1597,2018-07-14 00:57:29.000000000,2018-07-14 05:05:31.000000000,closed,4,"get model coefficients, not the function"
1596,2018-07-13 23:33:27.000000000,1970-01-01 00:00:00.000000001,open,11,cannot fit 'intercept only' logistic regression model 
1595,2018-07-13 21:04:52.000000000,1970-01-01 00:00:00.000000001,open,1,Secure Sockets
1594,2018-07-13 03:34:19.000000000,1970-01-01 00:00:00.000000001,open,1,Default `dplyr::left_join()` suffix values create failing joins in `sparklyr`
1593,2018-07-13 01:53:52.000000000,2018-07-13 03:45:43.000000000,closed,0,Fix regression from streaming feature while reading CSV with renamed columns
1592,2018-07-12 21:22:48.000000000,2018-07-13 06:18:26.000000000,closed,0,Run Livy tests into their own travis instance
1591,2018-07-12 01:10:53.000000000,2018-09-13 23:14:27.000000000,closed,9,coefficients from logistic regression have arbitrary sign?
1590,2018-07-11 05:20:12.000000000,2018-07-12 02:12:18.000000000,closed,0,Spark streaming minor fixes
1589,2018-07-10 23:46:03.000000000,2018-07-11 03:59:14.000000000,closed,0,Examples for scalers
1588,2018-07-09 16:15:51.000000000,2018-09-12 20:50:32.000000000,closed,3,Date values are shifted by one day
1587,2018-07-04 15:13:15.000000000,1970-01-01 00:00:00.000000001,open,4,Job aborted due to stage failure: ..... java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z 
1586,2018-07-04 03:37:55.000000000,2018-07-04 22:59:13.000000000,closed,2,Error sparklyr when using copy_to() function
1585,2018-07-03 23:51:54.000000000,2018-07-12 22:15:28.000000000,closed,2,WITH clause not supported in Spark SQL
1584,2018-07-03 08:41:27.000000000,1970-01-01 00:00:00.000000001,open,1,Multiple arrange functions fail with mutate
1583,2018-07-03 06:33:48.000000000,2018-07-03 10:51:03.000000000,closed,1,An example for ml_gradient_boosted_trees()
1582,2018-07-02 14:35:23.000000000,2018-07-02 17:53:55.000000000,closed,0,Fix date collection to use correct UTC conversion
1581,2018-06-29 22:00:23.000000000,1970-01-01 00:00:00.000000001,open,1,Package 'sparklyr' is not available (for R version 3.5.0)
1580,2018-06-29 17:08:15.000000000,1970-01-01 00:00:00.000000001,open,2,RStudio session doesn't release upon completion of Spark job
1579,2018-06-29 16:46:44.000000000,2018-07-13 21:37:39.000000000,closed,1,Investigate Livy performance improvement by upgrading HTTP connection
1578,2018-06-29 14:31:23.000000000,2018-07-02 14:48:22.000000000,closed,8,Support for ml_als with recommendations and pipelines
1577,2018-06-29 01:16:57.000000000,2018-06-29 03:40:49.000000000,closed,0,Fix monitoring hang under Spark 1.6.3
1576,2018-06-29 00:08:33.000000000,2018-06-29 03:40:50.000000000,closed,0,Hang under Spark 1.6 in devel branch using rstudio
1575,2018-06-28 19:50:52.000000000,1970-01-01 00:00:00.000000001,open,7,"Spark connection disconnects, sparklyr hangs and goes to an unmanageable state"
1574,2018-06-27 20:53:45.000000000,2018-06-28 02:53:40.000000000,closed,1,allow passing single-char strings as java.lang.Character args
1573,2018-06-25 21:44:24.000000000,1970-01-01 00:00:00.000000001,open,0,TM using Spark_apply Function is throwing error 
1572,2018-06-22 12:39:45.000000000,2018-06-25 20:14:57.000000000,closed,1,Databricks jdbc connection cannot find redshift driver class using sparklyr
1571,2018-06-22 10:38:42.000000000,2018-06-22 14:55:42.000000000,closed,1,fix minor typos in documentation
1570,2018-06-22 03:48:59.000000000,2018-06-22 05:45:47.000000000,closed,0,Support spark_apply() over empty results with grouped operations
1569,2018-06-20 18:59:49.000000000,2018-07-10 20:08:41.000000000,closed,2,Implement spark streaming
1568,2018-06-20 18:20:24.000000000,2018-06-21 01:24:00.000000000,closed,1,ml_save succeeded but cannot find file
1567,2018-06-20 16:32:53.000000000,1970-01-01 00:00:00.000000001,open,2,OutOfMemoryError when running distinct() after K-means
1566,2018-06-20 14:44:40.000000000,1970-01-01 00:00:00.000000001,open,2,"maybe cast to double instead of decimal(2,1) "
1565,2018-06-20 13:56:11.000000000,2018-06-20 18:54:40.000000000,closed,0,Fix hang in some operations caused by monitored connection
1564,2018-06-20 11:55:52.000000000,2018-06-20 18:54:30.000000000,closed,0,Remove cancellable internal state
1563,2018-06-20 06:09:43.000000000,2018-06-22 13:51:34.000000000,closed,0,Add support for job links in job progress
1562,2018-06-19 07:06:46.000000000,2018-07-17 11:19:29.000000000,closed,2,A minor issue in livy_validate_master 
1561,2018-06-18 23:00:56.000000000,2018-07-02 17:53:56.000000000,closed,1,Date roundtrip unit test fails under UTC+1 time zone
1560,2018-06-18 11:07:39.000000000,2018-09-12 02:41:56.000000000,closed,2,Prefix span implementation is not there?
1559,2018-06-15 20:57:26.000000000,1970-01-01 00:00:00.000000001,open,1,ScalaInteroperability: cannot access attributes on objects in objects
1558,2018-06-15 20:30:41.000000000,1970-01-01 00:00:00.000000001,open,1,Automatic conversion of String arrays
1557,2018-06-14 20:40:47.000000000,1970-01-01 00:00:00.000000001,open,1,Opt out of return value conversion
1556,2018-06-14 14:33:57.000000000,2018-06-14 15:50:42.000000000,closed,0,Improve logging and connection's viewer for Livy
1555,2018-06-14 12:35:26.000000000,1970-01-01 00:00:00.000000001,open,0,Newer versions of livy started using `livy_service_start()` not printing logs
1554,2018-06-14 08:15:10.000000000,2018-06-14 14:31:27.000000000,closed,0,An example for sdf_pivot()
1553,2018-06-13 17:13:12.000000000,2018-06-20 06:04:43.000000000,closed,0,Implement monitored connections
1552,2018-06-13 00:35:19.000000000,2018-06-13 09:55:17.000000000,closed,0,Drop temp views of metadata tables in ml_load()
1551,2018-06-12 23:46:03.000000000,2018-06-13 02:53:02.000000000,closed,0,Add support to read and write orc files to fix #1548
1550,2018-06-12 22:48:20.000000000,2018-06-13 02:54:28.000000000,closed,3,Ignore ml metadata tables to fix #1549
1549,2018-06-12 22:26:28.000000000,2018-06-13 09:55:17.000000000,closed,0,weird ml_model_metadata popping up in rstudio
1548,2018-06-12 22:17:04.000000000,2018-06-13 02:53:02.000000000,closed,5,Is there an example how to write ORC format from sparklyr?
1547,2018-06-12 21:14:56.000000000,2018-08-10 17:22:43.000000000,closed,5,One Vs Rest (LSVC) + Cross Validation doesn't work properly
1546,2018-06-12 12:24:26.000000000,2018-10-07 07:55:43.000000000,closed,0,Async support
1545,2018-06-12 11:34:08.000000000,1970-01-01 00:00:00.000000001,open,3,Spark Streaming from oracle to Cassandra
1544,2018-06-12 11:12:46.000000000,1970-01-01 00:00:00.000000001,open,0,inconsistent users between spark connection and livy session
1543,2018-06-09 17:26:37.000000000,1970-01-01 00:00:00.000000001,open,0,ml_generalized_linear_regression documentation
1542,2018-06-07 17:38:32.000000000,1970-01-01 00:00:00.000000001,open,0,sparklyr can access protected scala attributes
1541,2018-06-07 15:10:02.000000000,2018-06-07 19:19:51.000000000,closed,3,Improve Livy performance for long execution queries
1540,2018-06-07 12:57:47.000000000,2018-09-12 02:18:32.000000000,closed,2,apply UDF with more than one argument in spark_apply() function
1539,2018-06-07 09:22:18.000000000,2018-06-07 15:48:45.000000000,closed,1,Error while connecting Spark with Cassandra DB.
1538,2018-06-07 08:29:46.000000000,1970-01-01 00:00:00.000000001,open,3,Remove unnecessary sleep to improve performance
1537,2018-06-06 18:53:23.000000000,2018-06-06 20:56:45.000000000,closed,0,Add support Livy for MapR
1536,2018-06-06 17:22:43.000000000,2020-04-10 19:31:04.000000000,closed,7,copy_to fails on nested data
1535,2018-06-05 16:20:53.000000000,2018-09-12 02:12:00.000000000,closed,4,Error in spark_connect
1534,2018-06-05 14:24:31.000000000,1970-01-01 00:00:00.000000001,open,1,"are probability functions (pnorm, qnorm) available via sparklyr?"
1533,2018-06-04 20:34:32.000000000,2018-06-07 10:43:25.000000000,closed,4,Support configuring library path in spark_apply()
1532,2018-06-04 18:24:35.000000000,1970-01-01 00:00:00.000000001,open,2,Feature Request: Support spark shell parameters like spark.driver... via normal config
1531,2018-06-02 06:52:17.000000000,2018-09-12 00:42:08.000000000,closed,13,requirement failed: The columns of A don't match the number of elements of x
1530,2018-06-01 22:05:03.000000000,2018-06-07 16:49:56.000000000,closed,4,spark_apply set .libPaths
1529,2018-06-01 05:52:27.000000000,2018-06-01 21:11:23.000000000,closed,1,Examples for ft_binarizer() and ft_bucketrizer()
1528,2018-05-31 21:33:48.000000000,2018-06-01 02:08:25.000000000,closed,0,appveyor should not install sparklyr from github
1527,2018-05-29 18:21:50.000000000,2018-05-30 11:08:04.000000000,closed,2,An example using cross validation
1526,2018-05-29 08:21:37.000000000,2018-09-12 00:37:46.000000000,closed,4,spark_apply is very slow
1525,2018-05-28 22:52:32.000000000,2018-07-18 23:31:57.000000000,closed,5,Kubernetes
1524,2018-05-28 12:33:06.000000000,1970-01-01 00:00:00.000000001,open,3,what is equivalent to isLocalIterator() in sparklyr?
1523,2018-05-27 21:48:16.000000000,2018-06-14 10:04:27.000000000,closed,0,can not connect to sparklyr
1522,2018-05-27 06:42:08.000000000,2018-05-28 22:35:42.000000000,closed,0,Examples for logistic and linear regression
1521,2018-05-25 22:00:04.000000000,2018-05-25 23:48:42.000000000,closed,0,Avoid assigning globals to fix r CMD check warnings
1520,2018-05-25 01:23:05.000000000,2018-05-25 03:20:44.000000000,closed,0,Attempt to fix travis covr escaping
1519,2018-05-24 20:44:19.000000000,2018-05-25 03:21:15.000000000,closed,4,add dynamic config setter/getter
1518,2018-05-24 18:56:55.000000000,2018-05-25 03:20:57.000000000,closed,7,adds support for printing the RDD debug string 
1517,2018-05-24 12:57:05.000000000,2018-07-13 04:52:34.000000000,closed,4,sparklyr show wrong date
1516,2018-05-23 13:59:15.000000000,1970-01-01 00:00:00.000000001,open,6,is.data.frame(tbl_spark) should return TRUE
1515,2018-05-22 18:06:35.000000000,2018-09-12 00:01:52.000000000,closed,2,Optimize performances of glimpse() by adding a LIMIT statement
1514,2018-05-22 03:32:34.000000000,2018-09-14 11:34:35.000000000,closed,0,Don't use NSE in precondition functions
1513,2018-05-22 03:25:29.000000000,2018-08-10 17:22:40.000000000,closed,0,Don't require parameters to be specified for pipeline stage constructors
1512,2018-05-22 02:37:56.000000000,1970-01-01 00:00:00.000000001,open,1,using ft_r_formula with ml_pipelines
1511,2018-05-21 22:48:20.000000000,2018-05-22 04:42:48.000000000,closed,0,Add missing test packages to suggests section
1510,2018-05-21 20:43:25.000000000,2018-05-22 00:03:32.000000000,closed,0,Fix sdf_bind_rows in dplyr 0.7.5
1509,2018-05-21 19:47:33.000000000,2018-05-21 21:20:33.000000000,closed,1,sparklyr kafka stream
1508,2018-05-21 18:43:19.000000000,2018-05-22 02:59:42.000000000,closed,0,Improve spark_connect() version precedence
1507,2018-05-18 19:19:02.000000000,1970-01-01 00:00:00.000000001,open,11,Livy Unable to Access Hive Databases Created in HUE
1506,2018-05-18 17:42:47.000000000,1970-01-01 00:00:00.000000001,open,4,"grep, grepl, and regexpr to sparklyr"
1505,2018-05-18 17:03:11.000000000,2018-06-22 05:45:49.000000000,closed,1,Error in spark_apply when some groups return an empty data.frame
1504,2018-05-18 01:47:09.000000000,2018-09-11 23:42:51.000000000,closed,3,bug when summarizing with character variable
1503,2018-05-17 20:08:29.000000000,1970-01-01 00:00:00.000000001,open,4,'sdf_copy_to()' not properly coping NAs for character and factors
1502,2018-05-17 17:58:22.000000000,2018-05-17 21:05:39.000000000,closed,0,Correct `tidy()` output for linear models
1501,2018-05-17 05:40:10.000000000,2018-05-17 21:05:39.000000000,closed,1,tidy() for linear models gives incorrect statistics
1500,2018-05-16 23:12:42.000000000,2018-05-17 16:41:32.000000000,closed,2,Livy connection curl_fetch_memory timeout
1499,2018-05-16 12:26:34.000000000,1970-01-01 00:00:00.000000001,open,0,Improve spark_apply debugging user experience
1498,2018-05-16 07:38:31.000000000,2018-05-17 04:49:27.000000000,closed,1,Add support for sql editing from connections pane
1497,2018-05-15 20:11:17.000000000,1970-01-01 00:00:00.000000001,open,6,Trouble with spark_read_csv() on YARN 
1496,2018-05-15 13:07:13.000000000,2018-08-24 00:08:40.000000000,closed,41,Hive support breakage in Spark 2.3
1495,2018-05-15 01:09:24.000000000,2018-09-11 22:05:17.000000000,closed,2,ICONV spark_apply
1494,2018-05-14 22:16:26.000000000,1970-01-01 00:00:00.000000001,open,4,Connecting to Livy through Knox
1493,2018-05-14 19:03:36.000000000,2018-05-15 23:35:59.000000000,closed,1,An example for ml_multilayer_perceptron()
1492,2018-05-14 14:20:56.000000000,2018-05-14 17:00:06.000000000,closed,1,The problem with spark_connect()
1491,2018-05-14 08:24:33.000000000,2018-09-11 22:03:21.000000000,closed,6,spark_write_table: save the result to hdfs?
1490,2018-05-13 00:36:40.000000000,2018-05-16 22:25:22.000000000,closed,3,Problems with Rstudio overall
1489,2018-05-12 02:55:41.000000000,2018-05-12 03:20:33.000000000,closed,1,WIP: Use JDK7 in travis to ensure backwards compatibility
1488,2018-05-11 08:21:38.000000000,2018-09-11 21:54:55.000000000,closed,2,Sparklyr with Hadoop SequenceFile input type (key-value pairs)
1487,2018-05-10 22:42:26.000000000,2018-05-12 01:44:31.000000000,closed,0,Fix test under appveyor for windows coverage
1486,2018-05-10 22:26:09.000000000,2018-05-10 22:43:06.000000000,closed,0,Support for Spark 2.3 in local windows clusters
1485,2018-05-10 18:29:15.000000000,1970-01-01 00:00:00.000000001,open,5,connecting to Livy on a remote kerberized cluster.
1484,2018-05-10 16:54:33.000000000,2018-05-10 22:33:56.000000000,closed,2,An example for ml_evaluator()
1483,2018-05-10 16:28:35.000000000,2018-05-10 22:31:40.000000000,closed,2,An example for ml_random_forest()
1482,2018-05-10 00:38:37.000000000,2019-02-06 03:39:54.000000000,closed,2,Invoke toDebugString() with ml_decision_tree
1481,2018-05-09 18:16:53.000000000,1970-01-01 00:00:00.000000001,open,3,Kolmogorov-Smirnov test
1480,2018-05-08 19:37:12.000000000,1970-01-01 00:00:00.000000001,open,1,Scala interop improvements
1479,2018-05-07 21:22:51.000000000,2018-05-08 21:05:39.000000000,closed,1,An example for ml_decision_tree()
1478,2018-05-07 20:57:14.000000000,2018-05-08 21:03:47.000000000,closed,1,An example for ml_bisecting_kmeans()
1477,2018-05-07 10:16:20.000000000,2018-05-10 22:12:20.000000000,closed,5,Error: java.lang.IllegalArgumentException: Can not create a Path from an empty string
1476,2018-05-06 08:36:32.000000000,1970-01-01 00:00:00.000000001,open,2,Consider adding repositories setting to dependencies for extensions
1475,2018-05-06 08:22:48.000000000,1970-01-01 00:00:00.000000001,open,13,Support sparklyr + sf
1474,2018-05-05 23:18:20.000000000,1970-01-01 00:00:00.000000001,open,3,unable to connect to spark
1473,2018-05-05 20:53:54.000000000,2018-05-10 22:43:08.000000000,closed,7,Failed while connecting to sparklyr to port (8880) for sessionid (92513): Gateway in port (8880) did not respond.
1472,2018-05-05 19:10:36.000000000,2018-05-05 20:37:53.000000000,closed,0,Add support for https in resource manager when using yarn cluster
1471,2018-05-04 22:19:24.000000000,2018-05-04 23:07:11.000000000,closed,0,Fix ML tests to resolve 1.6 travis fails
1470,2018-05-04 21:24:47.000000000,2018-05-04 23:55:17.000000000,closed,0,Fix Livy under spark 1.6
1469,2018-05-04 21:18:36.000000000,2018-05-04 22:05:09.000000000,closed,0,Fix return status in travis script
1468,2018-05-03 00:04:39.000000000,2018-05-03 05:02:18.000000000,closed,0,Example: ml_naive_bayes()
1467,2018-05-02 20:00:00.000000000,2018-05-02 20:02:31.000000000,closed,0,Merge sparklyr 0.8.1 branch
1466,2018-05-02 18:43:48.000000000,1970-01-01 00:00:00.000000001,open,0,spark_write_csv fails with java.lang.NoSuchMethodError for Spark 1.6.3 and Scala 2.10
1465,2018-05-02 03:57:30.000000000,2018-05-02 05:11:28.000000000,closed,1,Keeping old Backend.main() shim for databricks mode
1464,2018-05-02 02:35:32.000000000,2018-05-02 20:18:38.000000000,closed,2,more efficient csv_string serialization
1463,2018-05-02 01:01:32.000000000,1970-01-01 00:00:00.000000001,open,1,collect fails outside of spark
1462,2018-05-01 21:21:06.000000000,2018-05-02 03:34:32.000000000,closed,4,Allow missing master for Databricks connections
1461,2018-05-01 19:59:51.000000000,2018-05-02 03:35:06.000000000,closed,2,Removal of spark_connect() default argument breaks Databricks support
1460,2018-05-01 17:52:34.000000000,1970-01-01 00:00:00.000000001,open,6,Add document_topic matrix to output
1459,2018-05-01 01:40:35.000000000,1970-01-01 00:00:00.000000001,open,3,yarn.resourcemanager.webapp.https.address.rm16 using 8090 port
1458,2018-05-01 01:27:01.000000000,2018-05-01 02:40:58.000000000,closed,0,Add `ml_validation_metrics()`
1457,2018-04-30 20:26:04.000000000,1970-01-01 00:00:00.000000001,open,8,Arrow
1456,2018-04-30 02:06:31.000000000,1970-01-01 00:00:00.000000001,open,0,Spark SQL expressions in dplyr statements require double escaping
1455,2018-04-30 00:09:15.000000000,2018-04-30 22:26:32.000000000,closed,1,An example of ml_pca()
1454,2018-04-29 21:40:49.000000000,1970-01-01 00:00:00.000000001,open,3,Spark_Install Allows Installation Of Unsupported Versions of Spark Without Warning
1453,2018-04-28 01:11:38.000000000,2018-08-10 17:22:39.000000000,closed,0,ML model object member semantics
1452,2018-04-28 00:44:35.000000000,2018-04-28 01:26:57.000000000,closed,0,default to spark 2.3
1451,2018-04-28 00:38:18.000000000,2018-04-28 01:04:18.000000000,closed,0,Support list of transformers in `ml_transform()`
1450,2018-04-27 23:20:53.000000000,2018-04-28 00:15:08.000000000,closed,0,ML tuning improvements
1449,2018-04-27 22:12:06.000000000,2018-04-28 01:26:57.000000000,closed,0,Default to version 2.3.0 for local connections
1448,2018-04-27 19:43:08.000000000,2018-04-27 20:21:59.000000000,closed,0,Support `feature_subset_strategy` in GBT algorithms
1447,2018-04-27 19:00:38.000000000,2018-04-27 19:34:22.000000000,closed,0,Add `ft_string_indexer_model()` and `string_order_type` to `ft_string_indexer()`
1446,2018-04-27 17:23:56.000000000,2018-04-28 00:15:08.000000000,closed,0,Parallelism for model tuning
1445,2018-04-27 17:23:14.000000000,2018-04-27 20:21:58.000000000,closed,0,Add feature_subset_strategy for gbt
1444,2018-04-27 02:08:23.000000000,2018-04-28 01:04:18.000000000,closed,0,Support ml_transform() to take a list of transformers
1443,2018-04-27 01:35:56.000000000,2018-04-27 19:34:22.000000000,closed,0,Support string_order_type in StringIndexer
1442,2018-04-27 01:22:23.000000000,2018-04-27 19:34:22.000000000,closed,0,Add ft_string_indexer_model()
1441,2018-04-27 00:43:29.000000000,2018-04-28 00:15:09.000000000,closed,0,Documentation error in ?ml_evaluator
1440,2018-04-27 00:22:06.000000000,2018-04-27 01:09:24.000000000,closed,0,Add ml_feature_importances()
1439,2018-04-26 19:49:08.000000000,2018-04-26 22:49:25.000000000,closed,0,Invoke method dispatch improvements
1438,2018-04-26 09:09:29.000000000,2018-04-26 09:11:18.000000000,closed,2,Yarn cluster mode connection fails with error `KaTeX parse error`
1437,2018-04-25 17:10:56.000000000,2018-04-30 20:57:44.000000000,closed,2,spark_apply performance
1436,2018-04-25 12:15:30.000000000,2018-04-27 01:09:25.000000000,closed,3,ml_tree_feature_importance() doesn't work for pipeline model stage
1435,2018-04-24 22:00:52.000000000,2018-04-25 18:26:56.000000000,closed,2,Issue with reference pages in the site
1434,2018-04-24 17:16:15.000000000,1970-01-01 00:00:00.000000001,open,1,sparklyr packages install error
1433,2018-04-24 02:08:33.000000000,2018-04-27 22:52:18.000000000,closed,6,"skip.header.line.count not respected, results in header row in data"
1432,2018-04-23 20:22:01.000000000,1970-01-01 00:00:00.000000001,open,11,spark_apply not working 
1431,2018-04-23 12:40:32.000000000,1970-01-01 00:00:00.000000001,open,0,Problem for indexing after a sdf_separate_column
1430,2018-04-23 10:03:59.000000000,2018-04-26 09:14:52.000000000,closed,3,Connecting to Spark using cluster mode Hive connectivity failed.
1429,2018-04-22 02:00:41.000000000,2018-04-26 09:40:26.000000000,closed,2,Including an example for ml_kmeans()
1428,2018-04-21 20:01:30.000000000,2018-09-11 11:19:33.000000000,closed,3,spark_connect and spark_config not responding (Win7 & 10)
1427,2018-04-20 18:33:06.000000000,1970-01-01 00:00:00.000000001,open,5,Using group_by within spark_apply
1426,2018-04-20 00:19:22.000000000,1970-01-01 00:00:00.000000001,open,2,spark can't recognize tally
1425,2018-04-19 17:53:29.000000000,2018-04-27 22:53:29.000000000,closed,2,GLM when observations of one variable are all the same
1424,2018-04-19 17:03:23.000000000,2018-04-19 18:06:12.000000000,closed,1,default hive database
1423,2018-04-19 16:51:57.000000000,1970-01-01 00:00:00.000000001,open,0,setting the timezone?
1422,2018-04-18 23:54:37.000000000,1970-01-01 00:00:00.000000001,open,0,spark and scala versions in java/sparkhello-%s-%s.jar in spark_dependencies method causing classpath issues 
1421,2018-04-18 00:04:44.000000000,1970-01-01 00:00:00.000000001,open,2,Cannot write spark table due to wrong FS
1420,2018-04-17 23:03:46.000000000,2018-04-17 23:26:24.000000000,closed,0,FileNotFoundException while querying tables with missing partitions
1419,2018-04-17 06:12:33.000000000,2020-01-13 19:59:58.000000000,closed,1,Support writing TFRecord files
1418,2018-04-16 15:25:02.000000000,2018-04-30 20:43:07.000000000,closed,1,Function reference pages not loading properly
1417,2018-04-14 03:50:11.000000000,2018-04-16 19:16:57.000000000,closed,0,Small livy perf improvement by caching spark version
1416,2018-04-13 20:14:29.000000000,2018-04-13 23:28:58.000000000,closed,8,Support ML for Livy
1415,2018-04-13 19:52:33.000000000,1970-01-01 00:00:00.000000001,open,0,src_tbls() in databases
1414,2018-04-13 19:49:15.000000000,1970-01-01 00:00:00.000000001,open,4,sdf_repartition not producing expected number of partitions
1413,2018-04-13 16:07:18.000000000,1970-01-01 00:00:00.000000001,open,1,sparklyr yarn cluster mode fail to connect - httr kerberos authentication
1412,2018-04-13 08:16:10.000000000,2018-04-13 17:24:45.000000000,closed,0,`spark_table_name()` handles multiline expressions
1411,2018-04-13 07:50:14.000000000,2018-04-13 08:42:39.000000000,closed,0,Add `ml_vocabulary()` and `ml_topics_matrix()`
1410,2018-04-13 06:59:28.000000000,2018-04-13 07:44:09.000000000,closed,0,Dispatch correct constructor for decision tree classification model
1409,2018-04-13 06:35:20.000000000,2018-04-13 07:40:49.000000000,closed,0,ml.stat functions
1408,2018-04-12 22:12:48.000000000,2018-04-13 01:57:59.000000000,closed,0,Detect yarn cluster from config
1407,2018-04-11 21:56:56.000000000,2018-04-11 22:41:17.000000000,closed,0,Add support for offset in GLM
1406,2018-04-11 00:49:03.000000000,2018-04-11 01:32:26.000000000,closed,0,output message for ml_save()
1405,2018-04-10 22:55:09.000000000,2018-04-11 00:35:36.000000000,closed,0,Don't capture calls in ml routines
1404,2018-04-10 13:36:54.000000000,2018-04-13 01:58:01.000000000,closed,2,sparklyr yarn cluster mode fail to connect to gateway - connection timeout
1403,2018-04-10 05:35:48.000000000,2018-04-10 07:50:51.000000000,closed,0,Add support to collect performance profiles in spark_apply()
1402,2018-04-10 03:44:02.000000000,2018-04-10 04:25:46.000000000,closed,0,Extend fix to support date-times in spark_apply()
1401,2018-04-10 00:25:52.000000000,2018-04-13 07:44:10.000000000,closed,0,ml_tree_feature_importance produces error for decision tree models
1400,2018-04-10 00:08:26.000000000,2018-04-10 02:31:05.000000000,closed,0,Add support for Livy 0.4 and Livy 0.5
1399,2018-04-09 22:17:53.000000000,2018-04-10 00:03:25.000000000,closed,0,Fix and reenable deactivated Spark 2.3.0 tests
1398,2018-04-09 19:34:34.000000000,2018-04-17 17:49:35.000000000,closed,1,Adds support for correlate
1397,2018-04-09 13:29:58.000000000,1970-01-01 00:00:00.000000001,open,0,db_analyze is throwing an error
1396,2018-04-08 22:57:42.000000000,2018-04-11 22:41:18.000000000,closed,0,Add offset argument for glm
1395,2018-04-06 21:34:20.000000000,2018-09-12 20:49:53.000000000,closed,12,support for Java `char` type
1394,2018-04-06 00:53:20.000000000,2018-04-06 01:19:59.000000000,closed,0,ml_ helper functions call capture
1393,2018-04-06 00:35:49.000000000,2018-04-11 00:35:36.000000000,closed,1,Remove call capturing from ml_ functions
1392,2018-04-05 23:53:49.000000000,2018-04-05 23:53:58.000000000,closed,0,update NEWS and bump version
1391,2018-04-05 23:17:15.000000000,2018-04-10 00:03:26.000000000,closed,0,Investigate failing tests under 2.3
1390,2018-04-05 01:04:10.000000000,1970-01-01 00:00:00.000000001,open,5,Spark job failed with No space left on device while plenty of space is available
1389,2018-04-04 19:36:37.000000000,1970-01-01 00:00:00.000000001,open,2,spark_read_parquet() loads data in different format than expected
1388,2018-04-04 15:02:05.000000000,1970-01-01 00:00:00.000000001,open,0,Sparklyr not connecting to Mesos
1387,2018-04-04 00:16:54.000000000,2018-04-04 08:15:15.000000000,closed,0,Support invoke_static() with package objects
1386,2018-04-04 00:09:29.000000000,2018-04-13 17:24:46.000000000,closed,1,Cryptic warning in sdf_copy_to()
1385,2018-04-03 08:05:33.000000000,2018-04-04 02:01:22.000000000,closed,4,Enable Kerberos authentication with Livy
1384,2018-04-02 01:58:32.000000000,2018-04-04 08:15:16.000000000,closed,9,access to scala singletons
1383,2018-04-01 01:39:37.000000000,1970-01-01 00:00:00.000000001,open,10,"Java version detected but couldn't parse version from: java version ""10"" 2018-03-20"
1382,2018-03-30 08:20:59.000000000,1970-01-01 00:00:00.000000001,open,2,Improve `spark_apply()` performance
1381,2018-03-27 22:02:16.000000000,2018-04-04 01:05:55.000000000,closed,0,Export spark_connection and spark_jobj classes
1380,2018-03-27 21:03:45.000000000,1970-01-01 00:00:00.000000001,open,0,Informative message on connection
1379,2018-03-27 19:12:28.000000000,2018-03-27 21:01:20.000000000,closed,0,remove spark_connect() master arg default
1378,2018-03-27 18:26:04.000000000,2020-04-15 21:02:07.000000000,closed,4,Support for dataframe operations on nested columns
1377,2018-03-27 07:21:18.000000000,2018-03-27 07:59:46.000000000,closed,0,Support roundtrip of date under spark_apply()
1376,2018-03-27 07:03:40.000000000,2018-03-27 07:59:47.000000000,closed,0,Dates not retrieved as dates `spark_apply()`
1375,2018-03-26 21:50:39.000000000,2018-04-05 23:49:48.000000000,closed,2,Spark 2.3 support
1374,2018-03-26 21:15:48.000000000,2018-04-04 01:05:55.000000000,closed,2,"The ""spark_connection"" and ""spark_jobj"" S4 classes are not exported"
1373,2018-03-26 21:13:49.000000000,2018-05-02 03:34:42.000000000,closed,0,spark_connection() does not use default value for 'master'
1372,2018-03-23 18:31:31.000000000,1970-01-01 00:00:00.000000001,open,9,sdf_copy_to Issue
1371,2018-03-23 18:27:18.000000000,1970-01-01 00:00:00.000000001,open,0,Reading csv file in fixed columns
1370,2018-03-23 07:12:45.000000000,2018-03-24 02:19:21.000000000,closed,0,spark_install related usability improvements
1369,2018-03-23 02:42:51.000000000,1970-01-01 00:00:00.000000001,open,5,Livy session times out
1368,2018-03-23 02:12:01.000000000,1970-01-01 00:00:00.000000001,open,0,Follow tidyverse style guide for error and warning messages
1367,2018-03-23 00:50:17.000000000,2018-03-23 04:17:56.000000000,closed,0,Fix a could serialization issues related to NAs
1366,2018-03-22 23:58:52.000000000,2018-03-23 04:17:56.000000000,closed,0,`spark_apply()` fails for `NA`s due to dates serialization issue
1365,2018-03-22 23:49:03.000000000,2018-03-23 04:17:56.000000000,closed,0,`spark_apply()` fails for `NA`s due to serialization issue
1364,2018-03-22 23:07:56.000000000,2018-03-22 23:43:03.000000000,closed,0,Remove NSE usage in cbind() and sdf_bind_cols() implementation
1363,2018-03-21 21:42:26.000000000,2018-03-22 23:43:03.000000000,closed,0,Unexpected behavior in `sdf_bind_cols()`
1362,2018-03-21 20:57:16.000000000,1970-01-01 00:00:00.000000001,open,2,Consider adding performance metrics for folds in ml_cross_validator_model()
1361,2018-03-21 04:13:41.000000000,2018-03-23 05:47:08.000000000,closed,2,Trouble connecting to sparklyr from Rstudio
1360,2018-03-18 18:58:27.000000000,2018-03-19 17:21:58.000000000,closed,2,YARN site url fix
1359,2018-03-16 20:40:16.000000000,1970-01-01 00:00:00.000000001,open,0,Consider reporting `spark_apply` execution time in worker logs
1358,2018-03-16 20:37:46.000000000,1970-01-01 00:00:00.000000001,open,0,Consider supporting worker logs in `spark_log` and RStudio integration.
1357,2018-03-16 20:36:04.000000000,1970-01-01 00:00:00.000000001,open,0,Consider reporting structured connection failure information
1356,2018-03-16 19:58:11.000000000,1970-01-01 00:00:00.000000001,open,3,Can idle sparklyr sessions be cleaned up?
1355,2018-03-16 13:30:15.000000000,2018-03-16 17:47:57.000000000,closed,1,Error: Invalid argument to --conf: spark.jars.ivy
1354,2018-03-16 04:18:42.000000000,1970-01-01 00:00:00.000000001,open,0,It would be helpful if Sparklyr were a bit more DBI compliant
1353,2018-03-14 19:59:14.000000000,2018-04-13 08:42:39.000000000,closed,0,Map term indices to terms ft_count_vectorizer
1352,2018-03-14 15:31:11.000000000,1970-01-01 00:00:00.000000001,open,1,Wrong Column names generated by sdf_pivot
1351,2018-03-14 00:59:27.000000000,2018-03-14 01:55:47.000000000,closed,0,Adds pipeline article
1350,2018-03-13 22:56:42.000000000,1970-01-01 00:00:00.000000001,open,0,Print output for SQL transformer shouldn't have column name header
1349,2018-03-12 20:25:24.000000000,2018-03-13 17:54:47.000000000,closed,12,How to move customize stop words in ft_stop_words_remover??
1348,2018-03-12 20:24:17.000000000,2018-04-11 01:32:26.000000000,closed,0,ml_save() returns NULL when finished
1347,2018-03-11 23:24:51.000000000,2018-05-03 23:09:40.000000000,closed,3,Problem to connect to rsparkling using standalone 
1346,2018-03-10 04:56:51.000000000,2018-03-13 01:23:13.000000000,closed,2,Cannot locate hive databases.
1345,2018-03-09 17:01:02.000000000,1970-01-01 00:00:00.000000001,open,4,Unable to Install Package Requiring to Load sparklyr ML Model
1344,2018-03-09 03:21:24.000000000,2018-03-09 03:46:00.000000000,closed,0,Fix MLib links
1343,2018-03-09 02:04:28.000000000,2018-03-09 02:32:56.000000000,closed,0,Updates NEWS
1342,2018-03-08 21:20:28.000000000,1970-01-01 00:00:00.000000001,open,0,Unclear error 8880 connected to an error in the dependencies file
1341,2018-03-08 14:24:16.000000000,2018-03-08 17:36:54.000000000,closed,1,  ml_tree_feature_importance() not supported for list
1340,2018-03-05 21:26:32.000000000,2018-04-05 23:49:49.000000000,closed,1,Model summary for multinomial logistic regression
1339,2018-03-05 21:21:49.000000000,2018-04-05 23:49:49.000000000,closed,0,Multiple column support in bucketizer
1338,2018-03-05 21:21:20.000000000,2018-04-05 23:49:49.000000000,closed,0,Multiple column support in quantile discretizer
1337,2018-03-05 21:20:31.000000000,2019-05-03 06:37:43.000000000,closed,1,OneHotEncoder is an Estimator in Spark 2.3
1336,2018-03-05 21:11:21.000000000,2018-04-05 23:49:49.000000000,closed,0,Feature hasher
1335,2018-03-05 21:09:27.000000000,2018-04-05 23:49:48.000000000,closed,0,Robust regression algorithms
1334,2018-03-05 21:07:58.000000000,1970-01-01 00:00:00.000000001,open,1,Image support
1333,2018-03-05 21:07:23.000000000,2018-04-05 23:49:50.000000000,closed,0,Clustering evaluator
1332,2018-03-05 16:21:22.000000000,2018-04-13 20:24:25.000000000,closed,7, FPGrowth algorithm invoke issue
1331,2018-03-02 18:51:12.000000000,1970-01-01 00:00:00.000000001,open,0,"""java.lang.IllegalArgumentException: invalid method ..."" when both trait and object are defined"
1330,2018-03-01 22:04:02.000000000,2018-03-02 22:20:09.000000000,closed,8,make sdf_mutate friendlier and more predictable
1329,2018-03-01 21:53:24.000000000,2018-03-21 19:06:27.000000000,closed,1,current design of sdf_mutate makes extensions awkward
1328,2018-03-01 01:53:58.000000000,1970-01-01 00:00:00.000000001,open,0,Weird NA Handling
1327,2018-02-28 19:09:43.000000000,2018-04-30 20:27:03.000000000,closed,3,What are the Apache Arrow integration plans?
1326,2018-02-27 22:27:58.000000000,2018-03-01 02:09:59.000000000,closed,4,Hive's rand for sparklyr syntax
1325,2018-02-26 22:32:37.000000000,1970-01-01 00:00:00.000000001,open,0,dplyr::top_n fails with non-positive weight
1324,2018-02-26 19:00:00.000000000,1970-01-01 00:00:00.000000001,open,8,Cannot pass data as a Scala List object
1323,2018-02-26 16:33:15.000000000,2018-02-27 23:49:01.000000000,closed,3,nrow no longer working...
1322,2018-02-26 13:46:37.000000000,1970-01-01 00:00:00.000000001,open,5,Spark via sparklyr fails to work efficiently with very wide dataframes
1321,2018-02-24 02:08:55.000000000,2018-04-27 02:11:52.000000000,closed,3,serialization date filtering in Sparklyr 0.7?
1320,2018-02-23 20:50:49.000000000,1970-01-01 00:00:00.000000001,open,0,Spark_apply fails on permissions error
1319,2018-02-23 08:18:11.000000000,2018-04-30 20:22:58.000000000,closed,1,How to add quotes when using spark_write_csv
1318,2018-02-23 04:12:29.000000000,2018-04-30 20:18:48.000000000,closed,0,Typo in sparklyr.yarn.cluster.hostadddress.timeout
1317,2018-02-22 12:46:06.000000000,1970-01-01 00:00:00.000000001,open,3,"Exception in thread ""main"" java.lang.IllegalArgumentException: Malformed \uxxxx encoding."
1316,2018-02-22 09:13:48.000000000,1970-01-01 00:00:00.000000001,open,1,Investigate large file errors under `copy_to()`
1315,2018-02-21 23:26:19.000000000,2020-05-11 15:52:13.000000000,closed,4,Consider adding support for nested lists in spark_apply data frame
1314,2018-02-21 23:25:08.000000000,2018-02-22 03:17:16.000000000,closed,0,Avoid using factors in the data frame provided by spark_apply
1313,2018-02-21 23:02:27.000000000,2018-02-22 03:17:17.000000000,closed,2,Avoid factors in provided data frame under spark_apply()
1312,2018-02-20 15:33:51.000000000,2018-09-01 03:30:52.000000000,closed,8,Error while encoding: java.lang.RuntimeException: java.lang.String is not a valid external type for schema of timestamp
1311,2018-02-20 05:04:52.000000000,2020-04-15 21:15:45.000000000,closed,2,Can read data from nested json file on first layer but not deeper layers
1310,2018-02-19 17:17:42.000000000,1970-01-01 00:00:00.000000001,open,1,"Datetime support seems only one-way, missing conversion support from R to Spark"
1309,2018-02-18 11:00:04.000000000,2018-02-18 20:17:21.000000000,closed,0,ml_default_stop_words() default to English
1308,2018-02-18 10:10:51.000000000,2018-02-18 10:44:47.000000000,closed,0,Allow sdf_predict() to take a transformer as the first argument
1307,2018-02-17 03:11:09.000000000,2018-02-17 06:23:55.000000000,closed,0,Fix sample_n() and sample_frac() to work with nontrivial queries
1306,2018-02-16 05:00:37.000000000,2018-02-22 20:40:38.000000000,closed,1,Data Processing and Filtering null/NaN values on a Spark dataframe
1305,2018-02-15 09:04:03.000000000,2018-02-16 07:48:55.000000000,closed,0,Add support for `spark_apply()` in Livy connections
1304,2018-02-14 14:59:33.000000000,2018-02-14 18:35:00.000000000,closed,1,Change livy_config_auth to livy_config in README.(Rmd|md)
1303,2018-02-13 21:29:17.000000000,2018-02-13 22:48:18.000000000,closed,0,Fix regression in response-features syntax for ml_ functions
1302,2018-02-13 20:50:54.000000000,2018-02-13 22:48:18.000000000,closed,4,ml_decision_tree failing with response-features syntax
1301,2018-02-11 06:50:01.000000000,1970-01-01 00:00:00.000000001,open,0,org.apache.spark.SparkException: Failed merging schema of file
1300,2018-02-10 01:03:14.000000000,2018-04-13 23:29:17.000000000,closed,1,Livy with MLib
1299,2018-02-09 17:56:07.000000000,1970-01-01 00:00:00.000000001,open,5,sample_n() fails after select()
1298,2018-02-09 08:26:42.000000000,2018-02-09 08:47:45.000000000,closed,0,Avoid using temp folder for spark_apply bootstrap script
1297,2018-02-09 05:02:36.000000000,2018-02-17 00:15:01.000000000,closed,2,"Using ft_bucketizer() throws an error - overscope_eval_next(overscope, expr)"
1296,2018-02-09 02:44:46.000000000,1970-01-01 00:00:00.000000001,open,0,support config sparklyr.shell.properties-file on sparklyr side
1295,2018-02-08 14:15:09.000000000,2018-02-22 04:48:12.000000000,closed,1,`spark_apply()` collects string columns to factor
1294,2018-02-06 18:57:08.000000000,1970-01-01 00:00:00.000000001,open,3,Train Tensor Flow model with sparklyr
1293,2018-02-06 07:52:17.000000000,2018-02-06 23:18:17.000000000,closed,11,is ft_regex_tokenizer ready for use?
1292,2018-02-06 00:01:14.000000000,2018-02-06 00:01:24.000000000,closed,0,bump version and add NEWS for #1291
1291,2018-02-05 23:37:00.000000000,2018-02-05 23:58:00.000000000,closed,0,Fix regression in ml_kmeans() for 1.6.x
1290,2018-02-05 21:27:06.000000000,2018-02-06 14:40:37.000000000,closed,1,driver logs on yarn client-mode
1289,2018-02-05 19:50:12.000000000,2018-09-10 21:21:57.000000000,closed,8,Can't pull result back from Spark
1288,2018-02-03 11:47:02.000000000,2018-02-05 23:58:00.000000000,closed,0,ml_kmeans() support in 1.6.x
1287,2018-02-03 10:49:21.000000000,2018-02-18 10:44:47.000000000,closed,3,"Consider bringing back `sdf_predict(model, tbl)` signature"
1286,2018-02-03 03:53:04.000000000,2019-10-19 21:08:57.000000000,closed,9,Spark NLP
1285,2018-02-03 03:42:59.000000000,2018-02-13 21:47:32.000000000,closed,2,"Spark connection hung showing ""Loading Objects"" message"
1284,2018-02-03 00:51:00.000000000,1970-01-01 00:00:00.000000001,open,10,Support [ bracket indexing
1283,2018-02-02 17:57:35.000000000,2018-05-25 16:29:54.000000000,closed,1,Fail to run sparklyr yarn-cluster model multiple job with Rmarkdown simultaneously
1282,2018-02-02 14:48:31.000000000,1970-01-01 00:00:00.000000001,open,3,include binaries for netlib-java?
1281,2018-02-02 11:48:21.000000000,1970-01-01 00:00:00.000000001,open,0,Consider making temp tables visible
1280,2018-02-02 05:17:19.000000000,2018-02-18 20:17:21.000000000,closed,0,ml_default_stop_words() should use English list by default
1279,2018-02-02 00:22:14.000000000,2020-07-30 23:29:03.000000000,closed,0,Better support for regular expressions with dplyr queries
1278,2018-02-02 00:20:37.000000000,2018-02-09 08:47:45.000000000,closed,0,Consider moving `sparkworker.R` from `/tmp` to `Spark.Files`
1277,2018-02-01 19:51:02.000000000,1970-01-01 00:00:00.000000001,open,0,Website links to MLlib wrapper functions give 404 errors
1276,2018-01-31 12:55:14.000000000,2018-01-31 12:59:40.000000000,closed,0,sparklyr fail to run yarn-cluster mode on Hadoop 2.6.0-cdh5.11.1
1275,2018-01-30 13:17:47.000000000,1970-01-01 00:00:00.000000001,open,0,spark_read_parquet file path issue
1274,2018-01-26 22:02:05.000000000,2018-01-26 22:05:33.000000000,closed,1,fastparquet.write() to s3 fails from a Windows operating system (with file_scheme='hive')
1273,2018-01-26 05:53:55.000000000,2018-01-26 11:54:05.000000000,closed,0,Fix `livy.session.start.timeout` under Livy
1272,2018-01-26 05:15:33.000000000,1970-01-01 00:00:00.000000001,open,0,Consider improving memory footprint under spark_apply()
1271,2018-01-26 00:31:07.000000000,2018-01-26 01:05:36.000000000,closed,0,Support launching custom command before starting worker roles
1270,2018-01-26 00:28:20.000000000,2018-01-26 11:54:05.000000000,closed,1,"Can not set ""livy.session.start.timeout"""
1269,2018-01-25 19:51:54.000000000,1970-01-01 00:00:00.000000001,open,0,spark_apply in distributed-r vignette
1268,2018-01-25 02:02:51.000000000,2018-01-25 02:30:35.000000000,closed,0,Add support for spark_apply() to launch non vanilla workers
1267,2018-01-24 23:15:32.000000000,2018-05-08 05:01:01.000000000,closed,0,Consider NSE/tidyselect for exported functions
1266,2018-01-23 21:58:38.000000000,2019-06-02 22:26:00.000000000,closed,8,Odd Error: !is.null(statementReponse$output) is not TRUE
1265,2018-01-23 20:53:53.000000000,2018-01-23 21:21:40.000000000,closed,0,Adds cluster mode section
1264,2018-01-23 19:00:09.000000000,2018-01-23 19:55:09.000000000,closed,0,Content cleanup
1263,2018-01-23 02:20:45.000000000,2018-01-23 02:55:42.000000000,closed,0,return tbl_spark for association rules and frequent itemsets
1262,2018-01-22 22:53:43.000000000,2018-01-22 23:37:54.000000000,closed,0,Fix input_cols printing for feature transformers
1261,2018-01-20 05:46:46.000000000,2018-01-20 10:57:16.000000000,closed,1,Consider using default formula in all ml functions
1260,2018-01-20 05:06:52.000000000,2018-01-20 12:03:29.000000000,closed,1,Support loading models on cluster
1259,2018-01-20 04:10:34.000000000,2018-01-20 05:18:55.000000000,closed,1,compute() fails
1258,2018-01-20 02:23:04.000000000,1970-01-01 00:00:00.000000001,open,3,spark_write_table() unable to append to existing Hive table
1257,2018-01-20 00:51:08.000000000,2018-01-20 01:17:18.000000000,closed,0,Informative error when user specifies formula in ml_ routines without tbl_spark
1256,2018-01-19 21:41:45.000000000,2018-01-19 23:12:06.000000000,closed,0,Increase test coverage for ML functions and various fixes
1255,2018-01-19 21:29:24.000000000,2018-01-19 23:45:11.000000000,closed,0,Fixes #1075
1254,2018-01-19 13:57:23.000000000,2018-01-19 15:30:42.000000000,closed,0,Enable code coverage for worker role
1253,2018-01-19 10:41:36.000000000,2018-01-19 13:49:30.000000000,closed,0,Add support for spark 2.2.1
1252,2018-01-19 05:27:01.000000000,2018-01-19 11:04:50.000000000,closed,0,Add support for dates in `copy_to()`
1251,2018-01-19 04:05:16.000000000,2018-01-20 01:17:19.000000000,closed,0,Provide informative error when formula is passed to ml_ routines when first argument is not tbl_spark
1250,2018-01-19 03:59:19.000000000,2018-01-19 04:29:19.000000000,closed,0,fix base table name discovery in ft_extract_sql() to fix #1249
1249,2018-01-19 03:09:21.000000000,2018-01-19 04:29:20.000000000,closed,0,ft_dplyr_transformer() fails when rendered SQL doesn't quote table name with backticks
1248,2018-01-19 00:37:01.000000000,2018-03-28 19:15:46.000000000,closed,0,Skip tests on CRAN by default
1247,2018-01-19 00:33:06.000000000,2018-04-13 07:40:50.000000000,closed,2,Add ml.stat functions
1246,2018-01-19 00:26:25.000000000,2018-01-19 00:52:17.000000000,closed,0,Add ft_vector_indexer()
1245,2018-01-18 12:35:09.000000000,2018-01-18 13:14:43.000000000,closed,0,Implement helper functions for model methods
1244,2018-01-18 11:33:22.000000000,2018-01-18 23:51:46.000000000,closed,0,Remove dead code and adds tests to improve code coverage
1243,2018-01-18 06:07:42.000000000,2018-01-18 07:14:29.000000000,closed,0,Fix base64 encoding use as regression from using base64enc package
1242,2018-01-18 05:02:38.000000000,2018-01-18 06:02:47.000000000,closed,0,Enable Livy tests in Travis
1241,2018-01-18 04:20:08.000000000,2018-01-18 05:33:48.000000000,closed,0,Fix crash during immediate reconnect
1240,2018-01-18 04:02:10.000000000,2018-01-19 00:52:17.000000000,closed,0,Add VectorIndexer
1239,2018-01-18 02:55:15.000000000,1970-01-01 00:00:00.000000001,open,2,weighted average function
1238,2018-01-18 02:13:27.000000000,2018-01-18 03:50:16.000000000,closed,0,Move mlutils.scala to 1.5 folder
1237,2018-01-18 00:44:42.000000000,2018-01-18 02:40:10.000000000,closed,0,Disable code coverage for spark 1.6 tests to avoid duped results
1236,2018-01-18 00:37:09.000000000,2018-01-18 00:56:20.000000000,closed,0,Fix a typo and add missing docs
1235,2018-01-17 23:58:42.000000000,2018-01-18 01:26:54.000000000,closed,0,Fix ML-related failures for 1.6
1234,2018-01-17 22:43:43.000000000,2018-01-17 23:43:15.000000000,closed,0,Make spark_web() more reliable under Spark 2.X
1233,2018-01-17 21:57:03.000000000,2020-08-13 16:17:15.000000000,closed,3,tidyr
1232,2018-01-17 21:13:26.000000000,2018-01-17 21:13:44.000000000,closed,0,document uid in ml_fpgrowth()
1231,2018-01-17 20:52:16.000000000,1970-01-01 00:00:00.000000001,open,12,Provide tidyr functions
1230,2018-01-17 18:26:00.000000000,1970-01-01 00:00:00.000000001,open,0,NullPointerException when accessing scala object members with override
1229,2018-01-17 12:50:37.000000000,2018-01-17 19:22:03.000000000,closed,0,Implement FP-Growth
1228,2018-01-17 11:51:45.000000000,2018-01-17 21:23:50.000000000,closed,0,use base64encode in livy_config()
1227,2018-01-17 09:27:03.000000000,2018-01-18 13:14:43.000000000,closed,0,Consider implementing & exporting companion helper functions for ml_ and ft_ models
1226,2018-01-17 06:40:34.000000000,2018-01-17 23:43:04.000000000,closed,3,Add support for Spark 1.6.X on Travis
1225,2018-01-17 03:41:16.000000000,2018-01-17 20:40:04.000000000,closed,0,A few fixes and improvements for writing tables
1224,2018-01-17 02:28:49.000000000,2018-01-17 12:39:20.000000000,closed,0,[WIP] Locality sensitive hashing
1223,2018-01-17 01:56:29.000000000,2018-01-17 19:22:03.000000000,closed,0,Implement FP-Growth
1222,2018-01-17 01:12:49.000000000,2018-01-17 10:51:04.000000000,closed,0,Add tests to validate collection of dates with timezones to fix #1194
1221,2018-01-16 22:38:14.000000000,2018-01-17 02:12:21.000000000,closed,0,sdf_bind_cols() is failling with dev rlang
1220,2018-01-16 22:32:00.000000000,2018-01-16 23:36:56.000000000,closed,0,Return value for `ncol()`
1219,2018-01-16 16:43:51.000000000,2018-01-17 00:37:11.000000000,closed,5,Incorrect return values using current_timestamp and to_date
1218,2018-01-16 12:14:19.000000000,2018-01-16 12:43:17.000000000,closed,0,Provide ml_predict.ml_model_clustering()
1217,2018-01-16 11:54:50.000000000,2018-01-16 12:27:27.000000000,closed,0,Support collecting VectorUDTs with nested subarrays
1216,2018-01-16 11:47:13.000000000,2018-01-16 12:24:36.000000000,closed,1,Add support to override compilation of scala object with higher version
1215,2018-01-16 11:34:20.000000000,2018-01-16 12:43:19.000000000,closed,1,ml_model_clustering need prediction methods
1214,2018-01-16 10:54:09.000000000,2018-01-16 11:15:39.000000000,closed,2,Support coefficient bounding for logistic regression
1213,2018-01-15 18:07:10.000000000,2018-01-17 23:43:16.000000000,closed,6,yarn-client spark_disconnect(sc) not working in sparklyr > 0.6.2
1212,2018-01-14 11:51:19.000000000,2018-01-14 19:49:01.000000000,closed,0,Implement ft_standard_scaler()
1211,2018-01-14 11:29:02.000000000,2018-01-14 11:50:32.000000000,closed,0,Implement ft_polynomial_expansion()
1210,2018-01-14 06:51:51.000000000,1970-01-01 00:00:00.000000001,open,3,Issue accessing remote Spark standalone cluster using livy
1209,2018-01-14 02:21:20.000000000,2018-01-14 03:43:21.000000000,closed,0,Add ft_normalizer()
1208,2018-01-13 03:45:51.000000000,2018-01-13 04:15:30.000000000,closed,0,Add ft_min_max_scaler()
1207,2018-01-13 02:55:33.000000000,2018-01-13 03:19:19.000000000,closed,0,Add ft_max_abs_scaler()
1206,2018-01-13 01:38:18.000000000,2018-01-13 02:23:47.000000000,closed,0,Implement ft_interaction()
1205,2018-01-13 00:25:49.000000000,2018-01-13 00:41:36.000000000,closed,0,Add ft_imputer()
1204,2018-01-12 22:30:09.000000000,2018-01-12 22:53:13.000000000,closed,0,Add ft_vector_slicer()
1203,2018-01-12 05:13:17.000000000,2018-01-13 04:40:04.000000000,closed,1,replace jsonlite base64_enc by base64encode from package base64enc
1202,2018-01-12 03:53:43.000000000,2018-01-12 19:40:26.000000000,closed,0,Add ft_chisq_selector()
1201,2018-01-12 02:41:22.000000000,2018-01-12 03:15:33.000000000,closed,0,Fix class names of feature transformers
1200,2018-01-12 01:55:58.000000000,2018-01-16 12:27:28.000000000,closed,0,wrapped array columns don't serialize properly
1199,2018-01-11 23:49:58.000000000,2018-01-12 01:38:36.000000000,closed,0,decouple sdf_ncol() and sdf_nrow() calculations
1198,2018-01-11 23:07:21.000000000,2018-01-16 23:36:56.000000000,closed,13,glimpse doesn't work
1197,2018-01-11 02:13:57.000000000,2018-01-11 03:03:06.000000000,closed,0,"Include IndexToString in ml_model objects, various enhancements"
1196,2018-01-11 01:25:56.000000000,2018-01-11 03:03:06.000000000,closed,0,Investigate test failures for IDF and Word2Vec under 1.6
1195,2018-01-10 23:09:34.000000000,1970-01-01 00:00:00.000000001,open,2,rowwise operations on spark dataframes
1194,2018-01-10 23:04:10.000000000,2018-01-17 10:51:04.000000000,closed,1,Investigate serialization with time zones
1193,2018-01-10 22:57:36.000000000,2018-01-10 23:16:02.000000000,closed,0,Fix for connect dialog with proxies
1192,2018-01-10 03:39:58.000000000,2018-01-11 03:03:06.000000000,closed,4,Consider officially supporting `features` and `response` arguments in ml_ routines
1191,2018-01-10 01:04:52.000000000,2018-01-11 03:03:06.000000000,closed,0,Include index to string transformation in canned ML pipelines
1190,2018-01-10 01:00:21.000000000,2018-01-10 01:00:27.000000000,closed,0,correct version
1189,2018-01-10 00:22:49.000000000,2018-01-10 00:23:42.000000000,closed,0,move TODOs in code to GitHub issues
1188,2018-01-10 00:20:53.000000000,1970-01-01 00:00:00.000000001,open,0,Documentation/examples on model tuning
1187,2018-01-10 00:19:29.000000000,1970-01-01 00:00:00.000000001,open,0,More checks on hyperparameters on R side
1186,2018-01-10 00:18:25.000000000,2018-01-20 01:17:19.000000000,closed,0,ml_param() and ml_summary() have different defaults for allow_null
1185,2018-01-10 00:17:24.000000000,2019-02-09 04:02:44.000000000,closed,0,Consider exporting ml_set_param()
1184,2018-01-09 00:50:00.000000000,1970-01-01 00:00:00.000000001,open,10," Error: Unexpected state in sparklyr backend, terminating connection: failed to invoke spark command"
1183,2018-01-08 14:40:15.000000000,1970-01-01 00:00:00.000000001,open,1,Cannot access java Enums
1182,2018-01-08 14:34:13.000000000,1970-01-01 00:00:00.000000001,open,1,NullPointerException: Cannot call attribute on companion object which is also defined on class
1181,2018-01-08 14:15:17.000000000,1970-01-01 00:00:00.000000001,open,1,How to get companion object?
1180,2018-01-05 19:52:55.000000000,2020-01-13 19:59:30.000000000,closed,0,Expose developer API for extending pipelines
1179,2018-01-05 03:49:42.000000000,2018-01-17 20:40:05.000000000,closed,0,"dbplyr & sparklyr - `compute()` returns error, but it still creates the new table"
1178,2018-01-04 06:50:44.000000000,2018-04-30 20:07:59.000000000,closed,1,Creating a custom function in scala used after `group_by`
1177,2017-12-27 02:10:35.000000000,2018-01-02 21:27:46.000000000,closed,1,nice
1176,2017-12-21 17:45:05.000000000,2018-01-05 09:36:27.000000000,closed,2,[ft_stop_words_remover()] How to apply custom stopwords?
1175,2017-12-20 03:34:35.000000000,2017-12-20 03:50:04.000000000,closed,0,Improve support for Spark 2.x with cloudera clusters
1174,2017-12-20 02:46:35.000000000,2017-12-20 03:20:02.000000000,closed,1,Update documentation on s3 integration
1173,2017-12-20 01:58:18.000000000,2017-12-20 03:19:02.000000000,closed,0,adding option to access LongType
1172,2017-12-19 21:04:56.000000000,2018-01-18 05:32:49.000000000,closed,7,Segfault on reinitialising connection - Reopened
1171,2017-12-19 19:31:16.000000000,2017-12-20 03:21:27.000000000,closed,6,Can the sparklyr jars be rebuilt (at least for spark 2 versions)?
1170,2017-12-19 04:15:20.000000000,1970-01-01 00:00:00.000000001,open,0,spark-shell execution error
1169,2017-12-15 23:38:18.000000000,2017-12-16 05:02:32.000000000,closed,0,Make new livy connection use rstudioapi::askForPassword()
1168,2017-12-12 19:54:18.000000000,2017-12-20 03:20:03.000000000,closed,0,Failing to ready S3 parquet files in Spark using Sparklyr package
1167,2017-12-12 02:44:55.000000000,2017-12-15 23:12:38.000000000,closed,5,enable inputting read schema to optimize reads of nested parquet data
1166,2017-12-11 23:47:28.000000000,2017-12-11 23:49:27.000000000,closed,0,last few mlib dplyr links
1165,2017-12-11 23:23:42.000000000,2017-12-11 23:25:36.000000000,closed,0,Fixed more broken links in mlib & dplyr
1164,2017-12-06 03:37:11.000000000,2017-12-06 03:39:07.000000000,closed,0,Adds search bar
1163,2017-12-06 00:25:06.000000000,2017-12-06 00:39:05.000000000,closed,0,Article conversions and broken links
1162,2017-12-05 03:25:13.000000000,2017-12-05 03:40:37.000000000,closed,0,Adds GitHub icon and link
1161,2017-12-04 16:17:09.000000000,1970-01-01 00:00:00.000000001,open,0,trailing backslash in sdf_pivot with column names 
1160,2017-12-01 20:33:49.000000000,2017-12-01 20:34:43.000000000,closed,1,NAs getting collected as FALSE
1159,2017-11-30 20:14:49.000000000,2017-12-01 02:00:41.000000000,closed,1,sdf_bind_* functions broken with dev rlang
1158,2017-11-30 18:17:15.000000000,2018-04-30 20:05:31.000000000,closed,1,create DB failed
1157,2017-11-30 09:35:42.000000000,2017-12-29 01:31:29.000000000,closed,3,Convert probability into probability list in sparklyr 
1156,2017-11-30 04:11:05.000000000,2017-12-02 07:38:48.000000000,closed,0,spark_connect erroring out
1155,2017-11-30 00:39:08.000000000,2017-11-30 00:40:13.000000000,closed,0,Fixes #1145
1154,2017-11-29 23:57:19.000000000,2017-11-30 00:24:03.000000000,closed,1,Fixes Netlify deployment issues
1153,2017-11-29 22:56:04.000000000,1970-01-01 00:00:00.000000001,open,0,Support sparklyr extensions for HUE notebooks
1152,2017-11-29 21:41:48.000000000,2017-11-30 01:11:52.000000000,closed,0,Fix regression due to rlang changes
1151,2017-11-28 20:44:04.000000000,2017-11-28 21:01:07.000000000,closed,0,Support one-sided formula (for clustering algos) in ml_formula_transformation()
1150,2017-11-28 19:50:55.000000000,2017-11-28 21:01:08.000000000,closed,0,Backwards compatibility fails for ml_kmeans()
1149,2017-11-28 19:43:35.000000000,1970-01-01 00:00:00.000000001,open,0,Working with or caching huge dataset (especially in columns)
1148,2017-11-28 01:39:02.000000000,2017-11-30 00:26:40.000000000,closed,6,Links on spark.rstudio.com broken
1147,2017-11-28 00:29:29.000000000,2017-11-28 01:05:04.000000000,closed,0,Fix favicon
1146,2017-11-27 05:29:41.000000000,2017-11-27 05:43:10.000000000,closed,0,Implement sdf_describe()
1145,2017-11-25 23:41:47.000000000,2017-11-30 00:40:15.000000000,closed,1,Text Mining Guide 404 error?
1144,2017-11-25 09:21:52.000000000,1970-01-01 00:00:00.000000001,open,6,spark_connect  error
1143,2017-11-25 03:22:35.000000000,2017-11-25 09:38:14.000000000,closed,1,Sparklyr doesn't distinguish between blank and NA
1142,2017-11-23 18:23:29.000000000,2018-01-16 11:15:39.000000000,closed,5,Expose upper and lower bounds for coefficients parameters
1141,2017-11-22 12:18:39.000000000,1970-01-01 00:00:00.000000001,open,2,column names within sparklyr
1140,2017-11-21 20:44:52.000000000,2017-11-21 21:25:21.000000000,closed,0,Improving blogdown process
1139,2017-11-21 20:41:02.000000000,2017-11-23 20:45:37.000000000,closed,1,Support predicate pushdown when reading from generic source (spark_read_source)
1138,2017-11-21 18:36:50.000000000,2017-11-21 23:24:06.000000000,closed,4,Getting the significance of coeficients in logistic regression using `ml_logistic_regression`
1137,2017-11-21 15:57:26.000000000,1970-01-01 00:00:00.000000001,open,2,Extracting characters based on regex pattern
1136,2017-11-21 03:23:19.000000000,2017-11-21 23:49:00.000000000,closed,2,ml_pipeline not found
1135,2017-11-20 16:02:02.000000000,2017-11-25 09:41:37.000000000,closed,3,left_join hangs
1134,2017-11-20 00:46:06.000000000,2017-11-21 19:54:25.000000000,closed,1,`knitr::kable()` seems to mis-order column names or column values with `sparklyr
1133,2017-11-19 03:25:15.000000000,2017-11-21 00:05:20.000000000,closed,1,Fix typos in documentation
1132,2017-11-18 04:34:43.000000000,2017-11-18 04:49:08.000000000,closed,0,Implement text analytics transforms
1131,2017-11-18 04:18:49.000000000,2018-07-13 02:54:08.000000000,closed,2,Streaming
1130,2017-11-17 02:18:35.000000000,1970-01-01 00:00:00.000000001,open,1,Blank suffix in left_join causes join to hang.
1129,2017-11-16 22:58:16.000000000,2018-01-18 03:50:16.000000000,closed,1,Investigate compatibility with Spark 1.5
1128,2017-11-16 22:45:12.000000000,2018-01-17 01:50:55.000000000,closed,2,Better interface for passing context to spark_apply()
1127,2017-11-16 22:42:42.000000000,2018-01-18 01:26:53.000000000,closed,3,Investigate test failures in 1.6.x
1126,2017-11-16 20:32:43.000000000,2017-11-16 20:53:09.000000000,closed,0,Spark ML compatibility for 1.6.x
1125,2017-11-16 01:45:53.000000000,2017-12-23 22:12:33.000000000,closed,12,spark_apply Error: Unable to retrieve a Spark DataFrame from object of class data.frame
1124,2017-11-15 22:03:10.000000000,1970-01-01 00:00:00.000000001,open,0,spark_apply() to allow chaining multiple date types
1123,2017-11-15 22:02:04.000000000,1970-01-01 00:00:00.000000001,open,0,spark_apply() could infer libraries
1122,2017-11-15 21:54:50.000000000,1970-01-01 00:00:00.000000001,open,1,Running compute() on output from summarise_
1121,2017-11-14 02:43:11.000000000,2017-11-16 01:50:27.000000000,closed,2,ERROR sparklyr: Gateway xxxxx failed calling take on xxx when running spark-apply
1120,2017-11-13 21:52:45.000000000,2017-11-14 08:45:27.000000000,closed,0,Adds the blogdown site
1119,2017-11-13 15:30:08.000000000,1970-01-01 00:00:00.000000001,open,10,"Error: Unexpected state in sparklyr backend, terminating connection"
1118,2017-11-11 10:37:24.000000000,2017-11-11 10:55:43.000000000,closed,0,Correct parameter default documentation for ml_naive_bayes()
1117,2017-11-11 00:22:20.000000000,2017-11-11 02:03:20.000000000,closed,0,Support dates retrieved as doubles in spark_apply()
1116,2017-11-10 23:06:11.000000000,2017-11-11 02:03:21.000000000,closed,0,Dates retrieved as doubles in spark_apply()
1115,2017-11-10 20:30:37.000000000,2017-11-10 20:55:37.000000000,closed,0,Spark ML compatibility for 2.0.0
1114,2017-11-10 04:57:23.000000000,2017-11-10 05:16:39.000000000,closed,0,Fix broken h2o under sparklyr with older cran version
1113,2017-11-10 01:28:35.000000000,2017-11-16 20:55:13.000000000,closed,2,Invalid method setForceIndexLabel for ml_* algorithms called with formula
1112,2017-11-09 20:11:35.000000000,1970-01-01 00:00:00.000000001,open,1,Better external package handlings with extensions for off line users
1111,2017-11-08 04:11:11.000000000,2017-11-09 23:44:52.000000000,closed,3,Passing variables to dplyr_ functions fail
1110,2017-11-07 20:54:12.000000000,1970-01-01 00:00:00.000000001,open,7,sdf_bind_col Error
1109,2017-11-07 20:49:55.000000000,2017-11-09 01:48:16.000000000,closed,0,fixes rstudio/sparklyr#1101
1108,2017-11-04 00:42:12.000000000,2017-11-15 04:29:04.000000000,closed,1,Function reference page does not contain all functions
1107,2017-11-03 22:44:27.000000000,2017-11-04 00:12:02.000000000,closed,2,Add support in spark_apply() for context param
1106,2017-11-02 02:32:59.000000000,2017-11-02 03:00:34.000000000,closed,0,Add support for 'spark_apply()' under 'yarn-cluster'
1105,2017-11-01 03:40:01.000000000,2017-11-01 22:49:01.000000000,closed,0,Add support under 'yarn-cluster' to wait for available resources
1104,2017-10-31 22:56:50.000000000,2017-11-02 02:56:28.000000000,closed,2,Documentation question: is there any way to control how many rows spark_apply() cuts data into?
1103,2017-10-31 22:55:11.000000000,2017-11-01 00:29:08.000000000,closed,0,`spark_write_table` with `mode = 'append'` requires a workaround to work properly in Hive
1102,2017-10-31 22:12:46.000000000,2017-10-31 22:49:30.000000000,closed,0,Improve spark_write overwrite docs to fix #1055
1101,2017-10-31 20:30:08.000000000,2017-11-09 01:48:18.000000000,closed,0,spark_write_source not appropriate for generic Spark data sources
1100,2017-10-31 18:49:58.000000000,2017-11-08 02:21:24.000000000,closed,9,Can't get sparklyr to connect with Shiny
1099,2017-10-30 20:43:34.000000000,2017-11-03 17:01:51.000000000,closed,2,spark_apply() can not find Rscript
1098,2017-10-28 04:33:02.000000000,2017-10-29 09:41:03.000000000,closed,1,Fix missing link in Machine Learning section
1097,2017-10-28 00:02:45.000000000,2017-10-29 09:41:41.000000000,closed,1,Machine Learning link broken
1096,2017-10-27 22:57:59.000000000,2017-10-28 23:12:17.000000000,closed,0,### While Trying to run Spark-Shell in terminal i am getting this error can some one please help me out.?
1095,2017-10-27 08:05:36.000000000,2017-10-27 08:10:33.000000000,closed,0,Strange behavior with lag
1094,2017-10-27 04:18:23.000000000,2017-10-28 00:06:03.000000000,closed,3,Combining multiple paths into a single spark_read_csv call
1093,2017-10-27 00:56:24.000000000,1970-01-01 00:00:00.000000001,open,0,"Data manipulation in R for a condition, Rstudio, "
1092,2017-10-26 23:42:01.000000000,2018-01-17 12:39:20.000000000,closed,0,Implement all spark.ml.feature functions
1091,2017-10-26 20:03:57.000000000,2017-11-08 02:24:17.000000000,closed,5,Pull data from remote Cassandra database with sparklyr?
1090,2017-10-26 18:51:42.000000000,1970-01-01 00:00:00.000000001,open,1,Not able to connect to spark deployed in yarn client mode
1089,2017-10-26 17:14:11.000000000,1970-01-01 00:00:00.000000001,open,1,how to read XML files with Sparklyr?
1088,2017-10-25 00:33:57.000000000,2018-01-20 12:03:29.000000000,closed,13,ml_load on a cluster
1087,2017-10-24 23:03:54.000000000,2017-10-24 23:23:56.000000000,closed,0,Also fix NAs data types test under Spark 2.2.0
1086,2017-10-24 21:17:28.000000000,2017-10-24 21:43:19.000000000,closed,0,Fix test for data type under Spark 2.2
1085,2017-10-24 19:01:57.000000000,1970-01-01 00:00:00.000000001,open,2,R session crashes after trying to use spark_connect for the first time
1084,2017-10-24 06:04:59.000000000,2017-10-24 06:05:16.000000000,closed,0,[WIP] ML Tuning and print method fixes
1083,2017-10-24 05:09:52.000000000,1970-01-01 00:00:00.000000001,open,3,Cannot connect to 'kerbenized' Spark cluster with the latest sparklyr
1082,2017-10-23 17:56:58.000000000,2017-11-18 04:21:31.000000000,closed,1,structured streaming support
1081,2017-10-21 00:35:42.000000000,2017-10-21 00:49:28.000000000,closed,0,"[WIP] Predict, transform, and fit methods"
1080,2017-10-20 06:13:44.000000000,1970-01-01 00:00:00.000000001,open,2,when more cores used Spark (Sparklyr) error to many files open
1079,2017-10-20 01:24:37.000000000,2017-10-26 00:05:33.000000000,closed,1,ML improvements
1078,2017-10-19 23:55:39.000000000,2017-10-20 00:08:40.000000000,closed,0,[WIP] ML tuning and persistence
1077,2017-10-19 20:48:03.000000000,2018-01-17 20:57:23.000000000,closed,2,Why the head() function is so slow for large datasets?
1076,2017-10-18 18:50:05.000000000,1970-01-01 00:00:00.000000001,open,0,import custom implicits
1075,2017-10-18 08:25:26.000000000,2018-01-19 23:45:11.000000000,closed,0,Hyperlinks to functions not working
1074,2017-10-18 08:21:55.000000000,2018-04-30 20:00:27.000000000,closed,1,"Is the default quote character really ""hdfs://"" ?"
1073,2017-10-17 01:49:13.000000000,2017-10-17 04:38:48.000000000,closed,0,Improve travis test_that output
1072,2017-10-17 00:08:05.000000000,2017-10-17 08:06:50.000000000,closed,0,[WIP] Pipelines API initial implementation
1071,2017-10-13 01:31:58.000000000,2017-10-25 01:59:36.000000000,closed,2,Fix ml_load and _ml_save methods
1070,2017-10-13 01:09:02.000000000,2018-01-20 03:43:28.000000000,closed,2,ml_save and ml_load fail HDFS Error
1069,2017-10-12 17:41:26.000000000,1970-01-01 00:00:00.000000001,open,1,scala methods with default arguments
1068,2017-10-12 14:16:31.000000000,1970-01-01 00:00:00.000000001,open,0,FeatureRequest: invoke with named arguments
1067,2017-10-12 02:39:18.000000000,1970-01-01 00:00:00.000000001,open,4,Documentation on how to use spark_write_jdbc to connect to MySql 
1066,2017-10-10 21:51:10.000000000,1970-01-01 00:00:00.000000001,open,1,spark_read_table fails when table prefixed with db name
1065,2017-10-10 21:37:03.000000000,2017-10-10 21:54:14.000000000,closed,1,Update connection_spark.R
1064,2017-10-10 21:19:34.000000000,2017-10-10 21:22:17.000000000,closed,0,Update connection_spark.R
1063,2017-10-10 20:11:22.000000000,1970-01-01 00:00:00.000000001,open,3,sdf_pivot returning AnalysisException due to ambiguous column name
1062,2017-10-09 22:28:52.000000000,2017-10-10 23:19:57.000000000,closed,9,Dynamic column names 
1061,2017-10-08 17:20:56.000000000,2017-10-10 07:46:51.000000000,closed,2,Change logs location for windows
1060,2017-10-08 17:07:46.000000000,2017-10-10 21:44:57.000000000,closed,0,cannot open file 'log4j.spark.log': No such file or directory
1059,2017-10-05 21:38:38.000000000,1970-01-01 00:00:00.000000001,open,6,Read RDS or RData using SparklyR
1058,2017-10-05 16:16:10.000000000,2019-10-23 22:57:50.000000000,closed,9,Conversion between R and Scala
1057,2017-10-05 16:00:50.000000000,2017-10-05 16:09:26.000000000,closed,2,import collection.JavaConverters._
1056,2017-10-04 19:17:08.000000000,2018-01-17 01:35:26.000000000,closed,4,DST error on datetimes when reading from Cassandra into Sparklyr
1055,2017-10-04 18:09:21.000000000,2017-10-31 22:49:31.000000000,closed,0,"spark_write_table(mode = 'overwrite') loses original table definition (SerDe, storage details and so on)"
1054,2017-10-03 19:04:02.000000000,2017-11-01 22:49:02.000000000,closed,2,Not able to connect to HTTPS_ONLY using yarn-cluster
1053,2017-10-03 10:20:51.000000000,2017-10-05 23:31:57.000000000,closed,0,Remove dead code from core deserializer
1052,2017-10-02 20:15:02.000000000,1970-01-01 00:00:00.000000001,open,0,UDFs in dplyr
1051,2017-10-02 04:03:50.000000000,1970-01-01 00:00:00.000000001,open,7,first() and last() functions not working
1050,2017-09-29 23:16:15.000000000,2018-04-30 19:52:31.000000000,closed,1,Improve sample_n error comment for Spark < 2.x
1049,2017-09-29 22:23:21.000000000,2017-10-02 20:19:48.000000000,closed,5,User Defined Functions with mutate (dplyr)
1048,2017-09-29 21:42:32.000000000,2017-10-02 20:26:45.000000000,closed,2,Update sample_n error comment for Spark < 2.x
1047,2017-09-29 20:09:01.000000000,1970-01-01 00:00:00.000000001,open,3,sdf_pivot returning NaN's and no is.nan function to mutate and replace
1046,2017-09-29 04:06:21.000000000,2017-09-29 05:13:46.000000000,closed,1,spark_write_json not working
1045,2017-09-29 01:31:42.000000000,2017-09-29 19:19:16.000000000,closed,0,Add support to `collect()` all `NA`s correctly
1044,2017-09-29 00:19:36.000000000,2017-09-29 03:34:26.000000000,closed,1,Note expected input type
1043,2017-09-28 13:59:56.000000000,1970-01-01 00:00:00.000000001,open,2,error with java VM on rstudio-server affecting sparklyr
1042,2017-09-28 06:50:27.000000000,2017-09-28 22:34:18.000000000,closed,1,An error probably caused by dplyr::rename_vars
1041,2017-09-28 03:45:36.000000000,2017-09-28 22:54:41.000000000,closed,0,Improve `collect()` serialization for dates and timestamps
1040,2017-09-27 22:49:08.000000000,2017-09-29 05:14:24.000000000,closed,4,"Sparklyr substitute for ""fill"" function?"
1039,2017-09-27 17:10:11.000000000,1970-01-01 00:00:00.000000001,open,15,Failed while connecting to sparklyr to port (8880)
1038,2017-09-27 01:55:02.000000000,1970-01-01 00:00:00.000000001,open,0,Consider serializing SparseVector to sparseVector
1037,2017-09-26 21:13:24.000000000,1970-01-01 00:00:00.000000001,open,2,TypeTag
1036,2017-09-26 00:45:16.000000000,2017-09-26 01:08:45.000000000,closed,1,`spark_apply()` hangs for 16min when multiple executors run on same node with package distribution
1035,2017-09-26 00:40:27.000000000,2017-09-26 01:32:27.000000000,closed,1,`spark_apply()` hangs for 16min when multiple executors run on same node with package distribution
1034,2017-09-26 00:38:09.000000000,1970-01-01 00:00:00.000000001,open,1,`spark_apply()` could significantly improve performance for data transfer into Scala
1033,2017-09-26 00:19:42.000000000,2017-11-01 22:49:02.000000000,closed,3,Cluster mode doesn't wait for ACCEPTED application to be resourced by YARN
1032,2017-09-22 18:32:52.000000000,2017-11-02 06:20:12.000000000,closed,0,Implement spark_read_libsvm()
1031,2017-09-22 18:28:35.000000000,1970-01-01 00:00:00.000000001,open,3,Job aborted due to stage failure
1030,2017-09-22 17:46:49.000000000,2017-09-22 17:47:35.000000000,closed,1,serialize listcols in copy_to()
1029,2017-09-22 04:07:39.000000000,2017-09-23 01:54:51.000000000,closed,0,Add support for explicit package distribution in `spark_apply()`
1028,2017-09-21 17:09:13.000000000,2017-10-26 12:29:07.000000000,closed,2,Unable connect to Spark 2.1.0
1027,2017-09-21 02:55:45.000000000,2017-09-23 01:54:52.000000000,closed,5,Reduce `spark_apply()` package depedencies
1026,2017-09-20 22:48:33.000000000,1970-01-01 00:00:00.000000001,open,10,compute() does not break table lineage for Sparklyr 0.7.0.9031
1025,2017-09-20 20:23:22.000000000,2017-10-31 23:45:17.000000000,closed,2,columns lost when converting from json to parquet
1024,2017-09-19 18:29:01.000000000,2017-10-27 02:59:43.000000000,closed,2,Spark SQL ``inline`` not supported
1023,2017-09-19 17:07:01.000000000,2017-09-19 20:57:40.000000000,closed,1,Update documentation of the mode param for spark_write_*()
1022,2017-09-19 09:50:15.000000000,2017-09-19 10:20:47.000000000,closed,0,Allow long error messages while connecting in `yarn-cluster` mode
1021,2017-09-18 22:40:26.000000000,1970-01-01 00:00:00.000000001,open,0,Consider `spark_apply()` to not require FQN
1020,2017-09-18 22:03:02.000000000,2017-09-18 23:01:07.000000000,closed,1,Text column with newline causes error in dplyr::copy_to in presence of a date column
1019,2017-09-17 01:13:09.000000000,2017-09-18 22:31:27.000000000,closed,1,Update deployment-amazon.Rmd
1018,2017-09-16 02:10:55.000000000,2017-09-19 00:41:48.000000000,closed,0,Fix a couple r cmd warnings
1017,2017-09-16 01:37:55.000000000,2017-09-16 02:02:54.000000000,closed,0,Support handling high-availability empty responses in yarn-cluster
1016,2017-09-15 21:27:06.000000000,2017-09-16 01:18:08.000000000,closed,0,Block java 9 and warn on local but allow override with sparklyr.java9
1015,2017-09-15 21:25:13.000000000,2017-09-16 01:09:42.000000000,closed,3,Issues with Mutate in Sparklyr
1014,2017-09-15 20:05:58.000000000,2017-09-15 20:55:54.000000000,closed,0,Enable true random session ids
1013,2017-09-15 17:03:17.000000000,2017-09-18 23:19:56.000000000,closed,1,Improve serialization from JDBC Sources
1012,2017-09-15 10:39:14.000000000,2017-09-16 08:42:33.000000000,closed,4,Install sparklyr with initialize_connect error
1011,2017-09-15 08:39:13.000000000,2017-09-15 20:55:55.000000000,closed,1,sparklyr connects to existing spark applications
1010,2017-09-15 02:18:08.000000000,2017-09-15 04:50:08.000000000,closed,0,Avoid port 8880 from being blocked on interrupted connections
1009,2017-09-14 22:57:15.000000000,2017-09-15 01:50:15.000000000,closed,0,Enable support for Java 9
1008,2017-09-14 02:11:55.000000000,2017-09-14 02:36:09.000000000,closed,0,Add .codecov.yml file to allow customizing
1007,2017-09-14 01:30:59.000000000,2017-09-14 02:07:49.000000000,closed,1,Improve query performance to retrieve fields
1006,2017-09-13 22:07:37.000000000,2017-09-14 01:31:37.000000000,closed,0,Fix empty results data.frame in `spark_apply()`
1005,2017-09-13 20:12:52.000000000,2017-09-19 20:57:40.000000000,closed,4,Improve docs for mode arg of spark_write_*()
1004,2017-09-13 05:42:36.000000000,2017-09-15 02:26:59.000000000,closed,0,Add yarn.resourcemanager.admin.address as fallback to find rest api under yarn-cluster HA
1003,2017-09-13 03:36:19.000000000,2017-09-13 03:57:00.000000000,closed,0,Doc tweak to sdf_read_column() to fix #650
1002,2017-09-13 00:56:02.000000000,1970-01-01 00:00:00.000000001,open,5,broom
1001,2017-09-12 04:04:44.000000000,2017-09-12 08:08:48.000000000,closed,0,Enable use of `tryCatch()` within `spark_apply()`
1000,2017-09-11 21:22:59.000000000,2017-09-14 04:05:13.000000000,closed,2,Failing to install from CRAN
999,2017-09-11 19:08:57.000000000,2017-09-11 19:51:04.000000000,closed,0,A couple of corrections to the text mining article
998,2017-09-11 17:48:01.000000000,2017-09-11 18:23:10.000000000,closed,0,Adds text mining article
997,2017-09-11 07:23:34.000000000,2017-09-21 00:37:58.000000000,closed,57,Not able to connect to Spark Cluster with Sparklyr 0.7.0-9019
996,2017-09-11 05:27:55.000000000,2017-09-11 17:13:52.000000000,closed,0,Adds text mining article and corrects cheatsheet link
995,2017-09-09 02:55:49.000000000,2017-09-09 04:10:59.000000000,closed,0,Remove parenthesis in operations (similar to sqlite) for union_all regression in spark 1.6 and fix #994
994,2017-09-08 23:41:46.000000000,2017-09-09 04:11:00.000000000,closed,0,Regression in `union_all` no working in Spark 1.6.X
993,2017-09-08 19:54:05.000000000,2017-09-12 08:08:49.000000000,closed,2,support for tryCatch() in spark_apply
992,2017-09-08 06:00:13.000000000,2017-11-01 00:29:09.000000000,closed,5,"sparklyr::spark_write_table ( , , mode = 'append') fails for ORC and Parquet"
991,2017-09-07 22:51:36.000000000,2017-09-07 23:28:11.000000000,closed,0,Add support for `na.omit.cache` option
990,2017-09-07 09:11:34.000000000,2017-09-07 20:39:41.000000000,closed,0,Enable `yarn-cluster` in CDH clusters
989,2017-09-07 01:15:37.000000000,2017-09-07 20:39:43.000000000,closed,0,"`master=""yarn-cluster""` requires config shell parameters when they should be inferred"
988,2017-09-07 00:22:58.000000000,2017-09-14 02:07:50.000000000,closed,7,na.omit() not working efficiently. 
987,2017-09-07 00:09:36.000000000,2017-09-15 04:50:10.000000000,closed,0,Port 8880 gets blocked with interrupted connections
986,2017-09-06 00:25:39.000000000,2017-09-06 19:27:44.000000000,closed,2,Feature request: Implementation of bisect k-means algorithm
985,2017-09-05 21:01:29.000000000,1970-01-01 00:00:00.000000001,open,0,Type of NA ignored in dplyr::mutate()
984,2017-09-05 18:28:35.000000000,2017-09-18 22:58:28.000000000,closed,15,sparklyr spark_connect issue from RStudio
983,2017-09-05 07:50:28.000000000,2017-09-12 08:08:49.000000000,closed,0,More informative spark_apply() call stacks on error
982,2017-09-04 20:13:43.000000000,1970-01-01 00:00:00.000000001,open,0,sparklyr::tally appears to count even when there is a column named n present
981,2017-09-03 23:27:21.000000000,2017-09-06 02:32:49.000000000,closed,2,rollapply for large data using sparklyr
980,2017-09-02 03:51:53.000000000,2017-09-17 05:42:49.000000000,closed,21,spark_apply runs forever and nothing appears in the gui
979,2017-09-01 04:02:04.000000000,2017-09-12 21:18:58.000000000,closed,6,how to combine multiple operations at once without loading the data multiple times?
978,2017-08-31 11:54:28.000000000,2017-11-28 19:40:26.000000000,closed,7,livy and config()
977,2017-08-31 00:44:51.000000000,1970-01-01 00:00:00.000000001,open,5,java.lang.OutOfMemoryError while using sparklyr on cluster
976,2017-08-30 18:19:09.000000000,2018-01-17 20:39:36.000000000,closed,4,Possible reversion on dim()/ncol()?
975,2017-08-29 23:08:43.000000000,1970-01-01 00:00:00.000000001,open,1,Allow passing additional httr config parameters in livy_config
974,2017-08-28 05:17:41.000000000,2017-08-28 05:52:24.000000000,closed,0,"Rebuild jars, sources and bump version"
973,2017-08-27 21:39:57.000000000,1970-01-01 00:00:00.000000001,open,2,Sparklyr should not treat small integers and R raw type
972,2017-08-26 21:35:38.000000000,2017-08-26 21:54:53.000000000,closed,0,Fix `invoke()` for integer arrays containing NAs
971,2017-08-26 12:00:42.000000000,2017-08-26 21:54:54.000000000,closed,3,Issues with spark_apply() in datasets containing NA
970,2017-08-26 03:35:41.000000000,2020-05-28 16:35:58.000000000,closed,11,Mutate not working but transmute working
969,2017-08-26 03:13:43.000000000,2017-08-29 20:46:11.000000000,closed,6,Allow additional livy session parameters
968,2017-08-26 03:08:49.000000000,2017-08-26 21:27:14.000000000,closed,0,`ml_lda` improvements towards supporting full text classification
967,2017-08-26 00:21:33.000000000,2017-08-26 00:43:17.000000000,closed,0,Updates to connections article
966,2017-08-25 23:39:50.000000000,2017-08-26 06:20:43.000000000,closed,1,Make feature transformers require input/output columns
965,2017-08-25 22:05:42.000000000,2017-08-25 22:51:45.000000000,closed,0,Adds connections article
964,2017-08-25 21:49:11.000000000,2017-08-26 06:24:30.000000000,closed,0,Add reference to ft_string_indexes to fix #464
963,2017-08-25 13:24:46.000000000,1970-01-01 00:00:00.000000001,open,2,include scala data files into compiled .jar
962,2017-08-25 10:38:40.000000000,2017-08-29 13:05:24.000000000,closed,2,spark_apply: subscript out of bounds
961,2017-08-24 21:46:59.000000000,1970-01-01 00:00:00.000000001,open,4,spark_apply error CDH 5.9.2 with HA
960,2017-08-23 19:49:33.000000000,2017-08-23 22:53:54.000000000,closed,4,Joins are not registering all columns in table
959,2017-08-23 19:31:05.000000000,1970-01-01 00:00:00.000000001,open,1,AWS scripts to launch EMR clusters for use with sparklyr
958,2017-08-23 17:51:25.000000000,2017-08-24 20:44:49.000000000,closed,6,import spark.implicits._
957,2017-08-22 11:44:22.000000000,2017-11-28 19:39:06.000000000,closed,5,sdf_partition doesnt work with livy
956,2017-08-22 10:06:32.000000000,2017-08-22 10:14:35.000000000,closed,0,Add support for `spark_apply_log()`
955,2017-08-22 07:57:11.000000000,2017-08-22 09:30:21.000000000,closed,0,Avoid unregistering workers during `spark_apply()`
954,2017-08-21 19:46:50.000000000,2017-08-22 09:46:28.000000000,closed,2,ml_create_dummy_variables - reference option does not work
953,2017-08-18 23:04:52.000000000,2017-08-18 23:29:59.000000000,closed,0,Fix regression in shinyapp for empty installs
952,2017-08-18 09:38:55.000000000,2017-08-18 11:24:26.000000000,closed,0,Fix race-condition first time spark_apply() runs with concurrent partitions while unpacking
951,2017-08-18 03:42:41.000000000,2017-08-18 07:46:45.000000000,closed,0,Add support for auto-column-names in spark_apply()
950,2017-08-18 02:57:54.000000000,2017-08-18 03:38:07.000000000,closed,0,Improve errors for `metric` under `ml_classification_eval()`
949,2017-08-18 01:51:44.000000000,1970-01-01 00:00:00.000000001,open,3,Large Uploads
948,2017-08-18 01:18:42.000000000,2018-06-20 11:37:14.000000000,closed,5,Monitoring
947,2017-08-18 01:06:22.000000000,2017-08-18 01:39:28.000000000,closed,0,Save Spark logs into subfolder by default
946,2017-08-17 21:33:53.000000000,2017-08-18 00:26:57.000000000,closed,0,Fix `spark_apply()` when R runs from worker node
945,2017-08-17 18:35:31.000000000,1970-01-01 00:00:00.000000001,open,3,cannot open file ... log
944,2017-08-17 02:55:58.000000000,2017-11-11 11:07:54.000000000,closed,2,ML Pipelines
943,2017-08-17 02:52:51.000000000,2017-08-17 21:37:48.000000000,closed,1,Remove unused arguments from ft_sql_transformer
942,2017-08-17 02:42:19.000000000,2017-08-17 02:42:40.000000000,closed,1,Consider supporting default parameters in `invoke()`
941,2017-08-17 02:30:08.000000000,2018-06-26 17:53:38.000000000,closed,21,Improve Serialization
940,2017-08-17 00:58:48.000000000,1970-01-01 00:00:00.000000001,open,0,Generic Invokes
939,2017-08-16 18:36:23.000000000,2017-08-21 19:23:24.000000000,closed,3,Sdf_predict for categorical columns not working in decision tree
938,2017-08-16 09:25:48.000000000,2017-08-17 07:07:00.000000000,closed,2,SparkContext was shut down when collcet data after spark_apply
937,2017-08-16 04:21:19.000000000,2017-08-19 00:06:35.000000000,closed,1,Classification prediction output
936,2017-08-16 03:42:22.000000000,2017-08-16 08:51:03.000000000,closed,0,Doc updates for extensions mappings
935,2017-08-16 02:05:11.000000000,2017-08-17 00:15:47.000000000,closed,2,Out of Bag (OOB) for sparklyr Random Forest
934,2017-08-16 01:07:33.000000000,2017-08-16 08:50:47.000000000,closed,0,Avoid connection aborted under `invoke()` and missing class
933,2017-08-15 23:13:37.000000000,2017-08-16 08:50:48.000000000,closed,0,Missing class dependencies on package causes connection termination
932,2017-08-15 03:04:41.000000000,2017-08-15 22:44:06.000000000,closed,4,Enhancements for tree-based methods
931,2017-08-15 03:02:07.000000000,2017-08-15 04:24:56.000000000,closed,0,Fix failed tasks under `spark_apply()` when running under concurrent partitions
930,2017-08-15 02:14:54.000000000,2017-08-15 04:24:57.000000000,closed,0,Some tasks fail for concurrent partitions in `spark_apply()`
929,2017-08-14 22:23:14.000000000,2017-08-14 23:36:14.000000000,closed,2,Inconsistent results after apply ft_string_indexer
928,2017-08-14 21:02:39.000000000,2017-08-17 00:17:00.000000000,closed,3,Sparklyr categorical features and response
927,2017-08-14 11:36:10.000000000,2018-09-10 20:49:07.000000000,closed,2,java.lang.UnsatisfiedLinkError on Windows when writing parquet to S3
926,2017-08-14 07:56:27.000000000,2017-08-14 22:38:37.000000000,closed,1,allow numeric `n` in `lead()` for dplyr
925,2017-08-13 11:39:10.000000000,2017-08-14 22:38:37.000000000,closed,2,"spark.sql.AnalysisException when calling ""lag"" or ""lead"" dplyr functions more than once"
924,2017-08-13 00:46:40.000000000,2017-09-10 00:24:46.000000000,closed,0,Add support for livy connection tests
923,2017-08-12 13:47:29.000000000,2017-08-17 02:22:56.000000000,closed,2,"Error in file(con, ""r"") : cannot open the connection"
922,2017-08-12 03:46:03.000000000,2017-08-12 05:11:23.000000000,closed,0,Better error for `sample_n()` and `sample_frac()`
921,2017-08-12 02:52:11.000000000,2017-08-12 03:43:14.000000000,closed,0,Fix `SIGPIPE` on `spark_connect()` immediately after `spark_disconnect()`
919,2017-08-11 18:22:49.000000000,2017-08-12 03:43:15.000000000,closed,4,Segfault on reinitialising connection
918,2017-08-11 03:35:39.000000000,2017-08-11 20:58:24.000000000,closed,0,Add support to initialize env vars to `spark_apply()`
917,2017-08-10 16:04:39.000000000,2017-08-16 21:51:29.000000000,closed,2,Sampled data is not able to be cached
916,2017-08-10 13:27:00.000000000,1970-01-01 00:00:00.000000001,open,4,Failed while connecting to sparklyr to port (8880) for sessionid (5313): Gateway in port (8880) did not respond.
915,2017-08-10 11:50:02.000000000,2017-08-12 17:13:31.000000000,closed,7,Set environment variables for `spark_apply()`
914,2017-08-10 03:01:43.000000000,2017-08-10 08:00:28.000000000,closed,0,Fix shiny app with no installed spark
913,2017-08-10 02:18:59.000000000,2017-08-10 22:14:38.000000000,closed,0,Add support to read and write plain files
912,2017-08-09 18:48:53.000000000,1970-01-01 00:00:00.000000001,open,10,Quantile and other statistical functions do not work in dplyr::summarize for spark data frame
911,2017-08-09 13:01:41.000000000,2017-08-09 21:58:30.000000000,closed,1,typo
910,2017-08-09 12:18:02.000000000,2017-08-09 21:58:53.000000000,closed,0,correct github link
909,2017-08-08 17:46:45.000000000,2017-08-10 00:48:30.000000000,closed,1,This is not an issue - it's meant to be a Big Thanks!
908,2017-08-08 05:26:57.000000000,2017-08-10 00:37:31.000000000,closed,0,Add support for project templates
907,2017-08-07 23:28:19.000000000,2017-08-17 00:16:33.000000000,closed,15,Documentation request/query: order of probability scores in Spark multinomial regression probability columns
906,2017-08-07 22:37:53.000000000,2017-08-07 22:57:18.000000000,closed,0,`compute()` to trigger refresh in the connection viewer
905,2017-08-07 08:50:13.000000000,2017-09-07 22:23:34.000000000,closed,1,Add support for `yarn-cluster` with high availability
904,2017-08-06 19:43:31.000000000,2017-08-07 02:29:50.000000000,closed,4,spark_apply() fails when running an operation over a partitioned SDF
903,2017-08-05 17:07:54.000000000,2017-09-07 22:25:18.000000000,closed,12,Cannot connect the Spark cluster with sparklyr 0.7.0 from RStudio Server
902,2017-08-05 03:33:21.000000000,2017-09-10 03:14:47.000000000,closed,1,Add code coverage badge
901,2017-08-05 01:17:03.000000000,2017-08-11 20:09:09.000000000,closed,0,PCA projection
900,2017-08-05 00:16:56.000000000,2017-11-03 19:46:40.000000000,closed,8,Change columns names
899,2017-08-04 05:14:49.000000000,2017-08-06 03:45:12.000000000,closed,0,Improvements to `spark_apply()` for `0.6.1` release
898,2017-08-04 00:31:14.000000000,1970-01-01 00:00:00.000000001,open,1,Consider streamlining versions tested in run-tests
897,2017-08-04 00:25:19.000000000,2017-11-16 22:51:56.000000000,closed,1,Investigate test failures related to version compatibility
896,2017-08-03 19:18:59.000000000,2017-08-04 01:32:44.000000000,closed,8,enhancements for ml_random_forest()
895,2017-08-03 18:26:19.000000000,2017-08-05 06:24:50.000000000,closed,9,unable to set java.io.tmpdir with spark_config
894,2017-08-03 07:37:15.000000000,1970-01-01 00:00:00.000000001,open,1,how to run dist() in spark
893,2017-08-02 23:09:23.000000000,2017-08-03 02:30:49.000000000,closed,1,Fix typo in error message
892,2017-08-02 22:40:11.000000000,2017-10-26 23:29:52.000000000,closed,0,sdf_predict() should return class labels and not indices for classification models
891,2017-08-02 10:32:15.000000000,2017-08-02 11:00:43.000000000,closed,0,Attempt to enable code coverage using covr
890,2017-08-02 02:04:03.000000000,2017-08-02 10:20:02.000000000,closed,2,Fix slow printing of spark dataframes
889,2017-08-02 00:41:32.000000000,2017-08-02 00:54:04.000000000,closed,1,add support for installing Spark 1.6.3
888,2017-08-01 22:36:53.000000000,1970-01-01 00:00:00.000000001,open,0,Provide bind_cols() and bind_rows() from dplyr via sdf_bind_*
887,2017-08-01 21:47:48.000000000,1970-01-01 00:00:00.000000001,open,0,Better interface for passing schema with nested structtypes
886,2017-08-01 21:42:15.000000000,1970-01-01 00:00:00.000000001,open,0,Support `missing` argument in if_else()
885,2017-08-01 20:23:52.000000000,2017-10-26 23:21:40.000000000,closed,1,Reconcile arguments for hyperparameters in ml_* functions with Spark
884,2017-08-01 18:15:31.000000000,2017-08-09 19:22:01.000000000,closed,5,Rotate data using PCA components found
883,2017-08-01 02:20:49.000000000,2017-08-02 10:25:56.000000000,closed,1,"For empty partitions, `spark_apply()` fails."
882,2017-08-01 02:13:49.000000000,2017-10-26 23:21:49.000000000,closed,0,Support Tweedie distribution for GLM
881,2017-07-31 21:45:00.000000000,2017-08-01 02:14:03.000000000,closed,0,"Allow use of concurrent connections, `yarn-cluster` regression."
880,2017-07-31 11:12:05.000000000,2017-08-02 10:28:27.000000000,closed,1,Gateway only supports one connection unless config change applied
879,2017-07-30 22:16:42.000000000,2017-08-17 01:25:25.000000000,closed,1,Avoid caching while using `spark_apply()` with `group_by`
878,2017-07-30 22:10:15.000000000,2017-08-02 10:28:06.000000000,closed,1,Using `spark_apply()` with empty partitions fails
877,2017-07-29 22:12:58.000000000,2017-07-29 22:33:19.000000000,closed,0,Improve distributed r docs and version bump
876,2017-07-29 02:01:19.000000000,2017-07-29 02:22:04.000000000,closed,0,Improve performance for spark_apply with packages
875,2017-07-29 00:08:13.000000000,2017-08-17 01:09:48.000000000,closed,2,Consider support for `:` and other formula operators in `ml_*` functions
874,2017-07-29 00:07:08.000000000,2017-07-31 20:27:04.000000000,closed,3,Is it possible to spark_read_jdbc() with a [condition] ?
873,2017-07-28 20:14:47.000000000,2017-07-28 20:41:58.000000000,closed,0,Publish the docs to S3 via Jenkins
872,2017-07-28 08:47:20.000000000,1970-01-01 00:00:00.000000001,open,0,Error in force(code) : Failed while connecting to sparklyr to port (8880) for sessionid (7772): Gateway in port (8880) did not respond.
871,2017-07-27 18:57:47.000000000,1970-01-01 00:00:00.000000001,open,0,sdf_predict() throws on NA values 
870,2017-07-27 12:18:07.000000000,2017-08-01 19:34:46.000000000,closed,2,Spark 2.2 in sparklyr 0.6.0 ?
869,2017-07-27 06:59:41.000000000,2017-08-01 21:55:59.000000000,closed,3,error from copy_to()
868,2017-07-27 02:04:41.000000000,2017-07-28 11:00:56.000000000,closed,0,Prepare sparklyr 0.6 for CRAN release
867,2017-07-26 19:57:20.000000000,2017-10-26 23:44:54.000000000,closed,3,Error in ensure_scalar_character(output.col) : 'NULL' is not a length-one character vector
866,2017-07-26 18:10:51.000000000,1970-01-01 00:00:00.000000001,open,1,Support sparklyr extensions for Livy connections
865,2017-07-26 18:08:52.000000000,1970-01-01 00:00:00.000000001,open,0,Investigate reading files from Azure Blob Storage during Livy session
864,2017-07-25 20:45:44.000000000,1970-01-01 00:00:00.000000001,open,2,Spark Connect on local throws error
863,2017-07-25 17:56:07.000000000,2018-01-17 20:52:22.000000000,closed,0,Feature request - tidyr:expand
862,2017-07-25 03:24:19.000000000,2017-07-26 09:32:03.000000000,closed,0,Auto generate table names when expression is invalid for copy_to functions
861,2017-07-25 02:31:10.000000000,2017-07-26 09:31:56.000000000,closed,0,Add vocabulary.only to ft_count_vectorizer
860,2017-07-25 00:53:08.000000000,2017-07-26 09:31:51.000000000,closed,0,Add support for multiple group_by columns in `spark_apply` and improvements
859,2017-07-24 18:55:22.000000000,1970-01-01 00:00:00.000000001,open,0,change data types from parquet files using spark_read_parquet 
858,2017-07-22 11:04:14.000000000,2017-07-23 14:13:18.000000000,closed,2,Distribute Driver Packages to Worker Nodes for `spark_apply()`
857,2017-07-22 02:17:21.000000000,2017-07-22 10:51:30.000000000,closed,0,Increase Default Connection Limit
856,2017-07-22 01:39:27.000000000,2017-07-22 02:29:46.000000000,closed,2,Add ability to add custom headers for livy config
855,2017-07-21 20:16:23.000000000,1970-01-01 00:00:00.000000001,open,6,How to increase H2o total cluster memory when using sparklyr & rsparkling
854,2017-07-20 01:13:45.000000000,1970-01-01 00:00:00.000000001,open,1,how to create a hive table from a sparkdataframe
853,2017-07-19 23:54:45.000000000,2017-07-22 01:46:45.000000000,closed,9,Add support for Yarn Cluster
852,2017-07-19 22:05:32.000000000,2017-07-21 01:05:55.000000000,closed,6,Add support to write JDBC or to Generic Sources
851,2017-07-19 20:40:59.000000000,2017-07-21 01:06:42.000000000,closed,1,Feature Request: Write to JDBC
850,2017-07-19 04:19:44.000000000,2017-07-19 20:26:57.000000000,closed,0,Add support for Spark 2.2
849,2017-07-19 00:28:23.000000000,1970-01-01 00:00:00.000000001,open,4,Sparklyr - support for username password  to connect to kerborised cluster
848,2017-07-17 06:21:29.000000000,2017-07-22 10:51:31.000000000,closed,1,Cannot handle more than 16 concurrent users
847,2017-07-15 01:44:24.000000000,2017-08-26 22:15:18.000000000,closed,2,Feature request: send _arbitrary_ R code transformations to the spark cluster?
846,2017-07-14 18:38:26.000000000,2017-07-15 00:16:10.000000000,closed,2,Reading csv files stored on hdfs using sparklyr from local desktop-Spark 1.6
845,2017-07-14 06:28:24.000000000,2017-07-14 20:10:54.000000000,closed,0,unify livy_config() custom header args
844,2017-07-14 03:12:59.000000000,2018-01-17 20:56:04.000000000,closed,1,Enable save/load APIs test on Travis
843,2017-07-13 23:27:23.000000000,2017-07-23 14:13:04.000000000,closed,2,"Preserve closures, formulas and quosures in spark_apply through rlang"
842,2017-07-13 22:40:51.000000000,2017-07-26 09:31:52.000000000,closed,2,Consider modifications to spark_apply group_by API
841,2017-07-13 21:04:23.000000000,1970-01-01 00:00:00.000000001,open,1,Out of memory issue because the h2o total memory size is 0.7 gb
840,2017-07-13 19:19:43.000000000,2017-08-02 21:02:41.000000000,closed,3,Segmentation fault (core dumped) on reconnection
839,2017-07-13 11:36:59.000000000,1970-01-01 00:00:00.000000001,open,3,how to setup spark_home into spark_lyr
838,2017-07-13 10:56:33.000000000,1970-01-01 00:00:00.000000001,open,2,error while looking for metadata directory when using livy
837,2017-07-13 00:07:38.000000000,2017-07-13 02:12:19.000000000,closed,3,Fix compilation in sparklyr extensions by allowing them to not have versioned scala dirs
836,2017-07-12 21:00:46.000000000,2017-07-13 02:12:38.000000000,closed,0,Enable all Spark tests in Travis
835,2017-07-12 14:30:42.000000000,1970-01-01 00:00:00.000000001,open,1,Issues with NA _character_ and count(x)?
834,2017-07-12 09:22:25.000000000,2017-07-13 23:39:52.000000000,closed,5,Added support for custom headers in config
833,2017-07-12 05:05:47.000000000,2017-07-13 09:50:42.000000000,closed,4,Add support for group_by under spark_apply
832,2017-07-11 17:00:21.000000000,2017-07-12 20:38:16.000000000,closed,3,sparklyr parse error
831,2017-07-11 15:45:36.000000000,2017-07-12 20:35:28.000000000,closed,3,Error: parse error: premature EOF
830,2017-07-11 13:45:58.000000000,2018-01-17 20:52:24.000000000,closed,0,"Support for tidyr::unite, tidyr::separate and other tidyr verbs"
829,2017-07-11 13:20:06.000000000,2017-07-12 01:15:46.000000000,closed,3,spark 2.1.0 missing
828,2017-07-11 13:18:47.000000000,2017-07-12 20:34:49.000000000,closed,6,master branch not functional
827,2017-07-11 04:52:56.000000000,2017-07-12 02:53:42.000000000,closed,0,Prevent incorrect install prompt while reactive switches between hadoop versions
826,2017-07-11 03:18:46.000000000,1970-01-01 00:00:00.000000001,open,3,spark_read_csv issue
825,2017-07-10 14:21:45.000000000,1970-01-01 00:00:00.000000001,open,3,Error while connecting to Spark from Rstudio using sparklyr
824,2017-07-10 12:02:14.000000000,2017-07-10 22:28:42.000000000,closed,1,Update utils.R
823,2017-07-07 23:37:50.000000000,2017-07-08 00:47:15.000000000,closed,0,"For local clusters, check that java exists under JAVA_HOME to fix #801 and #562"
822,2017-07-07 21:49:31.000000000,2017-07-08 00:46:44.000000000,closed,2,add csrf_header to livy_config()
821,2017-07-07 21:14:41.000000000,2017-07-07 21:23:01.000000000,closed,0,Improve 'argument is of length zero' error and `-Inf` warning while fetching data
820,2017-07-07 09:25:35.000000000,2017-07-11 04:49:44.000000000,closed,1,Fix sparklyr under databricks and refactor connections
819,2017-07-07 04:26:40.000000000,2017-07-07 09:17:08.000000000,closed,0,Use latest installed version as default
818,2017-07-06 07:55:24.000000000,2017-07-07 09:17:08.000000000,closed,0,Local mode connection should default to latest version installed?
817,2017-07-06 04:41:53.000000000,2017-07-07 04:27:47.000000000,closed,6,Integrate with spark-install package
816,2017-07-05 21:59:44.000000000,2017-07-05 23:46:59.000000000,closed,4,Add support for columns parameter in spark_read_* functions to fix #799
815,2017-07-05 19:47:59.000000000,1970-01-01 00:00:00.000000001,open,5,spark_read_csv unable to read big data sets
814,2017-07-05 15:09:22.000000000,1970-01-01 00:00:00.000000001,open,2,Values converted to zero when working with tables of more than 200 columns
813,2017-07-03 20:04:51.000000000,1970-01-01 00:00:00.000000001,open,3,concatenating string columns
812,2017-07-03 18:08:52.000000000,2017-09-17 02:18:45.000000000,closed,33, java.io.IOException: No space left on device
811,2017-07-02 23:44:53.000000000,1970-01-01 00:00:00.000000001,open,5,Is it possible to connect sparklyr to mongodb?
810,2017-07-02 12:49:11.000000000,1970-01-01 00:00:00.000000001,open,3,Cannot connect Spark 2.1.0 cluster using sparklyr 0.5.6
809,2017-07-01 04:02:08.000000000,2017-07-01 04:02:30.000000000,closed,0,"In windows, `sparklyr.log.console` is not pushing output to console"
808,2017-06-30 21:37:52.000000000,1970-01-01 00:00:00.000000001,open,4,Consider applying settings to shell and Spark Config automatically
807,2017-06-30 13:39:37.000000000,2017-06-30 14:47:24.000000000,closed,1,Spaklyr/dplyr window functions not working properly
806,2017-06-30 04:57:34.000000000,2017-06-30 21:43:58.000000000,closed,0,implement sdf_coalesce()
805,2017-06-30 01:12:28.000000000,2017-06-30 02:30:18.000000000,closed,0,support type upcasting in sdf_bind_rows()
804,2017-06-29 23:04:25.000000000,2017-06-30 02:30:18.000000000,closed,4,sdf_bind_rows filling in NaNs
803,2017-06-29 22:26:43.000000000,2017-06-30 00:31:39.000000000,closed,2,support weights.column in GLM type models
802,2017-06-29 22:12:49.000000000,2017-06-30 02:28:30.000000000,closed,0,Add support for `spark_context_config` and `spark_context_hive`
801,2017-06-29 20:34:03.000000000,2017-07-08 00:47:16.000000000,closed,35,Failed while connecting to sparklyr to port (8880)
800,2017-06-29 19:11:10.000000000,2017-07-01 04:56:41.000000000,closed,3,spark_write_json writes json as folder?!
799,2017-06-29 14:45:47.000000000,2017-07-05 23:47:00.000000000,closed,8,spark_read_json prohibitively slow with many json files
798,2017-06-29 09:38:44.000000000,2017-07-01 04:53:11.000000000,closed,10,"Error in UseMethod(""spark_write_csv"") :   no applicable method for 'spark_write_csv' applied to an object of class ""data.frame"""
797,2017-06-29 06:34:46.000000000,2017-06-29 20:45:31.000000000,closed,0,rename columns argument of sdf_reparition to partition_by
796,2017-06-29 00:24:41.000000000,2017-06-29 03:38:50.000000000,closed,0,Add support for `partition_by` under `spark_write_*` functions
795,2017-06-28 22:36:32.000000000,2017-06-28 23:41:00.000000000,closed,1,Fix cumprod to accommodate nonpositive numbers
794,2017-06-28 21:39:00.000000000,2017-06-28 23:41:00.000000000,closed,0,cumprod() doesn't work when there are nonpositive numbers
793,2017-06-28 19:28:29.000000000,2017-06-28 23:29:29.000000000,closed,0,Fix dbplyr window function warnings
792,2017-06-28 14:41:57.000000000,2017-06-28 23:29:29.000000000,closed,3,"""Translator is missing window functions"" warning on filter"
791,2017-06-28 01:56:21.000000000,2017-06-28 03:26:55.000000000,closed,1,Use protocol to avoid path does not exist exception and fix #525
790,2017-06-27 23:56:21.000000000,2017-06-29 14:41:07.000000000,closed,7,wrong/low number of cores allocated?
789,2017-06-27 09:09:55.000000000,2017-06-27 19:39:12.000000000,closed,1,Implement `cumprod()` for dplyr operations
788,2017-06-27 03:57:49.000000000,2017-06-27 09:02:46.000000000,closed,0,"Support for `cor()`, `cov()`, `sd()` and `var()` as window functions."
787,2017-06-27 00:50:14.000000000,2017-06-27 03:42:40.000000000,closed,0,Terminate connection under no status errors.
786,2017-06-26 23:07:33.000000000,2017-08-10 23:55:35.000000000,closed,2,`ml_multilayer_perceptron` throws `ArrayIndexOutOfBoundsException`
785,2017-06-26 23:02:53.000000000,2017-06-27 03:42:41.000000000,closed,1,Crash on r-session after serializing bad strings or critical Spark exceptions
784,2017-06-26 19:35:15.000000000,2017-06-26 23:03:33.000000000,closed,3,Installation failed: Couldn't connect to server
783,2017-06-26 00:44:12.000000000,1970-01-01 00:00:00.000000001,open,14,"Reliable spark crasher on current (June 25, 2017) development version of Sparklyr"
782,2017-06-25 09:51:50.000000000,2017-06-25 09:53:16.000000000,closed,1,Bugfix/dplyr window function warnings
781,2017-06-23 22:28:44.000000000,2017-06-24 04:37:39.000000000,closed,1,Avoid crashing r-session while invoking array character with NAs #780
780,2017-06-23 20:22:55.000000000,2017-06-24 02:35:12.000000000,closed,2,Some Scala exceptions cause backend to not return a status and crash r session
779,2017-06-22 10:14:16.000000000,2017-06-27 19:39:13.000000000,closed,3, dplyr CUMPROD not available
778,2017-06-22 04:21:04.000000000,2017-06-22 22:24:02.000000000,closed,0,Make compute cache data inmemory by default to fix #721
777,2017-06-22 00:36:53.000000000,2017-06-22 04:24:01.000000000,closed,0,"Fix to spark_apply column types, unit tests and cleanup"
776,2017-06-22 00:31:49.000000000,1970-01-01 00:00:00.000000001,open,0,Newlines are properly serialized / deserialized
775,2017-06-21 23:15:26.000000000,2018-04-13 08:22:06.000000000,closed,2,Consider functionality to simplify EDA/generation of summary statistics
774,2017-06-21 12:51:44.000000000,2017-06-24 04:37:40.000000000,closed,4,spark_apply can't deal with <NA> well
773,2017-06-21 05:08:42.000000000,2017-06-21 11:16:11.000000000,closed,0,Explicit local path reference while using copy_to in yarn client to a…
772,2017-06-20 21:40:18.000000000,2017-06-29 03:38:51.000000000,closed,0,spark_write_parquet should support writing partitioned output
771,2017-06-20 21:37:57.000000000,2017-06-28 10:28:40.000000000,closed,2,full_join does not support cartesian
770,2017-06-20 21:33:06.000000000,2017-07-13 09:50:43.000000000,closed,1,gapply/group operation support for sparklyr
769,2017-06-20 18:14:22.000000000,2017-06-22 02:07:42.000000000,closed,2,Sys.getenv('SPARK_HOME') returns empty string
768,2017-06-20 16:18:01.000000000,2017-07-01 04:43:33.000000000,closed,1,Job aborted due to stage failure
767,2017-06-19 11:37:21.000000000,2017-07-01 04:39:22.000000000,closed,1,ChangeFileModeByMask error 
766,2017-06-19 08:29:03.000000000,2017-06-19 20:26:37.000000000,closed,1,"Fix spark_connect(master = ""local"") when version isn't set"
765,2017-06-18 22:56:32.000000000,2017-10-26 23:29:27.000000000,closed,2,Is there any example code on how to use the multilayer perceptron model in sprklyr ?
764,2017-06-17 23:05:13.000000000,2017-06-18 01:52:42.000000000,closed,7,Stack overflow error unioning multiple tables
763,2017-06-17 02:10:29.000000000,2017-06-17 07:27:20.000000000,closed,1,hive operators for regex matching
762,2017-06-17 02:04:22.000000000,2017-08-17 00:19:02.000000000,closed,1,Consider to standardizecolumn names used for the generated probability / predicted columns
761,2017-06-16 20:24:29.000000000,2017-06-17 07:27:20.000000000,closed,0,filter Spark dataframe based on simple regex condition?
760,2017-06-16 17:41:45.000000000,2017-06-28 05:01:33.000000000,closed,3,filter() not working in sparklyr after a group-by?
759,2017-06-16 13:59:37.000000000,2017-07-01 04:35:38.000000000,closed,7,How to overwrite a spark dataframe?
758,2017-06-16 12:46:20.000000000,2017-07-01 04:24:30.000000000,closed,3,"R code execution error - Error: Column 'database' must be length 1 or 1, not 0"
757,2017-06-16 05:18:20.000000000,2017-06-16 06:02:02.000000000,closed,0,Allow version to override spark_home for master=local and fix #726
756,2017-06-16 05:16:46.000000000,2017-06-16 05:16:48.000000000,closed,0,Ease requirements for spark_connect tofix #703
755,2017-06-16 03:12:57.000000000,2017-06-16 03:43:57.000000000,closed,1,Fix windows connection issue with newinstance0 present in logs
754,2017-06-16 00:00:26.000000000,2017-06-29 19:15:09.000000000,closed,11,error when converting millisecond timestamps?
753,2017-06-15 05:14:52.000000000,2017-06-15 21:08:37.000000000,closed,1,Validate hostname is correct while creating spark context to fix #532
752,2017-06-14 23:11:40.000000000,2017-07-01 04:23:12.000000000,closed,1,Cross database joins fail
751,2017-06-14 03:55:52.000000000,2017-06-14 20:27:51.000000000,closed,2,Serialize NaN in long columns as doubles
750,2017-06-14 03:47:19.000000000,2017-06-14 20:27:43.000000000,closed,0,No need to constantly refresh connection viewer for temp tables
749,2017-06-13 03:47:16.000000000,2017-06-13 23:58:45.000000000,closed,5,"Error while installing latest development version - namespace ‘dbplyr’ 0.0.0.9001 is being loaded, but >= 1.0.0 is required"
748,2017-06-13 02:59:48.000000000,2017-06-13 04:47:09.000000000,closed,2,logistic multinomial model training errors-out
747,2017-06-13 02:52:31.000000000,2017-07-01 04:14:32.000000000,closed,12,sparklyr/RStudio reports error on dplyr::copy_to()
746,2017-06-13 01:31:40.000000000,2017-06-13 01:37:15.000000000,closed,0,unable to load big csv in Spark?
745,2017-06-10 11:07:07.000000000,2017-06-12 07:21:06.000000000,closed,1,Forward port v0.5.6 fixes and use dplyr from CRAN.
744,2017-06-09 06:51:40.000000000,2017-06-10 09:52:54.000000000,closed,19,Version 0.7.0 of dplyr function top_n does not work with sparklyr
743,2017-06-08 20:33:56.000000000,2017-06-29 19:15:17.000000000,closed,9,how to change the default options in spark_read_csv?
742,2017-06-08 18:33:16.000000000,2017-07-01 04:50:12.000000000,closed,8,Function that returns tbl_spark from Spark SQL query
741,2017-06-08 06:42:45.000000000,1970-01-01 00:00:00.000000001,open,10,`sdf_schema` is slow with Livy
740,2017-06-07 19:17:11.000000000,2017-06-09 10:09:05.000000000,closed,1,update README to use Spark 2.1
739,2017-06-07 18:37:08.000000000,2017-06-08 19:56:10.000000000,closed,0,sdf_partition takes numeric without L prefix for partitions arg
738,2017-06-07 18:27:08.000000000,2017-06-07 18:33:46.000000000,closed,0,Improve spark_apply performance
737,2017-06-07 18:17:44.000000000,2017-08-02 10:18:00.000000000,closed,2,spark_apply not working with sdf_repartition
736,2017-06-07 13:29:38.000000000,2017-06-16 09:30:41.000000000,closed,4,Collapse text by group in sparklyr data frame 
735,2017-06-07 10:43:25.000000000,2017-06-08 19:56:10.000000000,closed,1,sdf_repartition produced error
734,2017-06-07 09:52:06.000000000,2017-08-19 00:08:57.000000000,closed,4,Support ML pipelines
733,2017-06-07 03:57:46.000000000,2017-06-07 18:33:47.000000000,closed,4,Significantly improve `spark_apply` performance
732,2017-06-06 19:02:01.000000000,2020-04-14 22:07:53.000000000,closed,1,unable to resolve 's3.amazonaws.com'
731,2017-06-06 11:29:41.000000000,2017-06-07 10:30:48.000000000,closed,3,top_n produced error
730,2017-06-05 22:06:36.000000000,2017-06-07 18:18:46.000000000,closed,0,Format NEWS for 0.6 Release
729,2017-06-05 21:14:31.000000000,2017-08-26 22:14:51.000000000,closed,3,Add support for distributing/installing packages with `spark_apply`
728,2017-06-05 10:01:44.000000000,2017-06-07 18:18:21.000000000,closed,10,Implement R Workers
727,2017-06-05 09:40:03.000000000,2017-06-05 22:10:44.000000000,closed,3,Livy sources restructure
726,2017-06-05 02:18:52.000000000,2017-06-16 06:02:03.000000000,closed,5,Failed while connecting to sparklyr to port (8880) 
725,2017-06-04 22:48:21.000000000,2017-06-05 01:08:28.000000000,closed,1,add sdf_num_partitions
724,2017-06-04 11:35:21.000000000,2017-06-04 11:46:14.000000000,closed,1,add DBIConnection to livy sc and implement create_hive_context for livy
723,2017-06-04 11:09:55.000000000,2017-06-04 12:18:31.000000000,closed,0,"Revert ""Merge pull request #719 from kevinykuo/feature/sdf_repartition"""
722,2017-06-04 08:21:51.000000000,2017-06-04 12:09:42.000000000,closed,0,Backend improvements to support context and unregister
721,2017-06-03 22:02:13.000000000,2017-06-22 22:24:02.000000000,closed,10,Spark crasher
720,2017-06-02 15:17:13.000000000,1970-01-01 00:00:00.000000001,open,2,Support for HBase Data Source
719,2017-06-01 21:19:00.000000000,2017-06-04 08:16:12.000000000,closed,4,Support implementation of Spark 2.0+ features and add sdf_repartition()
718,2017-05-31 12:38:57.000000000,2017-05-31 12:39:29.000000000,closed,0,NALong type
717,2017-05-31 08:54:35.000000000,2017-09-14 03:19:04.000000000,closed,4,Copying a vector to Spark builds a copy of the vector for each row instead of using vector as a column
716,2017-05-31 05:44:37.000000000,2017-05-31 21:16:50.000000000,closed,1,add sparklyr issue template (closes #712)
715,2017-05-31 01:49:34.000000000,1970-01-01 00:00:00.000000001,open,1,Caching Spark installations on travis to enable unit tests
714,2017-05-31 01:09:18.000000000,2017-06-04 11:43:34.000000000,closed,1,Implement sdf_repartition
713,2017-05-30 16:22:51.000000000,2020-04-16 22:56:49.000000000,closed,4,Issues with sdf_copy_to fail
712,2017-05-30 02:33:40.000000000,2017-05-31 21:16:51.000000000,closed,1,How about creating the issue template?
711,2017-05-28 21:17:21.000000000,2017-05-30 07:09:35.000000000,closed,2,Feature request: it would be very handy to have an official way to get table name and data source.
710,2017-05-28 20:30:37.000000000,2017-05-29 02:02:39.000000000,closed,5,Support for Spark 2.1.0+
709,2017-05-27 02:10:16.000000000,2017-05-27 02:55:09.000000000,closed,1,broom for ml glm/lm
708,2017-05-27 01:30:32.000000000,2017-05-27 02:54:40.000000000,closed,3,Add broom to DESCRIPTION
707,2017-05-27 00:52:05.000000000,2017-05-27 01:19:36.000000000,closed,1,livy connection broken after backend refactoring
706,2017-05-26 18:43:11.000000000,2017-05-27 02:12:41.000000000,closed,0,broom for ML glm and linear regression models - take 3
705,2017-05-26 17:59:19.000000000,2017-05-26 18:43:59.000000000,closed,0,broom for ML glm and linear regression models - take 2
704,2017-05-26 11:58:27.000000000,2017-06-16 04:46:10.000000000,closed,3,Issue while copying data to spark connection
703,2017-05-26 11:51:48.000000000,2017-06-16 05:02:12.000000000,closed,3,Failed to detect version from SPARK_HOME
702,2017-05-26 02:20:46.000000000,2017-05-26 04:25:02.000000000,closed,2,Implement checkpoint directory and checkpointing
701,2017-05-25 22:33:22.000000000,2017-05-26 09:01:36.000000000,closed,7,Implement broom for ML glm and linear regression models
700,2017-05-25 18:34:32.000000000,2017-05-25 21:36:54.000000000,closed,0,fix typos in test-config
699,2017-05-24 13:18:19.000000000,2017-05-31 12:32:13.000000000,closed,5,How to get the top nth value in sparklyr?
698,2017-05-24 04:40:28.000000000,2017-05-26 09:44:30.000000000,closed,0,Add support to instantiate multiple backends
697,2017-05-23 21:11:17.000000000,2017-05-24 01:12:09.000000000,closed,0,Make scala compiler installable without sudo
696,2017-05-23 10:05:06.000000000,2017-05-23 10:48:36.000000000,closed,0,Support a login prefixes in backend service
695,2017-05-20 01:08:44.000000000,2017-05-21 04:10:55.000000000,closed,1,Implement type_sum.spark_jobj for better printing
694,2017-05-19 23:28:15.000000000,1970-01-01 00:00:00.000000001,open,3,Unable to connect using Windows
693,2017-05-19 21:48:31.000000000,2017-05-21 04:10:55.000000000,closed,2,Better printing of tbl_spark with jobjs
692,2017-05-19 21:37:36.000000000,2017-10-26 23:43:11.000000000,closed,5,Why ml_create_dummy_variables does not omit reference variable in sparklyr
691,2017-05-19 16:38:29.000000000,2017-06-16 03:57:24.000000000,closed,2,Unable to convert data.frame to SparkR format using as.DataFrame
690,2017-05-19 08:51:21.000000000,2017-10-26 00:05:37.000000000,closed,3,Consider handling 'struct' columns with sdf_separate_column
689,2017-05-18 13:50:49.000000000,2017-08-01 22:19:33.000000000,closed,2,"How can I achieve ""case when"" in sparklyr?"
688,2017-05-18 01:23:15.000000000,2017-06-04 08:16:12.000000000,closed,5,Implementing functionality not available in older Spark versions
687,2017-05-17 12:37:31.000000000,2017-06-16 11:41:13.000000000,closed,2,Problem connecting to Spark Stand Alone Cluster 
686,2017-05-17 08:36:06.000000000,2017-05-19 02:59:37.000000000,closed,0,add sdf_broadcast()
685,2017-05-16 21:52:32.000000000,2017-05-19 03:08:40.000000000,closed,0,residuals() and sdf_residuals() for lm/glm
684,2017-05-16 12:54:26.000000000,2017-05-17 22:08:21.000000000,closed,2,converting string to datetime?
683,2017-05-16 11:28:09.000000000,2017-05-17 10:05:50.000000000,closed,2, object 'rlang_new_language' not found
682,2017-05-16 00:37:10.000000000,2017-05-16 00:47:34.000000000,closed,0,Fix spark_config regression introduced by verbose connections
681,2017-05-15 22:45:20.000000000,2017-05-26 04:24:15.000000000,closed,3,sparklyr should install with github using only one command.
680,2017-05-15 14:38:07.000000000,2017-09-15 02:35:01.000000000,closed,3,Sparklyr losing rows
679,2017-05-15 10:53:33.000000000,2017-06-16 03:49:39.000000000,closed,3,unable to open spark log
678,2017-05-15 00:15:26.000000000,2017-06-14 21:40:58.000000000,closed,9,Sparklyr rename fails with dev version of dplyr
677,2017-05-14 23:34:59.000000000,2017-06-14 20:38:54.000000000,closed,2,Duplicate columns not allowed in join
676,2017-05-13 02:10:18.000000000,2017-05-13 02:51:23.000000000,closed,0,Fix to systems that do not resolve `localhost` and new config options
675,2017-05-12 20:30:24.000000000,2017-05-13 02:51:23.000000000,closed,1,Implement `spark_connect` in `verbose` mode to help troubleshoot connections
674,2017-05-11 13:30:52.000000000,1970-01-01 00:00:00.000000001,open,0,spark_read_csv prompts one-column warning with column not NULL and de 
673,2017-05-10 23:25:33.000000000,2017-05-13 02:39:22.000000000,closed,1,add ml_model_data()
672,2017-05-10 23:10:28.000000000,2017-05-11 17:07:33.000000000,closed,3,Implement residuals() for Spark ML linear and generalized linear regressions
671,2017-05-10 22:22:23.000000000,2017-05-10 23:28:31.000000000,closed,0,Fix row count message in cbind
670,2017-05-10 02:08:52.000000000,1970-01-01 00:00:00.000000001,open,4,Implement broom functions
669,2017-05-09 07:08:09.000000000,1970-01-01 00:00:00.000000001,open,1,"In consistent of the result of ""sample_n"" between spark version and the local version "
668,2017-05-08 14:09:24.000000000,2017-09-14 03:01:48.000000000,closed,2,Error connecting to Spark Instance 
667,2017-05-08 00:09:23.000000000,2017-05-08 00:09:36.000000000,closed,0,provide 'sdf_separate_columns()' API
666,2017-05-07 19:01:01.000000000,2017-09-14 02:58:02.000000000,closed,2,Sparklyr::spark_read_csv connection to Google Cloud storage (gs://)
665,2017-05-06 19:14:16.000000000,2017-05-07 20:11:08.000000000,closed,1,update remotes in DESCRIPTION to tidyverse/
664,2017-05-06 01:19:19.000000000,2017-05-07 20:08:23.000000000,closed,1,add 'from' argument to sdf_with_sequential_id and defaults to 1
663,2017-05-06 00:05:57.000000000,2017-05-16 22:05:27.000000000,closed,5,full_join loses values in `by` column
662,2017-05-05 22:34:45.000000000,2017-05-09 08:13:49.000000000,closed,7,Implement sdf_bind_rows and sdf_bind_cols
661,2017-05-05 21:53:12.000000000,2017-05-07 20:08:23.000000000,closed,1,Consider rebasing sdf_with_sequential_id from 1 instead of 0
660,2017-05-05 21:11:09.000000000,2017-05-05 21:12:26.000000000,closed,0,Add a Gitter chat badge to README.md
659,2017-05-05 07:15:08.000000000,2017-05-05 07:19:55.000000000,closed,2,Where are we setting the tbl_spark class?
658,2017-05-05 05:21:07.000000000,2017-05-08 00:04:18.000000000,closed,4,Allow for splitting / extraction of elements from vector-columns (list-columns)
657,2017-05-03 11:21:13.000000000,2017-05-06 02:16:12.000000000,closed,10,please consider re-opening spark 2.1 R code execution error #473
656,2017-05-02 18:41:37.000000000,2017-09-14 02:56:43.000000000,closed,2,Type mismatch error for filter function with dplyr over a spark 2.0.2 data frame
655,2017-05-02 17:39:21.000000000,2017-05-10 13:25:19.000000000,closed,3,sparkR on hives in secured environment
654,2017-05-02 11:12:59.000000000,1970-01-01 00:00:00.000000001,open,3,add example of using spark_write_parquet with the options list
653,2017-05-01 19:25:37.000000000,1970-01-01 00:00:00.000000001,open,2,Cannot install or connect 
652,2017-05-01 03:31:12.000000000,2017-05-01 19:54:46.000000000,closed,3,dplyr mutate fails to add column to sparklyr table
651,2017-04-30 21:50:32.000000000,2017-04-30 22:07:47.000000000,closed,0,"join issue Spark1.6.2 reports ""same name join"" even for ""by"" columns."
650,2017-04-30 21:26:13.000000000,2017-09-13 03:57:01.000000000,closed,5,Documentation request/query: what is guaranteed about row order in sparklyr?
649,2017-04-30 21:18:53.000000000,2017-05-02 21:38:57.000000000,closed,2,Feature request: sparklyr equivalent to SparkR::dapply
648,2017-04-30 21:08:46.000000000,2017-05-20 06:35:10.000000000,closed,2,Feature request: something to pull apart ml_* probability columns.
647,2017-04-30 08:52:18.000000000,2017-09-13 02:22:49.000000000,closed,3,Observations count in glimpse
646,2017-04-29 16:19:12.000000000,2017-06-22 01:38:39.000000000,closed,7,Incorrect calculation for natural logarithms
645,2017-04-28 18:41:57.000000000,2017-09-13 02:12:48.000000000,closed,8,Missing ) in SQL query using top_n() on Spark 1.6.x
644,2017-04-27 23:01:44.000000000,2017-05-09 08:38:01.000000000,closed,1,sdf_bind_rows and sdf_bind_cols
643,2017-04-27 21:06:07.000000000,2017-04-27 22:09:13.000000000,closed,1,ensure_scalar_* respects allow.null arg
642,2017-04-27 16:15:15.000000000,2017-04-27 22:09:13.000000000,closed,0,ensure_scalar_*() with NULL input and allow.null = TRUE throws error
641,2017-04-27 00:58:23.000000000,2017-05-01 21:05:46.000000000,closed,2,Update README.Rmd
640,2017-04-25 21:31:15.000000000,2017-04-25 23:47:23.000000000,closed,0,Merge 0.5.4 CRAN fixes back to main
639,2017-04-25 06:14:55.000000000,2017-04-26 21:02:17.000000000,closed,3,Feature/cbind
638,2017-04-24 09:08:27.000000000,2017-09-13 04:35:24.000000000,closed,3,dplyr renaming of duplicate columns breaks joins
637,2017-04-22 04:29:32.000000000,2017-04-22 04:52:52.000000000,closed,4,copy_to fails on column; works on all others
636,2017-04-22 01:13:09.000000000,2017-04-24 20:43:27.000000000,closed,0,fix a typo in README.md
635,2017-04-21 21:26:56.000000000,2017-04-21 22:22:43.000000000,closed,1,Arguments must be length 1 - v0.5.4
634,2017-04-20 22:00:36.000000000,2017-04-20 22:40:14.000000000,closed,4,dplyr via livy breaking
633,2017-04-20 10:07:36.000000000,2017-06-16 03:49:33.000000000,closed,1,Error while copying R dataframe to Spark memory
632,2017-04-19 01:37:58.000000000,2017-04-19 09:00:53.000000000,closed,1,adds print_jobj method for livy_connection
631,2017-04-19 01:07:10.000000000,2017-04-25 19:57:14.000000000,closed,14,Issue building rsparkling package due to `sql_build` not found
630,2017-04-19 00:32:36.000000000,2017-04-19 02:49:20.000000000,closed,2,Allow collection/persistence of ml_model objects
629,2017-04-18 21:30:35.000000000,2017-04-18 21:40:01.000000000,closed,3,Add warning on insufficient resources while creating backend to fix #628
628,2017-04-18 19:50:23.000000000,2017-04-18 21:40:01.000000000,closed,0,Spark hangs while connecting when not enough memory is available
627,2017-04-18 19:23:56.000000000,2017-06-22 01:24:38.000000000,closed,2,Better error message when spark_home is missing in spark_connect
626,2017-04-17 22:27:13.000000000,2017-04-17 22:42:09.000000000,closed,0,Support additional jars in `spark_compile`
625,2017-04-17 22:16:22.000000000,2017-07-07 21:27:07.000000000,closed,1,Refactor databricks gateway launch into indendent codebase
624,2017-04-17 22:06:20.000000000,2017-04-17 22:25:42.000000000,closed,0,Implement spark_read_source
623,2017-04-16 01:58:36.000000000,2017-04-25 19:57:01.000000000,closed,5,CRAN version 0.5.3 of sparklyr incompatible with dev version of dplyr 0.5.0.9002
622,2017-04-14 21:24:27.000000000,2017-09-13 19:59:26.000000000,closed,6,ml_gradient_boosted_trees() is slow
621,2017-04-14 21:07:00.000000000,2017-04-18 05:45:53.000000000,closed,6,glimpse doesn't work
620,2017-04-14 20:57:50.000000000,2017-04-14 21:21:47.000000000,closed,1,Improve separator naming
619,2017-04-14 18:09:09.000000000,2017-08-02 01:14:35.000000000,closed,4,Spaces in factor levels cause problems with ml_*() functions
618,2017-04-14 08:48:47.000000000,2017-04-14 16:16:52.000000000,closed,0,Add split separator pattern for R deser in Livy connections
617,2017-04-14 00:52:57.000000000,2017-04-14 16:16:53.000000000,closed,0,Livy serde for character columns
616,2017-04-13 23:27:57.000000000,2017-09-13 02:01:00.000000000,closed,2,spark_write_parquet() aborts for large datasets
615,2017-04-13 16:23:23.000000000,1970-01-01 00:00:00.000000001,open,2,copy_to() copying large dataframes
614,2017-04-13 01:50:05.000000000,2017-04-14 15:59:45.000000000,closed,1,fixes livy_service_start() when version is not specified
613,2017-04-12 21:40:27.000000000,2017-04-12 22:48:34.000000000,closed,8,incorrect sql translation in filter
612,2017-04-12 04:23:31.000000000,2017-04-17 22:25:32.000000000,closed,2,Not calling System.exit() inside the gateway thread in service mode
611,2017-04-12 01:28:11.000000000,1970-01-01 00:00:00.000000001,open,5,Sanitize table names in copy_to()
610,2017-04-11 22:32:15.000000000,2017-04-11 22:49:14.000000000,closed,1,Return object type information only for the new connection contract
609,2017-04-10 20:36:51.000000000,2017-06-22 01:38:43.000000000,closed,4,log calculation in mutate  method returns 1/log
608,2017-04-07 23:57:48.000000000,2017-04-17 22:14:36.000000000,closed,1,Expose support to read/write data from generic data sources
607,2017-04-07 18:15:17.000000000,2017-09-13 01:34:24.000000000,closed,1,Looking for how to mimic the behavior of the tm DocumentTermMatrix method in Spark API
606,2017-04-07 00:46:09.000000000,2017-04-10 23:04:09.000000000,closed,6,Problem reading NULL values in external Hive tables
605,2017-04-06 19:33:47.000000000,2017-08-18 07:06:57.000000000,closed,4,`ft_index_to_string` fails to convert indices back to strings
604,2017-04-06 11:39:22.000000000,2017-05-10 13:06:18.000000000,closed,3,Guidance on Setting up RStudio Server and Connecting to a Hadoop Cluster
603,2017-04-06 08:38:31.000000000,2017-07-06 20:58:30.000000000,closed,4,Failed while connecting to sparklyr to port (8880) for sessionid (8227): Gateway in port (8880) did not respond.
602,2017-04-05 21:56:40.000000000,2017-08-26 21:57:09.000000000,closed,3,How to use the tm and slam packages in sparklyr 
601,2017-04-05 11:15:07.000000000,2017-04-25 22:32:34.000000000,closed,12,Unexpected data type
600,2017-04-05 08:52:26.000000000,2017-09-13 01:26:24.000000000,closed,2,Could not locate executable winutils.exe in the Hadoop binaries
599,2017-04-05 03:48:06.000000000,2017-04-05 20:56:27.000000000,closed,0,Icons for Spark and Livy connections
598,2017-04-04 22:26:06.000000000,2017-09-13 00:56:40.000000000,closed,2,Decision tree/Gradient tree visualization/Spark Ml algorithms
597,2017-04-04 18:35:58.000000000,2017-09-13 00:28:23.000000000,closed,1,calling date function from spark_data frame
596,2017-04-03 17:41:18.000000000,2017-06-22 01:21:55.000000000,closed,10,Unexpected data type when creating connection or reading data
595,2017-04-02 10:38:25.000000000,2017-09-12 23:34:42.000000000,closed,6,Spark Connection Issues
594,2017-04-02 06:09:54.000000000,2017-04-03 00:36:31.000000000,closed,1,Error: Unexpected data type
593,2017-04-01 16:34:55.000000000,2017-08-19 00:07:48.000000000,closed,5,How to create Array of `PipelineStage`?
592,2017-04-01 02:35:09.000000000,2017-04-02 00:08:37.000000000,closed,15,sparcklyr installation error
591,2017-04-01 00:26:11.000000000,2017-04-01 02:58:10.000000000,closed,1,Supporting sparklyr in Databricks clusters
590,2017-03-31 23:05:17.000000000,2017-09-12 23:32:17.000000000,closed,3,Random forest in Spark R -Accuracy or Rsquared problem
589,2017-03-31 22:27:12.000000000,2017-06-22 04:24:02.000000000,closed,0,investigate test warnings / failures
588,2017-03-31 00:32:15.000000000,2017-03-31 04:00:59.000000000,closed,0,Support dbplyr and dplyr s3 changes
587,2017-03-30 20:59:55.000000000,2017-03-31 00:32:33.000000000,closed,1,Protect against older contracts that don't support listObjectTypes
586,2017-03-30 14:59:22.000000000,2017-03-31 04:52:08.000000000,closed,8,error in Sparklyr after updating it
585,2017-03-30 11:32:12.000000000,1970-01-01 00:00:00.000000001,open,8,Is there a sparklyr function to save one csv file.
584,2017-03-30 05:19:15.000000000,2017-03-30 19:14:51.000000000,closed,1,Fix issue with NAMESPACE not finding certain S3 methods
583,2017-03-30 04:15:48.000000000,2017-03-30 22:53:56.000000000,closed,4,Error: object 'db_data_type' not found whilst loading namespace 'sparklyr'
582,2017-03-29 07:28:15.000000000,2017-09-12 23:12:00.000000000,closed,2,Can't access to S3 bucket through flintrock & sparklyr tool chain
581,2017-03-29 03:32:49.000000000,2017-03-29 03:40:34.000000000,closed,0,Implement DBIs dbExecute an dbSendStatement for spark_connection
580,2017-03-28 21:49:18.000000000,2017-03-30 00:47:23.000000000,closed,1,Implement new RStudio Connections Pane contract
579,2017-03-28 21:11:45.000000000,2017-03-28 21:22:17.000000000,closed,0,Support overwrite and append in spark_csv_write
578,2017-03-27 23:29:57.000000000,2017-03-31 03:30:29.000000000,closed,12,Error reading Hive table with Invoke
577,2017-03-27 19:00:47.000000000,2017-03-29 03:40:34.000000000,closed,1,`db_drop_table` throws an error
576,2017-03-27 15:30:28.000000000,2017-09-06 22:57:36.000000000,closed,3,sparkhello: launch 'sparklyr::compile_package_jars()' download spark-1.5.2-bin-hadoop-2.6.tgz
575,2017-03-24 19:07:13.000000000,2017-03-25 01:35:54.000000000,closed,2,Added set_spark_home_env_var()
574,2017-03-24 05:15:44.000000000,2017-03-24 05:22:09.000000000,closed,1,Support collecting sets with new lines to fix #378 and #411
573,2017-03-22 21:24:49.000000000,1970-01-01 00:00:00.000000001,open,3,I can't find the equivelant of rowSums for spark dataframes
572,2017-03-22 18:56:28.000000000,2017-05-10 12:48:54.000000000,closed,1,Dev version of dplyr (0.5.0.9000) throws while trying a mutate with Sparklyr
571,2017-03-22 01:00:52.000000000,2017-09-06 22:24:56.000000000,closed,8,Can't use sparklyr on windows corporate machine
570,2017-03-21 21:59:17.000000000,2017-03-22 00:27:20.000000000,closed,1,Simplify compilation in Windows
569,2017-03-21 13:40:03.000000000,2017-05-10 11:47:38.000000000,closed,5,How to overwrite sparklyr data frame to the file format???
568,2017-03-21 12:19:20.000000000,2017-09-06 22:13:32.000000000,closed,7,Error in Sparklyr extension creation
567,2017-03-21 02:06:45.000000000,2017-03-21 02:45:53.000000000,closed,0,Support saving to default hive path for spark_write_table
566,2017-03-21 00:24:35.000000000,2017-05-10 12:45:28.000000000,closed,6,ML model error
565,2017-03-20 14:32:18.000000000,2017-03-20 22:23:19.000000000,closed,1,Add `ml_als_factorization()` options
564,2017-03-20 02:28:11.000000000,2017-09-06 22:06:34.000000000,closed,5,APPCRASH error for rsession.exe app
563,2017-03-19 00:36:56.000000000,2017-09-06 04:07:33.000000000,closed,3,* No rows dropped by 'na.omit' call
562,2017-03-17 19:56:37.000000000,2017-07-08 00:50:46.000000000,closed,25,Failed while connecting to sparklyr to port (8880)
561,2017-03-17 11:27:51.000000000,2017-03-20 22:23:19.000000000,closed,3,Implicit Function calls for ALS
560,2017-03-17 10:50:59.000000000,2017-09-06 04:03:40.000000000,closed,3,sdf_predict for RF takes lots of time to predict
559,2017-03-17 04:23:48.000000000,2017-03-17 04:34:00.000000000,closed,0,Make connection times at a par with sparkr
558,2017-03-16 16:08:48.000000000,2017-03-28 21:22:17.000000000,closed,0,While overwriting the csv getting issue in sparklyr
557,2017-03-15 20:00:34.000000000,1970-01-01 00:00:00.000000001,open,3,Add residuals() method for ml_model objects
556,2017-03-15 19:46:37.000000000,2017-08-01 22:37:18.000000000,closed,5,"bind_cols() gives ""incompatible number of rows"" error"
555,2017-03-15 19:33:50.000000000,2017-05-13 02:39:22.000000000,closed,2,Add a method to get the data from a model
554,2017-03-15 18:59:08.000000000,2017-10-26 07:02:40.000000000,closed,7,Add support for variable transformations in ml_* formulas
553,2017-03-15 15:31:40.000000000,2017-03-20 22:23:29.000000000,closed,1,Fix typo in NEWS.md
552,2017-03-14 18:59:25.000000000,2017-03-14 23:50:09.000000000,closed,1,fix http response validation for livy
551,2017-03-14 17:33:07.000000000,2017-05-10 12:10:06.000000000,closed,6,"sparklyr java extension - spark DataFrame created, but not accessible in R"
550,2017-03-14 00:03:53.000000000,2017-09-06 03:56:38.000000000,closed,3,Persistently getting `Gateway in port (8880) did not respond`.                  
549,2017-03-13 23:07:33.000000000,2017-05-10 12:07:17.000000000,closed,7,Rstudio - Cannot read from s3n using spark_read_csv or spark_read_parquet when connected to remote spark
548,2017-03-13 22:44:41.000000000,2017-04-25 23:47:24.000000000,closed,0,CRAN Readme missing Images
547,2017-03-13 12:30:56.000000000,2017-03-13 12:40:41.000000000,closed,0,Please Ignore
546,2017-03-13 09:51:44.000000000,2017-03-14 22:40:43.000000000,closed,1,Is Poisson Regression available in sparklyr ?
545,2017-03-11 01:22:33.000000000,2017-03-11 01:29:03.000000000,closed,0,http_error was introduced in httr 1.1
544,2017-03-10 09:24:57.000000000,2017-03-10 09:49:55.000000000,closed,1,lapply equivalent operation in sparklyr
543,2017-03-10 03:51:16.000000000,2017-03-10 03:54:10.000000000,closed,0,Merge hot fix 0.5.3 back to master
542,2017-03-10 03:15:46.000000000,2017-03-13 22:45:38.000000000,closed,8,spark_connect hangs
541,2017-03-09 22:55:04.000000000,2017-09-06 03:45:26.000000000,closed,1,Investigate ghost sessions while launching `spark_connect`
540,2017-03-09 20:51:22.000000000,2018-04-13 08:26:09.000000000,closed,2,Support dplyr select helpers for ml_* and ft_* functions
539,2017-03-09 20:12:20.000000000,2017-03-10 03:54:53.000000000,closed,4,Problems building : Error in conformMethod .. cannot be in sig
538,2017-03-09 14:55:38.000000000,2017-03-10 05:32:10.000000000,closed,6,"Issues installing SparklyR since this morning (""Lazy loading failed"")"
537,2017-03-08 21:40:59.000000000,2018-01-17 20:49:07.000000000,closed,4,Simplify return value from sdf_schema()
536,2017-03-08 02:57:02.000000000,2017-10-26 23:39:43.000000000,closed,2,"Return list of character vectors from ft_tokenizer(), ft_regex_tokenizer()"
535,2017-03-07 08:54:33.000000000,2017-03-10 04:06:38.000000000,closed,4,fix NPE when passing null to a Seq parameter via invoke
534,2017-03-07 06:05:55.000000000,2017-09-06 03:43:54.000000000,closed,7,problem with spark_connect() using sparklyr on a Cloudera CDH 5.10.0  Hadoop cluster
533,2017-03-07 02:56:17.000000000,2017-06-28 03:15:03.000000000,closed,2,“Error occurred during transmission.” in RStudio while using Microsoft R
532,2017-03-06 23:06:48.000000000,2017-06-15 05:19:37.000000000,closed,6,warning messages and fail to connect to Spark locally
531,2017-03-06 01:05:45.000000000,2017-05-10 12:02:17.000000000,closed,6,Error: Variables must be length 1 or 180.
530,2017-03-05 05:54:19.000000000,2017-09-06 03:39:45.000000000,closed,2,Error in Connection
529,2017-03-05 03:36:06.000000000,2017-09-06 03:36:35.000000000,closed,2,Error in Connection to Spark
528,2017-03-04 20:32:32.000000000,2017-09-06 03:38:59.000000000,closed,2,NA representation errors-out in Spark2
527,2017-03-04 18:39:12.000000000,2017-05-10 11:50:31.000000000,closed,1,user - selected install dir
526,2017-03-02 05:23:35.000000000,2017-05-10 11:46:31.000000000,closed,1,spark_write_csv fails when writing to aws  
525,2017-03-01 20:17:38.000000000,2017-06-28 03:26:56.000000000,closed,15,Sparklyr copy_to fails
524,2017-03-01 05:22:34.000000000,2017-03-27 01:06:55.000000000,closed,6,Add feature : read/write avro file format
523,2017-03-01 00:22:14.000000000,2017-05-10 11:40:59.000000000,closed,1,`mutate` no longer works with next version of `dplyr`
522,2017-02-28 06:35:10.000000000,2017-02-28 06:40:37.000000000,closed,0,Add dplyr tests and fix `sample_frac`
521,2017-02-28 04:33:54.000000000,2017-03-21 03:13:17.000000000,closed,7,Support for dplyr 0.6
520,2017-02-26 07:48:06.000000000,2017-06-30 22:42:23.000000000,closed,16,Unable to load Cassandra table using a spark session and R
519,2017-02-26 05:38:42.000000000,2017-02-26 10:06:26.000000000,closed,2,full_join messes up numbers
518,2017-02-25 05:05:32.000000000,1970-01-01 00:00:00.000000001,open,2,filter all and any feature
517,2017-02-24 12:48:36.000000000,2017-08-24 21:01:18.000000000,closed,15,How to connect ORACLE and read table using sparklyr
516,2017-02-23 22:44:09.000000000,2017-02-23 22:52:54.000000000,closed,5,Update spark_compile.R
515,2017-02-23 03:31:18.000000000,2017-09-06 03:15:56.000000000,closed,3,Do we need to worry about nullability of columns?
514,2017-02-23 02:02:03.000000000,2017-02-26 05:01:17.000000000,closed,1,Weird serialization behavior in mutate
513,2017-02-22 11:45:49.000000000,2017-05-10 11:31:36.000000000,closed,3,Installation issue on Windows
512,2017-02-22 10:23:35.000000000,2017-09-06 03:14:05.000000000,closed,4,Remove column from sparklyr dataframe in R
511,2017-02-22 02:06:10.000000000,2017-03-18 20:57:38.000000000,closed,0,Investigate 'top_n' command performance
510,2017-02-22 01:05:17.000000000,2017-02-22 05:01:54.000000000,closed,4,"fixes rbind to match columns by name, see #507"
509,2017-02-21 09:53:58.000000000,2017-09-06 03:00:08.000000000,closed,2,Counting records in dplyr seems to trigger two jobs 
508,2017-02-21 05:35:39.000000000,2017-02-24 08:30:23.000000000,closed,7,ClassNotFoundException when running spark_connect
507,2017-02-21 02:33:04.000000000,2017-06-21 04:01:32.000000000,closed,11,union and union_all appear to ignore column names on sparklyr
506,2017-02-21 00:00:29.000000000,2017-09-06 02:58:08.000000000,closed,2," head(d, n=1) has problems on sparklyr (possibly due to blank values)"
505,2017-02-20 23:29:54.000000000,2017-02-20 23:37:21.000000000,closed,1,Feature request: dplyr::bind_rows for sparklyr
504,2017-02-20 23:26:15.000000000,2017-02-20 23:30:27.000000000,closed,0,Avoid spark_read_csv column checks when schema is proivided
503,2017-02-20 22:56:41.000000000,2017-02-21 20:58:51.000000000,closed,3,Altering captured reference damages spark results.
502,2017-02-18 22:35:24.000000000,2017-05-10 08:10:32.000000000,closed,2,sparklyr and SparkR - the future?
501,2017-02-18 15:21:53.000000000,2017-02-22 03:46:49.000000000,closed,3,Handling database name again
500,2017-02-18 04:31:30.000000000,2017-02-18 04:34:36.000000000,closed,0,Mutate does not collect the correct columns
499,2017-02-18 03:11:13.000000000,2017-09-06 03:11:50.000000000,closed,8,Unable to submit job using livy in yarn mode 
498,2017-02-17 07:05:10.000000000,2017-02-17 07:22:45.000000000,closed,1,WIP: Immediately remove serialized temp csv files
497,2017-02-17 04:46:03.000000000,2017-06-16 03:49:29.000000000,closed,6,sparklyr error may be due to tmp/hive settings
496,2017-02-16 21:00:13.000000000,1970-01-01 00:00:00.000000001,open,8,temporary spark_serialize_*.csv files don't get deleted
495,2017-02-16 03:33:13.000000000,2017-03-01 18:29:11.000000000,closed,1,Long converted to numeric when using invoke_new()
494,2017-02-16 02:48:54.000000000,2017-02-16 02:51:39.000000000,closed,0,Always check winutil permissions and throw on error
493,2017-02-16 01:28:23.000000000,2017-02-16 01:33:14.000000000,closed,0,Improve logging for windows connection preparation
492,2017-02-15 13:50:55.000000000,2017-02-15 22:14:52.000000000,closed,5,Normalize jar paths for windows under spark 1.6
491,2017-02-15 11:28:48.000000000,2017-02-16 02:57:54.000000000,closed,13,Installation and copy_to errors
490,2017-02-15 06:18:59.000000000,2017-02-17 22:19:33.000000000,closed,4,Receiving Error when trying to use copy_to() function
489,2017-02-15 05:30:43.000000000,2017-02-15 07:02:09.000000000,closed,1,Add support to supecify column names in spark_read_csv
488,2017-02-15 03:24:47.000000000,2017-02-15 03:28:46.000000000,closed,0,Improve copy_to perf under yarn-client
487,2017-02-14 19:43:34.000000000,1970-01-01 00:00:00.000000001,open,6,"can't ""copy_to"" large datasets"
486,2017-02-13 22:41:01.000000000,2017-02-13 22:43:51.000000000,closed,0,Add SystemRequirements to DESCRIPTION
485,2017-02-13 13:14:04.000000000,2017-02-25 02:14:55.000000000,closed,10,select() doesn't work in sparklyr
484,2017-02-12 05:20:10.000000000,2017-02-12 05:29:26.000000000,closed,1,Fix typo in readme
483,2017-02-10 19:43:16.000000000,2017-06-20 01:01:29.000000000,closed,1,Get rotated data from ml_pca()
482,2017-02-10 15:24:26.000000000,2017-05-10 11:10:20.000000000,closed,10,No FileSystem for scheme: s3n
481,2017-02-10 12:28:56.000000000,2017-02-17 00:09:44.000000000,closed,3,Handle multiple databases with `tbl()`
480,2017-02-10 07:33:26.000000000,2017-02-13 22:43:52.000000000,closed,0,Include Spark Versions in DESCRIPTION
479,2017-02-10 05:17:02.000000000,2017-02-14 00:23:45.000000000,closed,2,Easy way to run Scala code within sparklyr?
478,2017-02-09 06:34:57.000000000,2017-02-09 06:38:51.000000000,closed,0,Fix Livy for Spark 2.0
477,2017-02-08 22:22:34.000000000,2017-02-10 11:47:37.000000000,closed,10,Error: Variables must be length 1 or 1.
476,2017-02-08 21:02:45.000000000,2017-05-10 11:09:36.000000000,closed,2,read sparkdataframes created with sparkr
475,2017-02-08 11:12:08.000000000,2017-02-20 15:01:20.000000000,closed,4,Error while connecting with spark with sparkly using RStudio with Kerberos enabled machines
474,2017-02-07 12:46:27.000000000,2017-02-09 05:21:17.000000000,closed,7,Handle database name
473,2017-02-06 20:09:14.000000000,2017-02-10 11:48:07.000000000,closed,8,spark 2.1 R code execution error
472,2017-02-06 18:41:05.000000000,2017-02-09 18:41:30.000000000,closed,5,SparklyR only connecting to 2/6 workers on standalone spark cluster
471,2017-02-04 19:50:31.000000000,2017-08-26 10:23:56.000000000,closed,3,[ml_lda()] Some Fundamental Question after Fitting ml_lda()
470,2017-02-04 04:43:40.000000000,2017-02-04 04:49:32.000000000,closed,0,Add rsparkling code snippet to README file
469,2017-02-04 04:37:24.000000000,2017-02-04 04:44:01.000000000,closed,0,Detect protocols in remote resources to avoid normalizing path
468,2017-02-02 19:00:11.000000000,2017-10-26 23:25:20.000000000,closed,1,Need ability to control boundaries in ft_quantile_discretizer()
467,2017-02-02 04:19:04.000000000,2017-02-04 04:03:29.000000000,closed,0,Use updated dialog api entry points
466,2017-02-02 03:46:33.000000000,2017-06-16 03:49:26.000000000,closed,1,/tmp/hive on HDFS should be writable error
465,2017-02-02 02:40:25.000000000,2017-08-26 06:20:44.000000000,closed,5,ft_binarizer() adds numeric field rather than logical
464,2017-02-02 01:14:54.000000000,2017-08-26 06:24:31.000000000,closed,6,Results of ft_one_hot_encoder() are short by one state when input contains zeroes
463,2017-02-02 01:07:57.000000000,2017-06-14 20:27:52.000000000,closed,4,Null values in Long columns are collected as -2^63
462,2017-02-01 23:57:33.000000000,2017-02-17 22:25:15.000000000,closed,1,Implement spark_read_jdbc to load data from jdbc sources
461,2017-02-01 21:49:00.000000000,1970-01-01 00:00:00.000000001,open,0,mutate + cut throws spark.sql.AnalysisException
460,2017-02-01 21:26:49.000000000,2017-06-21 03:38:18.000000000,closed,1,Path problem using spark_write_csv on windows 10 to Livy / Spark on Linux
459,2017-02-01 07:02:44.000000000,2017-02-02 01:25:46.000000000,closed,0,Bugfix while connecting and disconnecting from the ui
458,2017-02-01 01:01:35.000000000,2017-02-01 01:01:45.000000000,closed,0,Escape livy connection ui
457,2017-01-31 19:26:47.000000000,2017-08-18 03:52:20.000000000,closed,1,Malformed \uxxxx encoding error during spark_connect - result: sparklyr unusable
456,2017-01-31 14:23:52.000000000,2017-06-16 03:49:23.000000000,closed,1,Error Trying to create tables on spark using copy_to
455,2017-01-31 12:13:12.000000000,2017-08-18 03:19:51.000000000,closed,1,Random numbers generation
454,2017-01-30 12:01:32.000000000,2017-02-04 04:44:01.000000000,closed,2,spark_normalize_path
453,2017-01-30 06:54:20.000000000,2017-01-30 10:02:09.000000000,closed,1,Unable to retreive a Spark DataFrame from object of class SparkDataFrame
452,2017-01-26 14:39:12.000000000,2017-05-10 10:51:52.000000000,closed,7,pivoting table using invoke
451,2017-01-26 09:54:53.000000000,2017-01-28 03:55:04.000000000,closed,0,Use official release path for livy and livy to connections ui
450,2017-01-26 00:22:37.000000000,2017-01-26 02:31:45.000000000,closed,0,support collecting nulltypes as nas to fix #448
449,2017-01-25 23:32:44.000000000,2017-01-26 00:16:41.000000000,closed,5,Error when trying to save a 'ml_model' - Error: Invalid method save for object 2109
448,2017-01-25 19:54:05.000000000,2017-01-26 02:31:46.000000000,closed,3,Bug when assign NA to a column 
447,2017-01-25 16:14:41.000000000,2017-02-09 05:21:17.000000000,closed,0,Support for caching tables from other database apart from 'default' in Hive 
446,2017-01-25 11:01:16.000000000,2017-01-25 23:39:40.000000000,closed,2,spark_normalize_path does not return anything on Windows
445,2017-01-25 03:34:52.000000000,2017-01-25 03:39:44.000000000,closed,0,Fix deprecated warning while connecting to livy
444,2017-01-24 20:17:28.000000000,2017-01-25 15:43:04.000000000,closed,3,invoke issues on org.apache.spark.sql.Dataset
443,2017-01-24 01:45:05.000000000,2017-01-24 05:57:20.000000000,closed,2,"Count performance [e.g., GROUP BY vs. COUNT(*)]"
442,2017-01-23 21:13:33.000000000,2017-05-10 10:48:41.000000000,closed,3,ft_string_indexer with multiple variables
441,2017-01-21 05:49:49.000000000,2017-01-21 06:00:38.000000000,closed,0,`spark_normalize_path` not working correctly in windows
440,2017-01-21 04:23:13.000000000,2017-01-21 05:29:11.000000000,closed,0,Implement ft_count_vectorizer to enable easy use of ml_lda
439,2017-01-20 03:37:55.000000000,2017-08-24 21:45:20.000000000,closed,7,NullPointerException in ft_string_indexer
438,2017-01-20 01:24:52.000000000,1970-01-01 00:00:00.000000001,open,0,Directing Spark to use a different temp directory ( get round Mcafee Firewall).
437,2017-01-19 03:49:33.000000000,2017-08-24 22:06:30.000000000,closed,7,ml_decision_tree failed to compile
436,2017-01-19 01:48:49.000000000,2017-05-10 10:46:43.000000000,closed,2,ml_lda error
435,2017-01-18 22:56:44.000000000,2017-01-18 23:01:36.000000000,closed,0,Error 404: Not Found when installing Spark
434,2017-01-18 21:42:09.000000000,2017-01-18 22:14:03.000000000,closed,1,defined schema dynamically
433,2017-01-18 19:18:25.000000000,2017-01-25 03:39:45.000000000,closed,0,Livy warning triggers for `text_content` marked as deprecated
432,2017-01-18 14:18:03.000000000,2017-01-21 06:00:38.000000000,closed,2,Reading parquet data from S3
431,2017-01-17 21:03:54.000000000,2017-01-17 21:29:32.000000000,closed,3,is the SVM implemented in sparklyr ?
430,2017-01-17 16:20:46.000000000,2017-01-27 15:46:49.000000000,closed,1,Unable to connect spark to cassandra DB
429,2017-01-17 08:58:53.000000000,2017-05-10 10:46:05.000000000,closed,2,Uanble to implement invoke_new
428,2017-01-17 03:10:20.000000000,2017-01-18 20:58:38.000000000,closed,0,Implement options for shinyapp connections ui
427,2017-01-16 18:23:54.000000000,1970-01-01 00:00:00.000000001,open,0,Consider writing template test for Livy
426,2017-01-13 11:55:18.000000000,2017-06-27 09:02:46.000000000,closed,4,"cov, cor, sd, var are not available for use in mutate with Spark data frames"
425,2017-01-12 22:29:36.000000000,2017-05-10 10:38:17.000000000,closed,3,QuantileDiscretizer not finding setNumBuckets method
424,2017-01-12 02:51:00.000000000,2017-01-14 04:23:35.000000000,closed,5,Availability of toDebugString when using classification trees -Question
423,2017-01-12 01:54:27.000000000,2017-01-12 02:48:38.000000000,closed,1,investigate tokenizer test failures with Spark 1.6.2
422,2017-01-12 01:46:23.000000000,2017-01-12 02:41:31.000000000,closed,1,investigate ml_kmeans() test failure with Spark 2.1.0
421,2017-01-11 20:55:32.000000000,2017-01-16 18:24:10.000000000,closed,1,added waiting state
420,2017-01-11 13:36:17.000000000,2017-08-24 21:29:11.000000000,closed,11,Disabling Firewall/Mcafee Solves Connection Problem..Almost..Need directory list
419,2017-01-11 10:16:44.000000000,2017-01-11 10:21:23.000000000,closed,2,investigate test failures
418,2017-01-11 10:16:05.000000000,2017-01-11 10:16:19.000000000,closed,0,tests failing with CRAN DBI?
417,2017-01-11 09:40:37.000000000,2017-01-11 10:09:21.000000000,closed,1,object '.sparkREnv' not found
416,2017-01-11 04:21:23.000000000,2017-08-24 21:05:40.000000000,closed,1,Unable to create DTM document term matrix java.lang.OutOfMemoryError
415,2017-01-10 22:42:53.000000000,2018-08-24 00:08:40.000000000,closed,3,Disable hive support
414,2017-01-09 19:09:19.000000000,2017-02-17 22:15:08.000000000,closed,4,No FileSystem for scheme
413,2017-01-09 17:14:38.000000000,2017-05-10 10:34:34.000000000,closed,3,Failed to find Spark jars directory.
412,2017-01-09 13:53:16.000000000,2017-08-18 03:47:48.000000000,closed,2,please help me to slove this error
411,2017-01-09 02:11:53.000000000,2017-05-10 10:32:41.000000000,closed,8,Collecting string columns with new line characters splits into multiple rows
410,2017-01-08 23:09:10.000000000,2017-09-06 22:23:41.000000000,closed,22,Not able to connect to sparklyr or open a connection
409,2017-01-08 12:02:17.000000000,2017-06-16 03:49:20.000000000,closed,5,Get Java Error when Establishing/Using Connection
408,2017-01-08 10:31:01.000000000,2017-01-09 02:21:13.000000000,closed,1,Implement sample_n and sample_frac using tablesample
407,2017-01-08 10:14:43.000000000,2017-05-10 10:31:44.000000000,closed,21,Add download information for Spark 2.1.0
406,2017-01-07 06:01:12.000000000,2017-01-17 03:13:22.000000000,closed,0,Implement dynamic hadoop selection in shiny app
405,2017-01-07 03:40:48.000000000,2017-01-07 05:59:06.000000000,closed,0,Prompt for Spark install in shinyapp when version not installed 
404,2017-01-07 03:36:07.000000000,2017-01-07 05:58:57.000000000,closed,0,Add warning to shinyapp when java install is missing
403,2017-01-07 00:10:12.000000000,1970-01-01 00:00:00.000000001,open,1,Loading ObjectId from MongoDB
402,2017-01-06 04:37:13.000000000,2017-01-06 23:44:36.000000000,closed,0,Implement 3 connection alerts for shinyapp dialog
401,2017-01-04 21:40:10.000000000,2017-07-08 00:53:22.000000000,closed,13,sparklyr in YARN with high availability
400,2017-01-04 16:19:19.000000000,2017-01-11 16:27:03.000000000,closed,5,Gateway did not respond
399,2017-01-02 22:27:57.000000000,2017-04-29 01:37:02.000000000,closed,13,System cannot find the path specified.
398,2017-01-01 20:10:58.000000000,2017-02-17 22:18:59.000000000,closed,23,Error on Connect instruction on new machine
397,2017-01-01 11:53:06.000000000,2017-06-16 03:49:17.000000000,closed,5,Error when establishing Connection to spark
396,2016-12-30 13:40:04.000000000,2017-08-18 02:31:23.000000000,closed,3,select function demands column name to be in lower case while in fact it is not
395,2016-12-30 13:01:54.000000000,2017-08-18 02:29:08.000000000,closed,1,Cannot use first function inside summary
394,2016-12-27 02:47:44.000000000,1970-01-01 00:00:00.000000001,open,8,  Failed while connecting to sparklyr to port (8880) for sessionid (8540): Gateway in port (8880) did not respond.
393,2016-12-23 00:49:04.000000000,2017-08-18 02:22:56.000000000,closed,2,Consider: Should sdf_collect return a dplyr frame?
392,2016-12-21 02:41:26.000000000,2016-12-21 07:17:38.000000000,closed,1,Unable to read CSV
391,2016-12-20 23:03:39.000000000,2016-12-21 23:57:18.000000000,closed,1,sdf_save_table references non-existent function
390,2016-12-19 16:58:47.000000000,2016-12-20 11:54:18.000000000,closed,1,Unable to install version 0.5 with RStudio 1.0.44
389,2016-12-17 05:42:36.000000000,2016-12-18 10:43:29.000000000,closed,6,Spark doesn't respect config passed to spark_connect() v2
388,2016-12-17 01:10:27.000000000,2016-12-18 23:52:36.000000000,closed,1,Update sparklyr for 0.5 CRAN release
387,2016-12-17 00:29:34.000000000,2017-03-28 20:53:52.000000000,closed,2,Address breaking change in dplyr to use con_acquire()
386,2016-12-15 23:43:18.000000000,2017-08-18 02:21:56.000000000,closed,2,"""Failed to create Hive context"" warning on EC2 instance (/tmp/hive not writable)"
385,2016-12-15 20:15:13.000000000,2016-12-15 23:35:18.000000000,closed,1,"left_join() options ""by="" not work in library(sparklyr)"
384,2016-12-15 18:22:16.000000000,2017-08-18 02:20:48.000000000,closed,1,ft_one_hot_encoder columns name exception
383,2016-12-14 03:28:09.000000000,2017-01-16 18:34:55.000000000,closed,3,"""Failed to execute Livy statement with state waiting"" error happens occasionally"
382,2016-12-14 03:25:31.000000000,2017-08-18 02:17:02.000000000,closed,5,IllegalArgumentException with austen_books when using Livy
381,2016-12-13 23:02:00.000000000,2016-12-13 23:03:13.000000000,closed,0,Generalize livy_config_auth to livy_config and support pipes
380,2016-12-13 01:51:27.000000000,2016-12-20 00:29:37.000000000,closed,2,Implement SparklyR side of new package connection contract
379,2016-12-13 01:37:14.000000000,2017-05-10 10:23:44.000000000,closed,3,OutOfMemoryError
378,2016-12-12 14:58:34.000000000,2017-03-24 05:22:10.000000000,closed,3,Failure when JSON fields contain `\n` or `\r` characters
377,2016-12-12 12:34:18.000000000,2017-08-04 17:23:27.000000000,closed,3,How to control Random Forest
376,2016-12-10 01:04:50.000000000,2016-12-10 01:09:49.000000000,closed,0,app_name and others should throw warning when used in livy
375,2016-12-09 08:36:47.000000000,2017-05-10 10:21:37.000000000,closed,5,Unable to launch master locally
374,2016-12-08 20:55:20.000000000,2016-12-10 03:09:01.000000000,closed,1,reading csv with escaped quote chars.
373,2016-12-08 19:54:33.000000000,2016-12-13 00:14:04.000000000,closed,1,Added download links for Spark 2.0.2
372,2016-12-08 04:45:45.000000000,2016-12-08 05:40:22.000000000,closed,1,spark_disconnect does not close a Livy connection 
371,2016-12-08 04:36:10.000000000,2016-12-17 03:30:53.000000000,closed,9,WIP: fix dbi 0.5.13 breaking change from #351
370,2016-12-08 00:16:00.000000000,2016-12-08 05:52:55.000000000,closed,0,Trailing slash in the Livy URL causes error
369,2016-12-07 09:13:38.000000000,2016-12-10 05:53:27.000000000,closed,2,sdf_copy_to not registering DataFrame
368,2016-12-07 01:55:59.000000000,2016-12-08 05:40:55.000000000,closed,1,Error connecting to livy on EMR cluster with R 3.2.2
367,2016-12-07 01:50:28.000000000,2017-02-10 22:51:39.000000000,closed,7,Cannot connect to livy on EMR cluster using spark 2.0.1/livy3.0/scala 2.10 
366,2016-12-06 03:28:37.000000000,2016-12-10 08:20:36.000000000,closed,2,"copy_to(sc, iris) error if spark_connect(master =""spark://abc:7077), but OK if master=""local"""
365,2016-12-05 23:58:56.000000000,2016-12-10 01:09:49.000000000,closed,0,livy_install should not create folders with spark version in it
364,2016-12-03 05:01:54.000000000,2017-08-18 02:15:45.000000000,closed,4,sdf_partition fails to resolve automatically renamed columns after join
363,2016-12-03 04:41:10.000000000,2017-08-18 02:14:33.000000000,closed,4,dplyr compute() Bug
362,2016-12-03 02:57:51.000000000,1970-01-01 00:00:00.000000001,open,9,xgboost
361,2016-12-02 21:15:28.000000000,2016-12-05 22:06:32.000000000,closed,1,Set hadoopConfiguration with invoke 
360,2016-12-02 12:14:53.000000000,2017-05-10 10:15:56.000000000,closed,3,rsparkling-- unable to connect_spark()
359,2016-12-02 06:07:41.000000000,2016-12-20 00:35:56.000000000,closed,0,Implement the create connection ui with miniUI
358,2016-12-02 04:43:37.000000000,2016-12-02 05:30:39.000000000,closed,0,feat: include driver class path in base config
357,2016-12-01 23:24:15.000000000,2016-12-09 23:44:28.000000000,closed,4,Regression is dplyr do for ml models
356,2016-12-01 22:22:10.000000000,2016-12-10 05:47:00.000000000,closed,1,Error in ml_multilayer_perceptron_validate_layers
355,2016-12-01 21:50:50.000000000,2017-08-18 03:16:50.000000000,closed,3,Accuracy metric failing for Spark 1.6.0
354,2016-12-01 21:21:20.000000000,2017-06-16 03:49:14.000000000,closed,16,"iris_tb<-copy_to(sc,iris)"
353,2016-12-01 21:15:27.000000000,2017-05-10 10:11:52.000000000,closed,3,Connecting to Cluster and MLib
352,2016-12-01 20:57:17.000000000,2016-12-02 20:19:07.000000000,closed,3,"sc <- spark_connect(master = ""local"", config = list())"
351,2016-12-01 19:56:36.000000000,2017-05-10 10:07:40.000000000,closed,7,sqlInterpolate() and sqlParseVariables(): Change of interface
350,2016-12-01 05:06:00.000000000,2016-12-02 03:52:53.000000000,closed,1,Add support to add spark-submit params with sparklyr.shell.args env var
349,2016-12-01 03:55:17.000000000,2016-12-01 10:57:30.000000000,closed,0,Add support for basic authentication to livy connections
348,2016-12-01 03:05:52.000000000,2018-04-13 08:25:09.000000000,closed,2,"Random forest unable to handle catagorical independent varaible which contains ""."""
347,2016-12-01 01:33:30.000000000,2017-08-18 02:02:07.000000000,closed,1,fromJSON/sparklyr
346,2016-11-30 06:04:56.000000000,2016-11-30 06:56:17.000000000,closed,4,unable to count number of rows
345,2016-11-30 03:28:21.000000000,2016-11-30 04:22:04.000000000,closed,1,Improve performance for dplyr chains with ml
344,2016-11-29 21:24:27.000000000,2016-11-30 03:42:07.000000000,closed,1,Use get directly rather than duplicating the function
343,2016-11-29 03:24:49.000000000,2016-11-30 02:19:40.000000000,closed,1,ml_tree_feature_importance
342,2016-11-29 02:50:49.000000000,2016-11-30 23:03:43.000000000,closed,2,cran examples strategy
341,2016-11-29 02:02:54.000000000,2016-11-29 02:46:23.000000000,closed,1,ft_quantile_discretizer could never have worked 
340,2016-11-27 23:09:27.000000000,2016-12-11 00:09:58.000000000,closed,3,Would be more faithful to data if sparklyr represented NA as Spark lit(null:*) instead of blank and NaN.
339,2016-11-27 07:47:18.000000000,2017-08-18 02:00:40.000000000,closed,1,sparklyr fails to create temp table in _join(copy=TRUE) with dplyr and Spark 2.0.0
338,2016-11-27 07:42:46.000000000,2017-07-01 17:58:24.000000000,closed,2,"sparklyr complains about ""same name columns"" in join with dplyr and Spark 1.6.2"
337,2016-11-27 03:31:41.000000000,2016-11-28 23:26:48.000000000,closed,1,Bugfix: Allow column naming when HEADER=FALSE and columns defined
336,2016-11-24 19:34:15.000000000,2017-08-18 01:54:46.000000000,closed,6,ml_save fails in yarn-client mode
335,2016-11-24 04:56:43.000000000,2016-11-30 04:22:16.000000000,closed,0,Changes to tbl_cache and sdf_read/write
334,2016-11-24 00:30:40.000000000,2016-11-24 03:19:46.000000000,closed,2,Refactor copy_to into sdf_import
333,2016-11-23 23:28:25.000000000,2017-08-18 01:52:30.000000000,closed,2,Investigate Livy configuration while using `copy_to` with large files
332,2016-11-23 14:29:17.000000000,2017-05-10 10:01:50.000000000,closed,4,Java heap space reading table from hive
331,2016-11-22 06:31:50.000000000,2016-11-23 11:18:26.000000000,closed,5,Incorrect log calculation
330,2016-11-18 01:58:30.000000000,2017-08-18 01:58:30.000000000,closed,4,"spark_connect throws ""Failed to create Hive context, falling back to SQL."""
329,2016-11-17 15:26:31.000000000,2017-06-17 07:27:20.000000000,closed,4,"Including grep, mataches, etc in mutate"
328,2016-11-17 02:25:17.000000000,2016-11-17 23:08:42.000000000,closed,0,add support for 'data' argument in ml routines
327,2016-11-16 05:17:19.000000000,2016-11-23 05:21:25.000000000,closed,2,use friendly names when using copy_to
326,2016-11-16 00:17:04.000000000,2016-11-16 00:28:21.000000000,closed,2,deserialize DenseVector as arrays
325,2016-11-15 05:53:56.000000000,2016-11-15 05:59:25.000000000,closed,0,fix sparklyr in windows for spark 2.0.1 #323
324,2016-11-15 00:00:55.000000000,2016-11-16 00:21:19.000000000,closed,2,set sparklyr.do.implicit.dot to FALSE
323,2016-11-13 10:44:53.000000000,2016-11-15 08:51:06.000000000,closed,9,New copy_to() error Spark 2.0.1
322,2016-11-11 12:01:06.000000000,2016-11-12 05:54:57.000000000,closed,0,use spark.sql.warehouse.dir especially for spark 2.0 windows installs
321,2016-11-11 08:00:16.000000000,2017-08-18 01:50:32.000000000,closed,7,Error when trying to connect to spark 
320,2016-11-11 04:26:14.000000000,2016-11-11 04:26:25.000000000,closed,0,scope java version checks to local installs since not all clusters use JAVA_HOME
319,2016-11-11 01:11:26.000000000,2016-11-23 05:37:05.000000000,closed,5,"Consider implementing dim(), nrow(), ncol() for Spark data frames"
318,2016-11-11 01:03:10.000000000,2016-11-15 06:09:39.000000000,closed,3,drat repository for sparklyr
317,2016-11-10 23:18:52.000000000,2017-08-18 01:47:39.000000000,closed,3,support for nested object / method access in 'invoke'?
316,2016-11-09 23:31:10.000000000,2016-11-10 03:53:25.000000000,closed,1,Create spark data.frame with copy_to fail on expression
315,2016-11-09 19:38:27.000000000,2016-11-15 06:10:48.000000000,closed,7,spark_read_csv - does it read the data into main memory of the R session?
314,2016-11-09 13:01:30.000000000,2016-11-10 22:10:01.000000000,closed,6,Embed csv parser and dependencies directly into sparklyr
313,2016-11-08 00:08:38.000000000,2016-11-09 20:11:01.000000000,closed,2,sparklyr als getting a java.lang.NullPointerException error when predicting
312,2016-11-07 22:53:53.000000000,2016-11-09 09:24:07.000000000,closed,3,Performance difference between Spark and Sparklyr
311,2016-11-06 15:20:08.000000000,2016-11-07 19:17:59.000000000,closed,2,spark_install fails on win10
310,2016-11-05 23:21:18.000000000,2016-11-09 03:41:30.000000000,closed,1,How to add and save new attributes in Spark dataframe and parquet file?
309,2016-11-05 07:20:38.000000000,2016-11-05 08:58:21.000000000,closed,3,spark_connect() Error in validate_java_version() on AWS EMR Cluster
308,2016-11-04 20:30:35.000000000,2016-11-30 04:28:11.000000000,closed,13,Investigate performance regression from 0.4 in ml_linear_regression
307,2016-11-04 14:43:10.000000000,2017-08-18 01:46:39.000000000,closed,3,"Titanic data loaded OK in local mode, fail to load in yarn-client mode"
306,2016-11-03 16:10:17.000000000,2016-11-04 12:31:43.000000000,closed,6,Sparklyr connection issue on Mac OS Sierra
305,2016-11-03 09:00:12.000000000,2017-02-17 22:23:26.000000000,closed,23,"Unable to create spark connect from Rstudio, also from R console"
304,2016-11-02 02:20:49.000000000,2017-08-18 01:43:56.000000000,closed,12,Error when copying dataframe to spark context
303,2016-11-01 02:18:52.000000000,2017-08-18 01:41:34.000000000,closed,8,Rstudio Not Responding Once Open (Mac)
302,2016-11-01 00:50:04.000000000,2016-11-03 22:32:46.000000000,closed,2,spark_install failure with R 3.3.2
301,2016-10-31 22:20:33.000000000,2016-11-01 03:54:10.000000000,closed,1,initial support for (serial) 'do'
300,2016-10-31 21:01:27.000000000,2016-11-01 02:09:58.000000000,closed,4,dplyr / spark_read_csv() / High Column count Bug
299,2016-10-31 13:56:48.000000000,2017-08-18 01:39:06.000000000,closed,39,sparklyr remote connect : spark_connect() 
298,2016-10-29 21:34:04.000000000,2017-08-18 01:34:57.000000000,closed,6,Error: C stack usage is too close to the limit - ml_random_forest
297,2016-10-28 22:44:21.000000000,2017-08-18 01:19:47.000000000,closed,2,SparkContext lost after stopping operation in console
296,2016-10-28 19:56:22.000000000,2017-05-10 08:28:54.000000000,closed,4,ML functions do not respect table groupings
295,2016-10-28 12:46:43.000000000,2017-05-10 08:27:04.000000000,closed,11,spark_connect error
294,2016-10-28 12:22:46.000000000,2017-05-10 08:24:28.000000000,closed,5,sdf_load_table get error
293,2016-10-28 08:12:33.000000000,2016-10-29 02:57:43.000000000,closed,1,Behavior of NA
292,2016-10-28 01:50:41.000000000,1970-01-01 00:00:00.000000001,open,0,Warn users if unrecognized options are found in the config file
291,2016-10-28 00:30:52.000000000,2017-05-05 07:05:16.000000000,closed,1,Defaults in spark_read_*
290,2016-10-27 20:51:51.000000000,2016-10-27 21:22:02.000000000,closed,2,Export sdf_schema
289,2016-10-27 10:55:28.000000000,2016-10-27 22:56:47.000000000,closed,0,add support for infer_schema and columns options to spark_read_csv
288,2016-10-27 07:58:32.000000000,2017-05-10 08:21:08.000000000,closed,8,Unable to run spark_connect
287,2016-10-27 02:08:39.000000000,2017-05-10 08:20:16.000000000,closed,15,running sparklyr and getting memory error
286,2016-10-27 02:00:36.000000000,2016-10-28 09:06:08.000000000,closed,1,Spark doesn't respect config passed to spark_connect()
285,2016-10-26 23:55:57.000000000,2016-10-27 11:31:06.000000000,closed,3,Consider adding support for ALS (alternating least squares) algorithm
284,2016-10-26 00:47:03.000000000,2017-05-10 08:17:08.000000000,closed,2,Error when connect sparklyr to remote Spark cluster
283,2016-10-25 23:01:56.000000000,2016-10-27 20:42:51.000000000,closed,2,Commentd out shell_args <- NULL so that the shell args will be passed to the command line
282,2016-10-25 22:49:50.000000000,1970-01-01 00:00:00.000000001,open,5,Connect sparklyr to remote Spark master
281,2016-10-25 22:31:36.000000000,2016-11-11 04:34:07.000000000,closed,4,Local connection error: Failed while connecting to sparklyr to port (8880) for sessionid (103): Gateway in port (8880) did not respond.
280,2016-10-24 08:46:42.000000000,2016-11-01 07:30:13.000000000,closed,2,Connecting to EMR from a separate EC2 instance
279,2016-10-23 19:13:47.000000000,2018-04-13 20:26:31.000000000,closed,14,Call Tf-Idf Spark function from sparklyr
278,2016-10-22 09:23:44.000000000,2016-11-09 05:46:46.000000000,closed,3,copy_to error on Debian
277,2016-10-21 02:51:51.000000000,2017-06-16 03:48:47.000000000,closed,32,copy_to Error
276,2016-10-20 22:56:57.000000000,2016-10-21 00:32:35.000000000,closed,0,default to 'internal' tar
275,2016-10-20 22:07:47.000000000,2016-11-01 21:25:00.000000000,closed,4,Spark memory storage in RStudio Server
274,2016-10-20 13:46:12.000000000,2017-05-10 08:11:17.000000000,closed,19,sparklyr spark_connect issue
273,2016-10-20 04:48:03.000000000,2016-10-20 04:50:13.000000000,closed,1,"fix for namespace collision, closes #272"
272,2016-10-20 04:23:58.000000000,2016-10-20 04:50:14.000000000,closed,4,fix imports to avoid namespace collision
271,2016-10-17 02:04:44.000000000,2017-05-10 08:09:54.000000000,closed,3,dplyr::sample_n fails with wrong SQL when non Hive context is available
270,2016-10-16 22:48:10.000000000,2017-05-10 08:07:43.000000000,closed,8,read from jdbc
269,2016-10-15 22:04:09.000000000,2017-05-10 08:05:34.000000000,closed,7,GC overhead limit exceeded on write parquet file
268,2016-10-14 13:01:30.000000000,2016-10-15 03:14:11.000000000,closed,1,improve version parsing
267,2016-10-14 03:04:44.000000000,2016-10-14 03:32:20.000000000,closed,4,dplyr is needed to use `copy_to()`?
266,2016-10-13 04:47:44.000000000,2017-10-05 00:46:25.000000000,closed,7,spark tab in rstudio preview server shows many spark tables and there is no search
265,2016-10-13 04:18:07.000000000,2016-10-13 10:31:31.000000000,closed,5,Error While Encoding
264,2016-10-13 00:26:06.000000000,2017-08-18 01:12:23.000000000,closed,3,Another Column Limit Issue
263,2016-10-12 19:27:37.000000000,2016-10-21 03:03:12.000000000,closed,36,Failure to connect on Windows R 3.3.1
262,2016-10-11 18:01:18.000000000,2016-10-11 20:07:35.000000000,closed,7,extracting column names from a spark data frame
261,2016-10-11 00:01:24.000000000,2017-05-10 07:59:11.000000000,closed,1,Columns parameter not available in spark_read_csv
260,2016-10-08 01:14:15.000000000,2016-10-10 21:18:46.000000000,closed,1,implement `sdf_persist()`
259,2016-10-07 21:48:34.000000000,2016-11-23 05:05:27.000000000,closed,2,implement 'livy_install'
258,2016-10-07 03:06:43.000000000,2016-11-23 05:07:31.000000000,closed,3,Implement Livy connections
257,2016-10-07 01:41:52.000000000,2016-10-07 02:52:03.000000000,closed,1,implement handling for 'na.action'; default to 'na.omit'
256,2016-10-06 19:30:55.000000000,2017-08-18 01:55:19.000000000,closed,6,SparkContext was shut down on long running as_h2o_frame
255,2016-10-06 05:40:45.000000000,2017-08-02 10:36:17.000000000,closed,2,"implement 'gather', 'spread' methods"
254,2016-10-06 02:57:57.000000000,2016-10-06 03:36:41.000000000,closed,26,Failed while connecting to sparklyr to port (8880) for sessionid (7479): Gateway in port (8880) did not respond.
253,2016-10-06 01:30:15.000000000,2017-08-18 01:39:29.000000000,closed,0,consider moving derby.log and log4j.log into different directory
252,2016-10-06 00:48:56.000000000,2018-01-17 20:52:37.000000000,closed,8, Change between long and wide format
251,2016-10-06 00:31:18.000000000,2016-10-06 00:52:24.000000000,closed,2,question on spark sql functions which are not mapped?
250,2016-10-06 00:09:46.000000000,2017-08-18 00:48:12.000000000,closed,4,consider setting spark.sql.warehouse.dir by default
249,2016-10-05 22:47:39.000000000,2016-10-05 23:56:34.000000000,closed,9,lag function
248,2016-10-05 01:58:24.000000000,2016-10-05 02:08:54.000000000,closed,0,refactor feature transformers; add Tokenizer + RegexTokenizer
247,2016-10-04 21:00:26.000000000,2017-10-26 23:42:47.000000000,closed,6,Consider adding support for Word2Vec and TF-IDF
246,2016-10-04 13:30:45.000000000,2016-10-05 02:08:19.000000000,closed,1,"Correct definition of default ""quote"" argument"
245,2016-10-04 04:42:30.000000000,2016-10-05 22:01:21.000000000,closed,2,Failed to launch Spark shell. Ports file does not exist.
244,2016-10-03 01:07:41.000000000,2016-10-03 23:19:57.000000000,closed,4,Spark DF column limit? 
243,2016-10-01 01:43:31.000000000,2016-10-01 02:48:50.000000000,closed,3,'collect()' sometimes produces wrong result from 'copy_to()'ed datasets
242,2016-09-30 21:24:37.000000000,2017-08-18 00:45:08.000000000,closed,12,Unable to load high dimension dataset
241,2016-09-30 10:02:58.000000000,2017-08-18 00:28:27.000000000,closed,8,"spark_connect on OS X El Capitan returns ""Failed to open connection to monitor"""
240,2016-09-29 02:16:42.000000000,2016-09-29 21:05:22.000000000,closed,1,use ASCII unit separator for data copy
239,2016-09-28 22:02:23.000000000,2016-09-29 01:22:07.000000000,closed,7,sdf_save_table does not work using spark 1.6.2 and hadoop 2.6
238,2016-09-28 20:16:29.000000000,2016-10-05 01:18:43.000000000,closed,1,Replace ports file with gateway socket
237,2016-09-27 22:43:52.000000000,2017-08-18 00:25:17.000000000,closed,2,sparklyr with h2o - context creation issue 
236,2016-09-27 21:52:48.000000000,2017-08-18 00:23:47.000000000,closed,5,Dplyr query in tutorial not the same as on a data.frame
235,2016-09-27 19:59:42.000000000,2016-09-28 11:19:46.000000000,closed,3,"Add more Hive date support, espespecially a way to convert epoch time"
234,2016-09-27 18:03:03.000000000,2016-10-05 02:12:37.000000000,closed,2,Sparklyr to Spark ML - Integration & Architecture
233,2016-09-27 15:18:23.000000000,2016-09-28 13:29:50.000000000,closed,3,Where does sparklyr look for HTTPS certificate authorities?
232,2016-09-27 13:43:25.000000000,2016-10-05 02:12:52.000000000,closed,2,spark_write_csv function
231,2016-09-27 12:20:55.000000000,2016-09-27 23:35:47.000000000,closed,2,datediff function
230,2016-09-26 11:41:51.000000000,2016-09-27 11:41:33.000000000,closed,3,ERROR: dependency 'config' is not available for package 'sparklyr'
229,2016-09-26 04:52:02.000000000,2017-06-16 03:48:41.000000000,closed,35,Cannot set up the connection on spark 2.0.0
228,2016-09-25 10:22:43.000000000,2016-09-25 18:55:05.000000000,closed,2,Add URL field to DESCRIPTION
227,2016-09-24 18:34:04.000000000,2017-08-17 22:21:55.000000000,closed,6,Row binding large Spark DataFrames leads to a crash error.
226,2016-09-23 23:45:27.000000000,2016-09-23 23:50:10.000000000,closed,3,Spark download failure not caught / reported well
225,2016-09-23 22:01:06.000000000,2017-10-26 23:42:10.000000000,closed,6,Normalizer
224,2016-09-21 00:19:02.000000000,2016-09-21 00:52:20.000000000,closed,3,SparkUI URL on EMR clusters
223,2016-09-20 22:18:24.000000000,2016-09-26 19:10:37.000000000,closed,0,Increase logging while triggering spark_connect to allow exceptions to render
222,2016-09-20 21:29:28.000000000,2016-09-22 01:43:32.000000000,closed,1,revert use of readr to allow writeLines to reuse file connection while writ…
221,2016-09-16 22:08:02.000000000,2016-09-16 22:39:59.000000000,closed,3,Change in string formats during copy_to and collect operations on a cluster
220,2016-09-16 20:35:34.000000000,2016-09-26 22:17:30.000000000,closed,2,n_distinct does not accept more than one column
219,2016-09-16 20:10:52.000000000,2016-09-17 06:37:54.000000000,closed,2,IDE SparkUI button gives error
218,2016-09-16 19:59:25.000000000,2016-10-05 01:48:27.000000000,closed,5,"Couple of issues with IDE ""New Connection"" dialog on Cluster"
217,2016-09-15 21:54:56.000000000,2017-06-30 00:31:39.000000000,closed,3,ml_linear_regression regression weights
216,2016-09-15 21:43:40.000000000,2016-09-26 19:09:25.000000000,closed,1,add support for joins against local tables
215,2016-09-14 13:33:16.000000000,2017-08-17 03:38:20.000000000,closed,2,"*_join(..., copy = T) doesn't work"
214,2016-09-13 22:30:35.000000000,2016-09-15 21:44:31.000000000,closed,1,consider exporting `sdf_read_column`
213,2016-09-13 02:17:29.000000000,2016-09-14 03:07:08.000000000,closed,1,Implement pmin and pmax in dplyr interface
212,2016-09-11 23:34:38.000000000,2017-08-17 03:29:34.000000000,closed,3,Model Deployment
211,2016-09-11 10:41:40.000000000,2016-09-24 23:08:16.000000000,closed,2,pmin and pmax are unsupported
210,2016-09-09 22:22:02.000000000,2016-09-14 03:07:02.000000000,closed,0,add admin support to configure spark ui url
209,2016-09-09 01:22:45.000000000,2017-08-17 03:04:25.000000000,closed,42,Set up connection using sc from sparkR
208,2016-09-09 00:50:58.000000000,2016-09-13 00:44:44.000000000,closed,2,section.of -> section of
207,2016-09-08 17:38:56.000000000,2017-08-01 22:28:13.000000000,closed,4,Support for regParam and weightCol in GLM
206,2016-09-08 02:59:36.000000000,2016-10-05 01:12:12.000000000,closed,0,allow system administrators to configure spark ui url
205,2016-09-06 19:58:07.000000000,2016-09-13 03:28:37.000000000,closed,7,connect to Apache Cassandra
204,2016-09-05 13:12:03.000000000,2016-09-29 02:00:32.000000000,closed,11,Implement function quantile
203,2016-09-05 13:07:20.000000000,2016-09-10 01:52:03.000000000,closed,1,Rename function as.date
202,2016-09-02 22:32:37.000000000,2017-08-17 02:32:08.000000000,closed,3,Date comparison in filter
201,2016-09-02 21:13:39.000000000,2017-08-17 03:00:03.000000000,closed,2,SparkUI and Log errors out - cannot open file 'log4j.spark.log': No such file or directory
200,2016-09-02 15:14:18.000000000,2016-09-02 15:41:27.000000000,closed,1,job aborted due to stage failure.
199,2016-09-01 00:21:56.000000000,2016-09-13 00:51:37.000000000,closed,11,Second spark connection could hang (waiting state) in certain scenarios
198,2016-08-31 19:28:16.000000000,2016-09-01 01:16:39.000000000,closed,2,Applying ft_one_hot_enconder in ML 
197,2016-08-29 16:37:00.000000000,2016-10-05 01:59:19.000000000,closed,17,Error with ML 
196,2016-08-27 22:31:30.000000000,2017-08-17 02:57:06.000000000,closed,15,cross validation function and parameter tuning 
195,2016-08-26 16:31:39.000000000,2016-09-13 00:47:49.000000000,closed,4,"SQL Translation: modified `paste` to map to ""CONCAT_WS"" &  added `paste0` mapping to ""CONCAT"""
194,2016-08-26 15:52:21.000000000,2017-08-17 21:37:49.000000000,closed,2,ft_sql_transformer not working as described
193,2016-08-26 08:09:54.000000000,2016-08-26 20:22:45.000000000,closed,2,Null datetype value causing NPE
192,2016-08-26 06:57:27.000000000,1970-01-01 00:00:00.000000001,open,17,Collecting 1M rows several times triggers an exception in some environments
191,2016-08-25 20:03:40.000000000,2017-08-17 01:01:17.000000000,closed,3,Add support for anonymous Scala functions
190,2016-08-25 08:13:44.000000000,2016-09-29 01:27:31.000000000,closed,4,Enables to get a SparkContext and to use a running R Backend
189,2016-08-24 14:09:52.000000000,2016-11-11 12:04:21.000000000,closed,17,Failed to launch Spark shell. Ports file does not exist. -- The input line is too long.
188,2016-08-24 01:24:49.000000000,2016-08-26 20:21:27.000000000,closed,2,consider implementing additional types for sdf collect
187,2016-08-24 00:06:38.000000000,2017-08-17 02:46:06.000000000,closed,4,`copy_to` turns Dates into numeric columns (with only the year)
186,2016-08-22 17:59:15.000000000,2016-09-13 00:45:12.000000000,closed,15,concentration parameter for document and topics distributions in ml_lda v2
185,2016-08-22 01:31:19.000000000,2016-08-25 17:28:19.000000000,closed,2,config additional options
184,2016-08-20 23:39:27.000000000,2016-09-10 00:19:38.000000000,closed,4,Get a spark dataframe after using invoke 
183,2016-08-19 20:22:55.000000000,2017-08-17 02:44:32.000000000,closed,4,mutate does not work in spark 2.0.0 when prediction is not a long
182,2016-08-19 17:19:35.000000000,2016-08-22 16:50:31.000000000,closed,3,left_join doesn't work
181,2016-08-18 22:21:00.000000000,2017-07-22 01:46:46.000000000,closed,4,Support for yarn-cluster mode
180,2016-08-18 18:17:38.000000000,2016-08-22 17:59:58.000000000,closed,5,concentration parameter for document and topics distributions in ml_lda
179,2016-08-18 17:29:55.000000000,2016-08-19 20:46:05.000000000,closed,0,add `tol` parameter to kmenas to support tolerance of convergence
178,2016-08-17 19:43:31.000000000,2016-08-18 17:30:14.000000000,closed,3,setEpsilon and setInitializationMode for ml_kmeans
177,2016-08-17 17:26:23.000000000,2016-08-20 01:13:59.000000000,closed,3,Consider renameing max.iter parameter to iter.max in ml_kmeans
176,2016-08-17 17:20:00.000000000,2016-09-29 02:03:01.000000000,closed,30,Get value from spark environment
175,2016-08-16 20:49:23.000000000,2017-08-17 00:56:26.000000000,closed,4,mutate_each: Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
174,2016-08-16 20:46:35.000000000,2017-08-17 00:04:52.000000000,closed,3,mutate_each on many columns:  Error: java.lang.StackOverflowError
173,2016-08-16 16:56:05.000000000,2016-08-17 20:47:57.000000000,closed,3,compute cost for k-means
172,2016-08-16 15:22:57.000000000,2016-08-16 21:14:03.000000000,closed,2,"can't predict directly from ml_kmeans model: Error in eval(expr, envir, enclos) :    argument ""newdata"" is missing, with no default"
171,2016-08-15 23:21:05.000000000,1970-01-01 00:00:00.000000001,open,4,Would you please publish the JAR that comes with this R package as a Spark Package
170,2016-08-15 03:15:40.000000000,2016-09-29 02:02:22.000000000,closed,1,Bug in ml_save / ml_load
169,2016-08-13 05:01:35.000000000,2016-08-16 02:33:26.000000000,closed,2,Added classification metrics and a function to print feature importance.
168,2016-08-12 23:27:38.000000000,2017-08-17 00:01:50.000000000,closed,1,Parse exception on certain mutate Date call
167,2016-08-12 22:24:04.000000000,2016-08-19 10:40:20.000000000,closed,3,Error with dplyr::sample_n function
166,2016-08-12 20:37:58.000000000,2016-08-15 21:55:59.000000000,closed,2,Spark connection not found when running a shiny rmarkdown document
165,2016-08-11 21:04:18.000000000,2016-10-11 19:35:12.000000000,closed,4,implement compute in dplyr
164,2016-08-11 00:16:13.000000000,2016-08-11 00:41:23.000000000,closed,5,implement 'collect' method for Dataset
163,2016-08-10 03:46:11.000000000,2017-08-17 02:34:36.000000000,closed,1,handle / report NA values in logical vectors for copy_to
162,2016-08-10 02:52:42.000000000,2016-08-10 03:02:22.000000000,closed,0,"copy_to(..., overwrite = TRUE) fails with Spark 2.0.0"
161,2016-08-10 02:34:53.000000000,2016-08-10 03:31:16.000000000,closed,1,handle model predictions with categorical variables
160,2016-08-09 20:45:51.000000000,1970-01-01 00:00:00.000000001,open,0,consider providing commands to start spark cluster detached from session
159,2016-08-09 20:31:59.000000000,2016-08-10 19:37:43.000000000,closed,5,how to use data from Hive on  YARN cluster with sparklyr?
158,2016-08-09 20:21:35.000000000,2016-08-10 18:44:36.000000000,closed,5,ml_kmeans on Spark 2.0.0 gives Error: Unable to retreive a Spark DataFrame from object of class character 
157,2016-08-09 18:39:12.000000000,2017-08-18 01:21:42.000000000,closed,6,long operations do not always cancel
156,2016-08-09 18:22:45.000000000,2016-09-29 02:04:48.000000000,closed,4,readr infinite loop while installing sparklyr
155,2016-08-09 02:03:18.000000000,2016-08-09 17:23:27.000000000,closed,1,AGAIN: Failed to launch Spark shell. Ports file does not exist.
154,2016-08-06 22:47:11.000000000,2016-08-07 11:19:45.000000000,closed,1,Cache a table: need a name registered
153,2016-08-06 22:46:51.000000000,2016-08-07 01:51:07.000000000,closed,0,Cache a table
152,2016-08-06 20:11:30.000000000,2017-08-16 23:56:25.000000000,closed,1,Feature: be able to overwrite parquet file
151,2016-08-06 04:08:30.000000000,2017-08-17 02:33:49.000000000,closed,2,investigate incorrect serialization of missing vs. NA strings
150,2016-08-06 01:29:53.000000000,2016-08-10 00:17:00.000000000,closed,11,implement 'spark_compile_package_jars' for extension packages
149,2016-08-05 01:27:51.000000000,2016-08-10 03:30:11.000000000,closed,1,prefer 'major.minor' versioning for spark jars
148,2016-08-04 21:59:56.000000000,2016-08-10 03:31:45.000000000,closed,3,investigate failure with Spark 2.0.0
147,2016-08-04 21:44:29.000000000,2016-08-10 03:30:51.000000000,closed,2,"Error: 'could not find function ""connection_is_open"" ' "
146,2016-08-04 02:15:12.000000000,2016-08-04 15:33:00.000000000,closed,2,merge sparkapi into sparklyr
145,2016-08-03 16:21:54.000000000,2016-08-04 02:42:58.000000000,closed,3,Failed to connect to Spark (SPARK_HOME is not set).
144,2016-08-03 15:50:35.000000000,2017-02-17 00:09:43.000000000,closed,2,Dealing with multiple databases
143,2016-08-02 14:55:06.000000000,2016-11-05 02:36:51.000000000,closed,8,copy_to error & saveAsTable option
142,2016-08-01 16:31:08.000000000,2016-08-02 13:25:17.000000000,closed,8,defaul config YAML for cluster deployment
141,2016-08-01 15:07:17.000000000,2016-08-01 15:42:21.000000000,closed,0,extend spark_config documentation with a link to config-template.yml on GitHub
140,2016-07-30 02:04:04.000000000,1970-01-01 00:00:00.000000001,open,4,allow 'tbl_spark's to be constructed from streaming Spark DataFrames
139,2016-07-30 01:46:59.000000000,2016-08-26 22:35:45.000000000,closed,9,Add ALS ML model similar to SparkR
138,2016-07-29 16:35:27.000000000,2016-08-01 15:03:14.000000000,closed,2,extend spark_config documentation with a link to config-template.yml
137,2016-07-29 16:32:22.000000000,2016-07-29 17:15:02.000000000,closed,0,typo in man for spark_config
136,2016-07-29 16:11:06.000000000,2016-08-01 19:29:35.000000000,closed,5,defaul config YAML for cluster deployment
135,2016-07-29 15:56:39.000000000,2016-07-29 17:17:09.000000000,closed,0,typo in spark_connect documentation
134,2016-07-29 00:16:18.000000000,2016-11-05 02:24:54.000000000,closed,9,implement save / load for 'ml_model' objects
133,2016-07-28 15:39:42.000000000,2016-11-05 02:04:56.000000000,closed,8,Predict(...) on large newData seems unordered
132,2016-07-27 22:11:59.000000000,2016-07-28 00:02:42.000000000,closed,0,update spark 2.0 preview to official 2.0.0 release
131,2016-07-27 18:25:58.000000000,2016-08-09 20:13:17.000000000,closed,5,connecting to YARN cluster with KERBEROS authentication using spark_connect
130,2016-07-26 23:52:32.000000000,2016-07-28 23:31:00.000000000,closed,1,Survival Regression
129,2016-07-26 22:59:15.000000000,2016-07-27 04:08:09.000000000,closed,2,"spark_connect not using ""version"" argument"
128,2016-07-26 16:48:55.000000000,2016-07-26 23:43:30.000000000,closed,5,Transforming numerical fields into categories and then model
127,2016-07-25 23:15:21.000000000,2016-11-05 01:33:55.000000000,closed,8,Handling nulls and NA in dataframes 
126,2016-07-25 23:09:02.000000000,2018-10-02 02:08:58.000000000,closed,3,implement spark_read_feather()
125,2016-07-25 13:46:05.000000000,2016-07-26 11:01:01.000000000,closed,19,Can not create spark_connect.
124,2016-07-23 15:00:50.000000000,2016-07-23 18:19:09.000000000,closed,0,export higher level spark_home_dir function rather than spark_install_find
123,2016-07-23 02:46:21.000000000,2016-07-23 08:45:39.000000000,closed,0,add support for optional versions in sparkapi
122,2016-07-21 21:55:10.000000000,2016-07-22 00:21:57.000000000,closed,0,spark_conenct fails with 2.0.0-preview only using sparklyr version 0.2.29
121,2016-07-21 03:40:50.000000000,2016-07-21 19:56:50.000000000,closed,0,remove references to spark.api.r
120,2016-07-21 01:19:45.000000000,2020-03-27 03:47:42.000000000,closed,8,user defined functions in dplyr
119,2016-07-20 04:03:33.000000000,2016-07-20 21:20:19.000000000,closed,3,Use dplyr on existing tables within Spark cluster.
118,2016-07-19 14:19:57.000000000,2016-07-19 19:09:31.000000000,closed,1,Add Disqus panel to spark.rstudio.com
117,2016-07-19 11:52:06.000000000,2016-07-20 21:27:31.000000000,closed,7,Sparklry installation failed on centos
116,2016-07-18 19:48:00.000000000,2016-07-22 04:12:21.000000000,closed,3,Casting variables
115,2016-07-18 15:12:46.000000000,2016-08-09 20:11:33.000000000,closed,9,"extend ""Deployment"" page with a wider YARN cluster connection description"
114,2016-07-17 13:47:55.000000000,2016-10-05 01:22:01.000000000,closed,26,spark_connect failed on OS X:Failed to launch Spark shell. Ports file does not exist.
113,2016-07-16 20:39:39.000000000,2016-07-21 20:56:28.000000000,closed,2,append to existing table
112,2016-07-16 20:19:50.000000000,2016-11-04 22:54:53.000000000,closed,13,ml_lda number of topics = columns of dataset why?
111,2016-07-15 22:53:50.000000000,2016-11-04 22:35:31.000000000,closed,9,Automatically rename ambiguous/repeated column names in CSV
110,2016-07-15 13:53:25.000000000,2016-11-04 21:21:54.000000000,closed,10,DBI interface needs to implement sqlParseVariables generic
109,2016-07-14 22:47:00.000000000,2016-07-15 03:10:48.000000000,closed,1,expose 'unionAll()' API for row-binding tbls / Spark DataFrames
108,2016-07-14 07:28:06.000000000,2016-07-14 07:47:47.000000000,closed,1,sparklyr docker image is available for China user
107,2016-07-13 21:22:03.000000000,2016-11-04 21:19:45.000000000,closed,2,sparklyr mangles column names with non-ASCII characters
106,2016-07-13 20:12:41.000000000,2016-07-14 23:16:54.000000000,closed,1,support for reading from relative paths
105,2016-07-13 10:38:06.000000000,2016-07-14 13:01:34.000000000,closed,9,Can't install sparklyr
104,2016-07-12 21:03:08.000000000,2017-10-26 23:28:51.000000000,closed,3,consider how to incorporate string-related feature transformers
103,2016-07-12 18:33:47.000000000,2016-07-22 03:15:16.000000000,closed,2,enable spark_disconnect by master and name
102,2016-07-12 03:50:27.000000000,2016-07-12 04:07:25.000000000,closed,0,spark_connect speed in windows can be improved by moving setx cmd to install
101,2016-07-12 02:21:25.000000000,2017-10-26 06:54:17.000000000,closed,3,consider how reference labels should be chosen / selected for ml routines
100,2016-07-10 22:31:34.000000000,2016-07-10 23:33:07.000000000,closed,2,Fail to run the linear_regression model
99,2016-07-10 22:26:00.000000000,2016-07-11 21:11:48.000000000,closed,2,"Fail to run the k-means example, I just give a right version"
98,2016-07-10 19:32:44.000000000,2017-06-16 03:43:58.000000000,closed,5,Connecting to Spark on IBM Bluemix
97,2016-07-10 09:26:03.000000000,2016-07-21 20:50:23.000000000,closed,1,spark_connect fails in Windows when Spark CMD files are not executable
96,2016-07-10 08:23:29.000000000,2016-07-12 20:46:37.000000000,closed,20,ml_logistic_regression does not work with categorical features
95,2016-07-10 04:51:24.000000000,2016-07-10 22:37:36.000000000,closed,1,Closures
94,2016-07-09 17:03:06.000000000,1970-01-01 00:00:00.000000001,open,1,Automatically delete spark-warehouse folder or set its location on config file
93,2016-07-08 23:54:34.000000000,2016-07-12 03:27:41.000000000,closed,10,Error setting spark_config params
92,2016-07-08 14:09:02.000000000,2016-07-22 10:44:42.000000000,closed,10,How to set all column names of spark data frame?
91,2016-07-08 03:16:30.000000000,2016-07-09 00:11:46.000000000,closed,1, Error in summary method with lasso regression
90,2016-07-08 00:58:59.000000000,1970-01-01 00:00:00.000000001,open,0,support for data types (especially dates) in spark_read_parquet 
89,2016-07-07 20:08:24.000000000,2016-07-07 20:12:01.000000000,closed,1,enable multiple connections to same host via distinct app_name
88,2016-07-07 18:30:05.000000000,2016-07-08 09:39:28.000000000,closed,12,Error about loaded version of sparkapi when install of sparklyr is comleted
87,2016-07-07 13:52:39.000000000,2016-07-07 19:55:25.000000000,closed,5,setting up config
86,2016-07-07 04:41:48.000000000,2016-07-22 03:12:36.000000000,closed,50,"Error when running sc<-spark_connect(master = ""local"")"
85,2016-07-07 01:21:34.000000000,2016-07-08 09:15:20.000000000,closed,2,"Error in creating Local Spark Connection, Error in instances[[scon$sconRef]] <- NULL"
84,2016-07-06 19:38:00.000000000,2016-07-08 11:33:14.000000000,closed,2,placing predicted values into spark dataframes
83,2016-07-06 15:41:01.000000000,2017-08-10 02:33:13.000000000,closed,2,"Support for decimal separator (comma or period), skip lines and nrows ?"
82,2016-07-06 15:29:46.000000000,2016-07-07 00:15:41.000000000,closed,2,$ operator not defined for this S4 class error in spark_connect 
81,2016-07-06 14:58:47.000000000,2017-06-05 21:21:45.000000000,closed,47,Apply functions from SparkR
80,2016-07-06 05:06:16.000000000,2016-07-07 02:05:33.000000000,closed,8,Failed to launch Spark shell. Ports file does not exist
79,2016-07-05 23:23:04.000000000,2016-07-06 01:02:56.000000000,closed,0,expose read/write mode/options in parquet and json interface
78,2016-07-05 19:37:18.000000000,2016-07-12 03:25:31.000000000,closed,5,Specify temp directory in spark_connect()
77,2016-07-05 17:34:36.000000000,2018-04-13 08:25:01.000000000,closed,6,Creating new tbl with `sdf_partition()` doesn't show up in spark environment.
76,2016-07-05 13:45:46.000000000,2016-07-08 02:09:13.000000000,closed,20,"rbind(x,y) and unionAll(x,y)"
75,2016-07-05 13:30:22.000000000,2016-07-05 14:00:13.000000000,closed,1,coalesce in dataframe 
74,2016-07-05 13:16:55.000000000,2016-07-07 08:46:59.000000000,closed,7,NOTE: user should install devel version od dplyr before installing sparklyr
73,2016-07-04 17:48:11.000000000,2016-07-08 09:37:27.000000000,closed,5,How to connect to spark?
72,2016-07-03 20:45:45.000000000,2016-07-07 08:41:54.000000000,closed,1,How to enable mode overwrite or append in spark_write_parquet() function?
71,2016-07-03 10:18:58.000000000,2016-07-22 10:41:50.000000000,closed,2,"validate or fix transmute, rename, slice and others"
70,2016-07-03 05:16:50.000000000,2016-07-07 21:11:31.000000000,closed,1,Documentation for `...` arg for `ml`.
69,2016-07-03 03:44:24.000000000,2016-07-05 22:39:13.000000000,closed,0,remove collect and collect.tbl_spark from docs
68,2016-07-02 23:48:41.000000000,2016-07-03 02:51:53.000000000,closed,5,"How to read csv file with delimiter = "";"" using spark_read_csv() ?"
67,2016-07-02 18:38:10.000000000,2016-07-02 20:32:33.000000000,closed,1,Can't create confusion matrix using `table()` with sdf objects. 
66,2016-07-02 06:21:02.000000000,2016-07-05 22:40:01.000000000,closed,3,`collect.tbl_spark()` is in package description but says can't be found in console.
65,2016-07-01 21:40:56.000000000,2018-01-17 20:44:05.000000000,closed,6,`ml_logistic_regression()` throws error regarding null values even after using na.omit
64,2016-07-01 20:34:14.000000000,2016-07-02 01:01:35.000000000,closed,0,Add travis badge to readme file
63,2016-07-01 20:31:47.000000000,2016-07-02 01:00:27.000000000,closed,0,Remove embedded winutil binaries
62,2016-07-01 18:47:10.000000000,2016-07-08 01:40:58.000000000,closed,0,Fix `spark_log` and `spark_web` in windows environment
61,2016-07-01 18:31:58.000000000,2016-07-02 01:53:18.000000000,closed,0,Add ability to invoke extended scala methods directly over the model object
60,2016-07-01 07:10:26.000000000,2017-10-26 23:27:22.000000000,closed,19,Add .toPMML spark methods for MLlib into sparklyr
59,2016-06-30 20:37:47.000000000,2017-08-10 00:50:18.000000000,closed,10,Google Dataproc: Certain error conditions cause a hang in the command
58,2016-06-30 19:40:59.000000000,2016-06-30 19:45:42.000000000,closed,0,improvements found while migrating 1b rows perf investigation
57,2016-06-30 17:51:27.000000000,2016-06-30 19:37:36.000000000,closed,3,"cannot copy dataframe to spark, httr:read_csv error "
56,2016-06-30 13:49:45.000000000,2016-06-30 21:26:29.000000000,closed,10,install error on mac: subscript out of bounds
55,2016-06-30 05:07:57.000000000,2016-06-30 05:54:58.000000000,closed,4,persistent spark path
54,2016-06-30 01:36:08.000000000,2016-07-17 09:19:54.000000000,closed,8,Some issues related to copy_to() and flights data in a cluster environment
53,2016-06-30 01:23:58.000000000,2016-07-22 03:05:42.000000000,closed,9,"Error when installing sparklyr, error in curl: timeout was reached"
52,2016-06-29 20:16:54.000000000,2016-07-08 17:35:24.000000000,closed,11,"Error on ""reached elapsed time limit"" when reloading R session in a cluster"
51,2016-06-29 19:42:39.000000000,2016-07-07 20:36:04.000000000,closed,1,Error on spark_connect on Windows when username has a space in it
50,2016-06-29 19:22:05.000000000,2016-06-29 19:42:59.000000000,closed,2,Working with YARN cluster in client mode
49,2016-06-29 18:40:19.000000000,2016-06-30 19:45:42.000000000,closed,0,need to improve experience while failing to connect to cluster
48,2016-06-29 13:58:01.000000000,2016-07-12 03:22:24.000000000,closed,10,error when creating a spark connection in windows 7
47,2016-06-28 21:57:13.000000000,2016-07-07 08:37:21.000000000,closed,10,Error when installing sparklyr if dplyr was not installed first
46,2016-06-28 21:32:56.000000000,2016-06-28 21:35:00.000000000,closed,0,during windows install in x64 and x86 use default system path
45,2016-06-28 21:30:21.000000000,2016-07-07 22:30:27.000000000,closed,1,Error on spark_connect() after installing msvc redistributable without restarting RStudio
44,2016-06-28 20:18:56.000000000,2016-06-28 20:20:34.000000000,closed,0,spark windows installation over wow64
43,2016-06-28 02:37:48.000000000,2016-06-28 02:40:11.000000000,closed,0,add support for windows wit wow64 running
42,2016-06-27 20:02:06.000000000,2016-06-27 22:00:26.000000000,closed,1,add support for running on windows
41,2016-06-27 18:15:25.000000000,2016-06-27 18:17:06.000000000,closed,0,map date time columns as doubles
40,2016-06-26 11:00:37.000000000,2016-06-26 13:23:59.000000000,closed,3,Add connection close wait time for older versions of the ide
39,2016-06-25 10:16:43.000000000,2016-06-27 04:00:59.000000000,closed,9,Fix spark-submit launch on windows and instructions
38,2016-06-25 04:19:37.000000000,2016-06-25 04:20:30.000000000,closed,1,strange bug when attempting to run Spark code after session restart 
37,2016-06-24 22:48:00.000000000,2016-06-28 03:27:33.000000000,closed,1,"ClassCastException using copy_to with ""flights"" data in cluster mode"
36,2016-06-24 21:54:44.000000000,2016-07-07 00:13:05.000000000,closed,2,consider refactoring 'spark_api' family of functions
35,2016-06-24 01:48:49.000000000,2016-09-29 02:35:13.000000000,closed,2,provide mechanism for `cbind`ing Spark DataFrames
34,2016-06-23 17:16:21.000000000,2016-07-07 08:33:18.000000000,closed,1,invalid versions in `spark_install()` produce unhelpful error
33,2016-06-23 00:01:34.000000000,2016-07-07 22:24:35.000000000,closed,3,restore version and appname checks for idempontent connections
32,2016-06-22 22:36:25.000000000,2016-06-23 17:29:54.000000000,closed,1,SQL Parsing error
31,2016-06-22 00:27:21.000000000,2016-06-22 01:51:31.000000000,closed,4,`spark_connect()` doesn't detect version change on multiple calls
30,2016-06-21 22:06:24.000000000,2016-06-22 00:06:25.000000000,closed,2,"write methods should take 'sparkapi_jobj', not 'jobj'"
29,2016-06-20 19:56:23.000000000,2016-06-20 20:55:26.000000000,closed,1,make the DBI interface internal
28,2016-06-20 19:56:13.000000000,2016-06-20 20:55:12.000000000,closed,1,import rather than depend upon dplyr
27,2016-06-17 22:05:10.000000000,2016-06-18 05:11:48.000000000,closed,3,sample_n w/o collect fails
26,2016-06-17 00:53:35.000000000,2016-07-06 00:17:20.000000000,closed,2,Support hadoop 1.x in spark_install
25,2016-06-16 22:56:59.000000000,2016-09-29 02:34:13.000000000,closed,2,implement 'summary()' for ml_ routines
24,2016-06-16 17:44:35.000000000,2016-06-22 00:09:50.000000000,closed,1,Expand time for file to appear?
23,2016-06-16 17:27:19.000000000,2016-06-16 19:19:31.000000000,closed,2,Expand EC2 docs.
22,2016-06-16 01:34:47.000000000,2016-07-06 18:40:48.000000000,closed,0,`collect()` fails when one column returns to R as a jobj
21,2016-06-15 19:18:16.000000000,2016-06-15 21:41:45.000000000,closed,1,don't export accessors for sc instance data
20,2016-06-15 18:57:56.000000000,2016-06-22 00:08:22.000000000,closed,1,Set expectations around EC2 launch time
19,2016-06-15 18:43:03.000000000,2016-06-22 00:10:33.000000000,closed,3,Can we pick a more general default instance size
18,2016-06-15 18:41:48.000000000,2016-06-22 00:11:08.000000000,closed,1,key file naming too particular
17,2016-06-15 00:01:27.000000000,2016-06-17 01:36:05.000000000,closed,5,consider exposing ml transformation utilities
16,2016-06-09 21:47:28.000000000,2016-06-09 23:07:00.000000000,closed,1,cannot cast columns to `numeric` on creation
15,2016-06-09 21:25:57.000000000,2016-06-17 01:35:32.000000000,closed,3,no longer able to create 'sql_context' from 'sc'
14,2016-06-09 21:17:18.000000000,2016-07-06 00:57:23.000000000,closed,0,printing a 'spark_tbl' reports logical columns as character
13,2016-06-09 01:29:23.000000000,2016-07-06 01:52:10.000000000,closed,3,readme notes
12,2016-06-07 23:08:46.000000000,2016-06-25 10:36:39.000000000,closed,2,shiny reactives for structured streaming
11,2016-06-07 22:01:02.000000000,2016-06-08 00:47:54.000000000,closed,6,improve performance of scala => R object transfer
10,2016-06-07 05:11:43.000000000,2016-06-08 01:00:56.000000000,closed,4,improve performance of 'scala => R' object transfer
9,2016-06-03 20:58:43.000000000,2016-06-07 18:10:09.000000000,closed,4,handle '.' in names
8,2016-06-03 03:46:22.000000000,2016-06-17 01:18:00.000000000,closed,1,consider making R6 / simple wrapper classes for common jobj types
7,2016-06-02 02:15:22.000000000,2016-06-03 01:35:40.000000000,closed,2,improve error reporting from `spark_invoke`
6,2016-06-01 23:38:29.000000000,2016-06-03 01:37:34.000000000,closed,0,"provide `spark_invoke_ctor` as alias to `spark_invoke(..., ""<init>"")`"
5,2016-06-01 22:44:42.000000000,2016-06-03 01:56:27.000000000,closed,2,provide more user feedback in 'spark_install'?
4,2016-05-27 21:16:58.000000000,2016-05-27 23:05:40.000000000,closed,1,Remove a number of the notes from R CMD check
3,2016-05-27 20:55:32.000000000,2016-05-27 20:56:31.000000000,closed,0,Use devel devtools so circular dependencies work
2,2016-05-24 23:33:04.000000000,2016-05-31 09:19:11.000000000,closed,5,R CMD check notes
1,2016-05-24 20:12:45.000000000,2016-05-25 15:46:30.000000000,closed,1,Remove install token from README and fix history
